NOTE: Redirects are currently not supported in Windows or MacOs.
/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : ./tools/test.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 1
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:28596
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_jh6o_jv8/none_qm80_ny2
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=28596
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_jh6o_jv8/none_qm80_ny2/attempt_0/0/error.json
projects.mmdet3d_plugin
======
Loading NuScenes tables for version v1.0-trainval...
23 category,
8 attribute,
4 visibility,
64386 instance,
12 sensor,
10200 calibrated_sensor,
2631083 ego_pose,
68 log,
850 scene,
34149 sample,
2631083 sample_data,
1166187 sample_annotation,
4 map,
Done loading in 22.401 seconds.
======
Reverse indexing ...
Done reverse indexing in 6.3 seconds.
======
load checkpoint from local path: ./ckpts/uniad_base_e2e.pth
2023-07-26 13:51:20,425 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.0.conv2 is upgraded to version 2.
2023-07-26 13:51:20,429 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.1.conv2 is upgraded to version 2.
2023-07-26 13:51:20,431 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.2.conv2 is upgraded to version 2.
2023-07-26 13:51:20,433 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.3.conv2 is upgraded to version 2.
2023-07-26 13:51:20,436 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.4.conv2 is upgraded to version 2.
2023-07-26 13:51:20,438 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.5.conv2 is upgraded to version 2.
2023-07-26 13:51:20,440 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.6.conv2 is upgraded to version 2.
2023-07-26 13:51:20,443 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.7.conv2 is upgraded to version 2.
2023-07-26 13:51:20,445 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.8.conv2 is upgraded to version 2.
2023-07-26 13:51:20,448 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.9.conv2 is upgraded to version 2.
2023-07-26 13:51:20,450 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.10.conv2 is upgraded to version 2.
2023-07-26 13:51:20,453 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.11.conv2 is upgraded to version 2.
2023-07-26 13:51:20,455 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.12.conv2 is upgraded to version 2.
2023-07-26 13:51:20,458 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.13.conv2 is upgraded to version 2.
2023-07-26 13:51:20,460 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.14.conv2 is upgraded to version 2.
2023-07-26 13:51:20,462 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.15.conv2 is upgraded to version 2.
2023-07-26 13:51:20,465 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.16.conv2 is upgraded to version 2.
2023-07-26 13:51:20,467 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.17.conv2 is upgraded to version 2.
2023-07-26 13:51:20,470 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.18.conv2 is upgraded to version 2.
2023-07-26 13:51:20,472 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.19.conv2 is upgraded to version 2.
2023-07-26 13:51:20,475 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.20.conv2 is upgraded to version 2.
2023-07-26 13:51:20,477 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.21.conv2 is upgraded to version 2.
2023-07-26 13:51:20,480 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.22.conv2 is upgraded to version 2.
2023-07-26 13:51:20,482 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.0.conv2 is upgraded to version 2.
2023-07-26 13:51:20,487 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.1.conv2 is upgraded to version 2.
2023-07-26 13:51:20,490 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.2.conv2 is upgraded to version 2.
The model and loaded state dict do not match exactly

unexpected key in source state_dict: bbox_size_fc.weight, bbox_size_fc.bias, pts_bbox_head.query_embedding.weight, pts_bbox_head.transformer.reference_points.weight, pts_bbox_head.transformer.reference_points.bias

> /Users/liangming.xu/code/UniAD/tools/test.py(230)main()
-> result = model(return_loss=False, rescale=True, **data)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(723)simple_test_track()
-> bs = img.size(0)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(658)_forward_single_frame_inference()
-> bev_embed, bev_pos = self.get_bevs(img, img_metas, prev_bev=prev_bev)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(57)decode_single()
-> max_num = self.max_num
(Pdb)   /Users/liangming.xu/code/UniAD/tools/test.py(274)<module>()
-> main()
  /Users/liangming.xu/code/UniAD/tools/test.py(230)main()
-> result = model(return_loss=False, rescale=True, **data)
  /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(83)forward()
-> return self.forward_test(**kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(292)forward_test()
-> result_track = self.simple_test_track(img, l2g_t, l2g_r_mat, img_metas, timestamp)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(753)simple_test_track()
-> frame_res = self._forward_single_frame_inference(
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(658)_forward_single_frame_inference()
-> bev_embed, bev_pos = self.get_bevs(img, img_metas, prev_bev=prev_bev)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(481)select_active_track_query()
-> result_dict = self._track_instances2results(track_instances[active_index], img_metas, with_mask=with_mask)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(788)_track_instances2results()
-> bboxes_dict = self.bbox_coder.decode(bbox_dict, with_mask=with_mask, img_metas=img_metas)[0]
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(152)decode()
-> predictions_list.append(self.decode_single(
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(57)decode_single()
-> max_num = self.max_num
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(152)decode()
-> predictions_list.append(self.decode_single(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(788)_track_instances2results()
-> bboxes_dict = self.bbox_coder.decode(bbox_dict, with_mask=with_mask, img_metas=img_metas)[0]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(481)select_active_track_query()
-> result_dict = self._track_instances2results(track_instances[active_index], img_metas, with_mask=with_mask)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(658)_forward_single_frame_inference()
-> bev_embed, bev_pos = self.get_bevs(img, img_metas, prev_bev=prev_bev)
(Pdb) 653  	
654  	        track_instances = Instances.cat([other_inst, active_inst])
655  	
656  	        # NOTE: You can replace BEVFormer with other BEV encoder and provide bev_embed here
657  	        import pdb; pdb.set_trace()
658  ->	        bev_embed, bev_pos = self.get_bevs(img, img_metas, prev_bev=prev_bev)
659  	        det_output = self.pts_bbox_head.get_detections(
660  	            bev_embed,
661  	            object_query_embeds=track_instances.query,
662  	            ref_points=track_instances.ref_pts,
663  	            img_metas=img_metas,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(481)select_active_track_query()
-> result_dict = self._track_instances2results(track_instances[active_index], img_metas, with_mask=with_mask)
(Pdb) tensor([False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False,  True, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False,  True, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False,  True, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(57)decode_single()
-> max_num = self.max_num
(Pdb)   /Users/liangming.xu/code/UniAD/tools/test.py(274)<module>()
-> main()
  /Users/liangming.xu/code/UniAD/tools/test.py(230)main()
-> result = model(return_loss=False, rescale=True, **data)
  /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(83)forward()
-> return self.forward_test(**kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(292)forward_test()
-> result_track = self.simple_test_track(img, l2g_t, l2g_r_mat, img_metas, timestamp)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(753)simple_test_track()
-> frame_res = self._forward_single_frame_inference(
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(696)_forward_single_frame_inference()
-> out.update(self.select_sdc_track_query(track_instances[track_instances.obj_idxes==-2], img_metas))
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(488)select_sdc_track_query()
-> result_dict = self._track_instances2results(sdc_instance, img_metas, with_mask=False)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(788)_track_instances2results()
-> bboxes_dict = self.bbox_coder.decode(bbox_dict, with_mask=with_mask, img_metas=img_metas)[0]
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(152)decode()
-> predictions_list.append(self.decode_single(
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(57)decode_single()
-> max_num = self.max_num
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/modules.py(249)forward()
-> active_track_instances = self._select_active_tracks(data)
(Pdb)   /Users/liangming.xu/code/UniAD/tools/test.py(274)<module>()
-> main()
  /Users/liangming.xu/code/UniAD/tools/test.py(230)main()
-> result = model(return_loss=False, rescale=True, **data)
  /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(83)forward()
-> return self.forward_test(**kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(292)forward_test()
-> result_track = self.simple_test_track(img, l2g_t, l2g_r_mat, img_metas, timestamp)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(753)simple_test_track()
-> frame_res = self._forward_single_frame_inference(
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(706)_forward_single_frame_inference()
-> out_track_instances = self.query_interact(tmp)
  /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/modules.py(249)forward()
-> active_track_instances = self._select_active_tracks(data)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(57)decode_single()
-> max_num = self.max_num
(Pdb)   /Users/liangming.xu/code/UniAD/tools/test.py(274)<module>()
-> main()
  /Users/liangming.xu/code/UniAD/tools/test.py(230)main()
-> result = model(return_loss=False, rescale=True, **data)
  /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(83)forward()
-> return self.forward_test(**kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(292)forward_test()
-> result_track = self.simple_test_track(img, l2g_t, l2g_r_mat, img_metas, timestamp)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(777)simple_test_track()
-> results = self._det_instances2results(track_instances_fordet, results, img_metas)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(835)_det_instances2results()
-> bboxes_dict = self.bbox_coder.decode(bbox_dict, img_metas=img_metas)[0]
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(152)decode()
-> predictions_list.append(self.decode_single(
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(57)decode_single()
-> max_num = self.max_num
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(152)decode()
-> predictions_list.append(self.decode_single(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(835)_det_instances2results()
-> bboxes_dict = self.bbox_coder.decode(bbox_dict, img_metas=img_metas)[0]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(777)simple_test_track()
-> results = self._det_instances2results(track_instances_fordet, results, img_metas)
(Pdb) Instances(num_instances=901, image_height=1, image_width=1, fields=[ref_pts: tensor([[-1.8111e-02,  6.4056e-01, -1.6428e-01],
        [-1.1195e+00,  8.4606e-01,  4.2058e-01],
        [ 1.3552e+00,  2.4231e-01, -2.9146e-01],
        ...,
        [-9.4047e-02,  1.0546e+00, -2.0764e-01],
        [ 1.2377e+00,  3.4943e+00,  3.4574e-01],
        [ 1.2477e-03, -2.4410e-03,  1.1362e-01]]), query: tensor([[ 0.9794,  1.4678,  2.2049,  ..., -0.8909, -0.0528, -0.0377],
        [-0.1857,  0.0648, -0.3255,  ...,  0.8429,  0.9830,  1.0372],
        [ 0.9206, -2.1922, -1.2307,  ..., -0.6641, -0.4396,  1.1959],
        ...,
        [-0.4122,  1.3001, -0.3364,  ..., -0.0273,  0.7269,  0.7551],
        [ 0.5784, -1.9046, -0.5663,  ...,  0.1317, -0.8664,  1.2704],
        [ 1.1220, -1.8478,  0.7056,  ...,  2.9896,  0.3278,  1.9336]]), output_embedding: tensor([[-0.0888,  1.1860,  1.2986,  ...,  0.4291, -0.7264,  1.0962],
        [-0.0456, -0.0433, -0.3571,  ...,  0.0131,  0.3755,  0.2974],
        [-0.4183,  0.1344, -0.5244,  ..., -0.0383,  0.3907,  0.1019],
        ...,
        [ 0.4592, -0.0442, -0.3416,  ...,  0.6930, -0.1248,  1.1393],
        [-1.1838,  0.5513,  0.2055,  ..., -0.4299, -0.7415, -0.0049],
        [-0.1825, -0.4079,  0.1608,  ...,  0.2527, -0.3362,  0.8228]]), obj_idxes: tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -2]), matched_gt_idxes: tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1]), disappear_time: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), iou: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), scores: tensor([1.2134e-03, 6.2523e-02, 3.5854e-02, 2.3008e-03, 1.1493e-03, 1.1479e-02,
        1.6889e-02, 2.7017e-02, 4.1991e-03, 3.1803e-03, 1.4656e-02, 4.7814e-03,
        2.1172e-02, 3.6873e-01, 6.2139e-03, 3.8186e-03, 1.2621e-02, 4.0460e-02,
        3.7893e-02, 3.4594e-03, 4.9484e-03, 9.8611e-04, 2.1758e-02, 5.3686e-02,
        2.1225e-02, 3.4493e-02, 2.8313e-03, 1.5702e-03, 1.4362e-02, 2.7795e-02,
        4.6897e-02, 7.2637e-03, 2.7099e-02, 1.4972e-02, 3.9342e-03, 2.4330e-02,
        9.3692e-03, 6.4523e-02, 5.1957e-02, 9.3188e-03, 6.6445e-02, 8.2580e-02,
        3.8335e-03, 6.9467e-03, 3.4724e-02, 5.2116e-03, 8.9579e-02, 6.2508e-02,
        5.2185e-02, 9.1465e-03, 2.8851e-02, 5.1593e-03, 1.0974e-01, 3.9678e-03,
        2.8626e-02, 2.6586e-02, 8.3299e-03, 5.2649e-02, 5.3267e-03, 6.4704e-03,
        3.9233e-03, 1.5086e-02, 6.7448e-02, 6.6768e-03, 1.6665e-02, 6.9540e-02,
        2.5125e-02, 3.6785e-02, 5.8670e-03, 7.5140e-03, 1.2913e-02, 3.6196e-02,
        8.6278e-03, 7.7499e-03, 6.9070e-02, 3.8398e-02, 1.3969e-02, 1.1849e-03,
        8.7286e-03, 8.0405e-03, 6.5666e-03, 1.3306e-01, 4.7247e-03, 3.9266e-02,
        5.0965e-03, 7.2163e-03, 5.7265e-02, 3.8921e-02, 1.6542e-02, 1.4544e-01,
        1.4110e-01, 8.5508e-03, 3.6722e-02, 1.1033e-03, 9.6849e-04, 1.3027e-01,
        6.2588e-04, 5.8292e-03, 1.6276e-02, 5.5910e-03, 1.1736e-02, 2.3894e-02,
        5.0752e-03, 6.0627e-02, 1.2194e-02, 4.0648e-03, 2.2797e-02, 1.6678e-02,
        3.1925e-03, 4.7256e-02, 7.4789e-02, 8.4010e-01, 5.7277e-03, 2.7151e-02,
        1.0818e-01, 4.1882e-02, 1.9956e-03, 4.3114e-02, 7.3796e-03, 1.1827e-02,
        3.1510e-02, 8.1394e-02, 5.5510e-02, 2.3008e-02, 3.7469e-03, 1.6620e-02,
        1.1137e-02, 4.6571e-03, 6.4330e-03, 6.4549e-02, 1.4618e-01, 2.0940e-02,
        2.4190e-02, 6.6831e-02, 8.4846e-04, 7.3563e-03, 4.9336e-03, 1.4138e-03,
        1.2344e-03, 6.2734e-02, 8.6931e-03, 6.2626e-03, 2.2344e-02, 5.7888e-02,
        6.1706e-02, 2.5208e-02, 9.7907e-04, 2.8844e-03, 9.5125e-03, 1.2403e-02,
        1.1536e-02, 1.6938e-02, 3.4666e-02, 5.2722e-03, 2.4653e-02, 4.4650e-03,
        7.2293e-03, 1.3935e-02, 6.5360e-02, 1.1119e-03, 2.4714e-03, 1.4973e-02,
        2.6434e-03, 2.1652e-03, 1.2158e-02, 6.7462e-03, 1.9515e-02, 2.4495e-02,
        3.6428e-02, 2.1267e-02, 3.1087e-02, 1.9324e-02, 4.9264e-03, 1.2190e-02,
        3.7031e-02, 1.6408e-03, 1.8139e-02, 1.3024e-03, 1.2271e-03, 1.2923e-02,
        7.4022e-03, 5.7929e-03, 1.0363e-02, 1.2676e-03, 1.0056e-02, 1.1427e-02,
        7.5995e-02, 3.9850e-03, 6.6336e-03, 1.4071e-03, 6.7100e-03, 5.1421e-02,
        1.3440e-03, 6.4037e-02, 1.2116e-02, 4.6018e-02, 4.9342e-02, 5.1683e-03,
        1.9097e-02, 1.5111e-02, 3.0793e-02, 7.4207e-03, 2.6880e-02, 3.5225e-03,
        1.1567e-02, 1.4508e-03, 1.6973e-02, 6.1134e-03, 4.1442e-02, 1.0759e-02,
        6.6415e-02, 4.8017e-02, 6.6356e-03, 1.5206e-03, 1.2363e-03, 4.3600e-02,
        3.9149e-02, 1.9085e-02, 1.5656e-02, 2.7196e-02, 1.1147e-03, 1.6049e-01,
        5.6968e-02, 5.2893e-03, 4.0854e-02, 1.6607e-01, 3.7793e-03, 9.2531e-03,
        5.4123e-02, 1.1974e-02, 1.3448e-03, 2.4931e-02, 1.3381e-02, 1.2397e-02,
        3.0968e-02, 3.7141e-02, 4.5333e-02, 1.1147e-02, 2.6424e-02, 4.2933e-02,
        5.2535e-03, 1.1537e-02, 6.0293e-03, 3.8656e-02, 1.0428e-02, 6.7816e-03,
        5.7107e-02, 1.0390e-01, 3.6373e-03, 4.7635e-03, 6.8706e-03, 2.4473e-02,
        5.5701e-03, 9.1752e-04, 3.1969e-03, 4.2385e-03, 4.7782e-03, 1.3262e-03,
        2.7159e-02, 1.6284e-02, 1.0323e-02, 4.7396e-02, 4.2747e-02, 3.8807e-02,
        7.0219e-03, 4.5195e-02, 2.4153e-02, 5.1583e-02, 7.8921e-03, 1.0167e-02,
        1.5030e-02, 2.6144e-02, 6.5438e-03, 4.0822e-02, 1.0016e-03, 9.4240e-03,
        3.8219e-02, 8.1689e-03, 5.1255e-02, 9.5637e-03, 1.3022e-03, 2.5308e-03,
        1.0544e-02, 2.3149e-02, 8.2537e-03, 1.2807e-02, 1.0644e-02, 5.5866e-02,
        8.2002e-03, 9.8223e-02, 1.1481e-03, 3.2006e-02, 4.2788e-02, 4.7632e-03,
        9.0154e-02, 8.6585e-03, 3.0511e-03, 6.2478e-03, 8.3633e-03, 5.2223e-03,
        7.2684e-03, 1.4663e-02, 4.0191e-03, 7.4031e-03, 9.1275e-03, 1.2543e-02,
        2.3229e-02, 1.3753e-03, 5.9674e-02, 3.3736e-02, 4.8074e-02, 4.1207e-02,
        9.5094e-02, 1.2115e-02, 1.6038e-02, 8.3455e-03, 3.7825e-02, 6.7053e-03,
        1.0765e-03, 1.7989e-02, 5.3714e-03, 8.1112e-03, 3.5229e-02, 2.2709e-02,
        1.4656e-01, 1.1850e-02, 2.6655e-02, 6.5880e-03, 6.8146e-03, 6.6188e-02,
        5.6035e-03, 9.2401e-03, 4.9330e-02, 1.1847e-03, 7.3345e-02, 3.6133e-02,
        8.9987e-01, 4.9836e-02, 8.0589e-02, 4.1223e-03, 6.2678e-02, 1.2009e-01,
        3.9707e-03, 1.8302e-02, 2.6263e-01, 4.8747e-02, 3.4416e-02, 1.4222e-02,
        1.6961e-03, 8.5399e-03, 5.1251e-03, 5.7892e-02, 8.2813e-03, 1.4120e-02,
        1.2153e-03, 3.0682e-02, 5.2534e-02, 3.1185e-03, 5.3804e-03, 2.1879e-02,
        1.0233e-02, 3.4845e-02, 5.0240e-02, 6.6517e-03, 5.5033e-02, 9.9240e-02,
        5.8001e-03, 3.6543e-03, 3.5133e-02, 1.5622e-02, 7.5054e-02, 6.2472e-02,
        7.9391e-03, 6.3959e-02, 2.9504e-02, 6.9829e-02, 1.1694e-02, 9.7521e-02,
        4.1910e-02, 1.6028e-02, 1.5102e-01, 7.6756e-02, 5.6412e-02, 6.7188e-03,
        5.6265e-03, 4.2931e-03, 3.5824e-03, 1.1934e-02, 2.5243e-02, 1.5601e-02,
        9.1454e-03, 9.2640e-03, 1.2290e-03, 4.8899e-03, 1.6706e-03, 5.1655e-03,
        3.5898e-03, 1.1129e-02, 4.1541e-02, 5.8084e-03, 1.7909e-02, 5.2201e-03,
        1.2108e-02, 1.8057e-03, 4.9781e-02, 3.7611e-02, 3.1539e-02, 1.0157e-02,
        1.1005e-03, 3.7674e-02, 9.4846e-04, 1.3821e-02, 1.5579e-03, 4.8643e-02,
        7.5679e-03, 4.9013e-03, 1.1422e-03, 1.2696e-01, 1.9293e-02, 1.9225e-02,
        6.2625e-03, 6.8183e-03, 6.1910e-02, 5.0084e-03, 4.9455e-02, 5.0841e-02,
        2.5227e-02, 2.1574e-02, 3.6100e-02, 2.7357e-02, 4.2781e-02, 3.4200e-02,
        7.3570e-03, 1.1011e-02, 7.6662e-02, 1.3262e-02, 3.2418e-02, 1.4014e-02,
        9.6086e-03, 1.6986e-02, 4.6768e-02, 2.1747e-03, 3.5014e-02, 2.0059e-02,
        2.3717e-02, 2.0145e-02, 2.8579e-02, 3.5022e-03, 9.9863e-04, 4.2501e-02,
        2.5523e-02, 4.8021e-03, 1.2995e-02, 4.5505e-03, 2.9458e-02, 1.3647e-02,
        2.3899e-02, 1.0175e-02, 3.2205e-02, 3.4850e-03, 1.0634e-03, 1.1630e-02,
        7.9688e-03, 1.4233e-01, 2.2008e-02, 1.6555e-03, 4.5813e-02, 1.1434e-03,
        1.1137e-02, 1.3660e-02, 2.5831e-02, 3.4862e-02, 4.6683e-03, 2.3943e-02,
        7.4350e-03, 4.2919e-02, 2.1815e-02, 1.1046e-02, 8.6327e-03, 2.1631e-02,
        9.6153e-03, 1.0895e-01, 8.7908e-03, 1.9043e-02, 3.9042e-02, 2.6306e-02,
        3.4800e-03, 4.7643e-02, 6.1349e-03, 1.0257e-02, 5.8688e-03, 1.4184e-02,
        1.6281e-02, 7.4497e-03, 9.5034e-04, 3.2814e-02, 4.1897e-02, 2.1638e-02,
        9.9387e-03, 9.2697e-03, 5.0314e-02, 1.2052e-03, 1.4283e-02, 1.4066e-02,
        5.3169e-02, 1.4760e-02, 1.2717e-02, 2.0727e-02, 2.0729e-02, 1.3156e-02,
        1.6902e-02, 6.2680e-03, 6.2336e-03, 1.5705e-02, 7.7093e-02, 1.6454e-02,
        4.2099e-03, 7.0141e-02, 1.2030e-02, 3.5844e-02, 1.3685e-02, 4.8726e-03,
        8.7846e-03, 9.5205e-03, 3.2727e-03, 1.2507e-01, 6.3954e-03, 1.8167e-02,
        3.7289e-03, 9.2284e-03, 3.8752e-03, 2.6565e-03, 2.6234e-03, 1.2883e-03,
        7.1558e-03, 2.7902e-02, 2.3973e-02, 4.2808e-02, 2.2890e-02, 1.3514e-02,
        8.4640e-03, 5.5918e-03, 7.9391e-03, 6.8766e-03, 9.4866e-03, 8.0524e-03,
        1.4649e-02, 4.7029e-03, 4.3191e-03, 2.5143e-02, 1.0017e-02, 9.3041e-04,
        2.1764e-02, 1.6214e-02, 5.6475e-03, 5.7276e-03, 1.1524e-02, 1.2925e-02,
        1.0318e-02, 2.3928e-03, 2.6898e-03, 1.0364e-01, 8.2849e-03, 4.2610e-03,
        1.4148e-01, 3.6718e-03, 1.7754e-02, 1.3446e-02, 7.2389e-03, 8.3923e-03,
        1.3773e-02, 2.9674e-02, 2.6754e-02, 9.5184e-03, 3.2540e-03, 7.8509e-04,
        4.3543e-02, 4.2098e-02, 9.8746e-04, 1.1894e-02, 4.3983e-03, 4.8268e-02,
        1.3743e-02, 6.1215e-04, 1.3224e-02, 1.2323e-02, 4.2154e-02, 2.5367e-02,
        1.6254e-02, 1.3730e-02, 6.4320e-02, 4.1057e-03, 6.7030e-03, 1.6866e-02,
        6.2101e-02, 1.6485e-02, 2.5149e-02, 4.1828e-02, 7.5231e-03, 2.4282e-03,
        3.4044e-03, 4.8306e-03, 2.4965e-02, 3.4466e-02, 1.4917e-02, 1.3371e-02,
        2.1824e-02, 1.1339e-03, 6.6276e-03, 1.2884e-02, 4.6933e-02, 4.4922e-02,
        5.5381e-03, 1.2710e-02, 4.4529e-02, 2.3726e-02, 3.8491e-02, 1.4928e-02,
        2.8750e-02, 2.4997e-03, 1.4293e-03, 1.4469e-02, 1.2889e-02, 1.2198e-02,
        3.1700e-03, 1.2895e-03, 6.8457e-02, 2.9942e-02, 1.3678e-02, 1.1382e-02,
        3.1289e-02, 1.6485e-03, 3.9063e-02, 8.6605e-01, 2.9481e-02, 8.5971e-03,
        2.4789e-01, 7.0986e-03, 5.5425e-03, 7.1797e-03, 8.5298e-02, 4.7958e-02,
        1.8968e-02, 8.1707e-03, 5.9681e-03, 2.8397e-02, 2.0292e-02, 5.9120e-03,
        1.1771e-03, 2.0855e-02, 2.0247e-02, 8.6334e-03, 7.0641e-03, 8.1918e-03,
        9.3954e-03, 8.2024e-02, 2.2804e-03, 1.1885e-01, 2.5871e-02, 5.7722e-03,
        1.5079e-02, 5.9215e-02, 3.9772e-03, 2.1827e-02, 1.2483e-02, 7.7384e-03,
        6.8899e-02, 1.0509e-02, 1.6041e-02, 1.4781e-03, 3.0236e-02, 3.8648e-02,
        2.0800e-03, 9.3104e-03, 1.4078e-02, 2.0105e-03, 6.4797e-03, 5.8823e-02,
        2.2588e-01, 1.3489e-02, 4.4152e-02, 6.9509e-02, 3.3535e-02, 8.8430e-03,
        5.5192e-03, 6.5108e-03, 6.0700e-03, 2.3320e-02, 3.8966e-02, 2.7285e-02,
        1.6611e-03, 7.4567e-03, 3.0014e-02, 1.0790e-03, 1.0670e-02, 2.3976e-02,
        7.9866e-03, 1.9947e-02, 3.6452e-02, 2.0288e-02, 8.5655e-03, 2.3905e-03,
        7.0432e-03, 4.7897e-02, 4.0366e-02, 9.3588e-03, 5.6001e-03, 5.6697e-03,
        2.7458e-02, 1.4447e-02, 5.3912e-03, 9.4531e-03, 1.7389e-02, 1.5690e-02,
        5.1908e-03, 2.7225e-02, 7.7876e-03, 6.9681e-03, 3.2093e-03, 3.8725e-02,
        4.3201e-03, 1.0264e-02, 1.1616e-02, 8.6118e-02, 6.7074e-03, 4.5637e-03,
        9.0264e-03, 7.3751e-03, 2.8856e-02, 1.7818e-02, 3.6863e-02, 1.2164e-02,
        6.8021e-03, 9.1666e-03, 3.8805e-03, 1.2022e-02, 5.3499e-03, 2.3527e-03,
        7.1392e-03, 2.2741e-03, 1.1849e-03, 1.8058e-02, 4.9544e-03, 1.0407e-02,
        6.3434e-02, 7.7950e-03, 5.3718e-02, 8.5043e-03, 1.8742e-02, 3.7175e-03,
        3.4874e-02, 1.5555e-02, 3.5836e-02, 7.2156e-03, 4.0224e-02, 1.1971e-02,
        1.5522e-01, 1.3716e-01, 2.7829e-02, 7.1587e-03, 5.9096e-03, 3.8481e-02,
        4.1408e-02, 1.1290e-01, 1.0321e-03, 8.1784e-02, 2.3073e-03, 3.0509e-02,
        2.5704e-02, 3.5071e-02, 1.5234e-03, 5.5836e-03, 3.0906e-02, 1.9596e-03,
        1.8160e-02, 1.7222e-02, 2.1589e-03, 4.1568e-03, 1.4273e-02, 7.8894e-02,
        3.0986e-03, 2.0555e-02, 7.5576e-03, 1.7354e-02, 6.7544e-03, 1.1260e-03,
        3.3693e-02, 1.6364e-03, 2.9528e-02, 2.8759e-02, 1.3075e-02, 3.5391e-03,
        7.9627e-03, 5.4334e-02, 1.2412e-02, 4.3285e-03, 9.7642e-02, 8.2015e-03,
        2.4233e-02, 2.2819e-02, 1.0958e-03, 2.8139e-03, 5.0963e-02, 3.4218e-03,
        9.4313e-03, 3.9315e-02, 4.9605e-02, 1.0425e-01, 2.3686e-03, 5.0026e-02,
        7.7612e-03, 5.4702e-03, 7.4165e-03, 1.3946e-03, 4.2023e-02, 1.6111e-02,
        2.4136e-02, 8.0160e-03, 1.0436e-03, 4.6804e-03, 2.0107e-03, 1.7419e-02,
        8.8171e-03, 6.5201e-03, 8.7014e-03, 7.4491e-02, 3.7844e-02, 5.1229e-02,
        6.2621e-02, 7.2930e-03, 6.8501e-02, 5.1532e-02, 1.8383e-02, 1.2483e-03,
        5.3616e-02, 1.3578e-02, 2.3480e-02, 2.9433e-02, 1.5497e-03, 1.9143e-02,
        4.4572e-02, 3.2648e-02, 6.3635e-03, 5.6019e-03, 7.2052e-02, 3.3516e-02,
        1.1562e-03, 1.0537e-03, 1.0457e-02, 2.8388e-03, 1.9056e-02, 6.6741e-03,
        6.4513e-03, 5.7186e-03, 1.0832e-02, 6.3372e-02, 1.3298e-01, 1.7387e-02,
        3.6845e-02, 1.3048e-03, 8.4211e-03, 4.9586e-02, 5.9509e-02, 1.6831e-02,
        4.2773e-03, 4.2043e-02, 5.1998e-03, 1.4899e-02, 8.1630e-03, 2.6650e-02,
        4.8746e-03, 6.2005e-03, 4.2179e-02, 6.4319e-03, 2.8676e-02, 6.1934e-03,
        5.1957e-03, 3.4885e-02, 3.0818e-02, 2.3451e-02, 1.1838e-02, 9.3603e-03,
        6.1641e-02, 6.0797e-03, 3.9582e-03, 5.2156e-02, 2.8057e-03, 2.6650e-02,
        1.9928e-03, 2.5077e-02, 7.7074e-04, 9.9252e-04, 1.8732e-02, 1.1438e-03,
        1.2189e-01, 5.4555e-03, 1.0569e-01, 2.4203e-03, 6.2680e-03, 1.5034e-02,
        4.0580e-01]), track_scores: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), pred_boxes: tensor([[-4.6363e-01,  1.5860e+01,  3.4261e-01,  ..., -7.5941e-01,
          4.1765e-03,  1.0221e-04],
        [-2.5999e+01,  2.0453e+01,  7.6815e-01,  ..., -2.4500e-01,
         -8.4732e-04,  1.3136e-03],
        [ 3.0206e+01,  6.1731e+00,  7.0703e-01,  ..., -3.4799e-01,
         -8.1343e-04, -5.1993e-04],
        ...,
        [-2.4058e+00,  2.4745e+01,  6.4873e-01,  ...,  4.1019e-01,
          8.7779e-04,  3.3310e-04],
        [ 2.8178e+01,  4.8182e+01,  7.3901e-01,  ..., -3.3784e-01,
          6.6150e-04, -5.3343e-03],
        [ 3.1940e-02, -6.2492e-02,  5.5435e-01,  ..., -9.9405e-01,
         -1.7210e-01,  6.9688e+00]]), pred_logits: tensor([[ -7.8005,  -9.2291, -10.3650,  ...,  -8.7853,  -7.8331,  -6.7131],
        [ -2.9977,  -2.7077,  -3.0400,  ...,  -5.0790,  -4.6607,  -4.8856],
        [ -3.2918,  -4.1178,  -4.6904,  ...,  -6.0773,  -4.4435,  -5.3701],
        ...,
        [ -5.0660,  -5.8891,  -6.7540,  ...,  -6.7987,  -6.7486,  -7.4395],
        [ -4.7776,  -5.3053,  -5.1385,  ...,  -6.4729,  -4.1823,  -6.3856],
        [ -0.3814,  -5.0945,  -5.5865,  ...,  -7.4560,  -4.3447,  -5.7929]]), mem_bank: tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.6297, -0.2389, -0.0543,  ..., -1.3331,  0.2644,  0.4980]],

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.4326,  0.2157,  0.5255,  ...,  0.7514, -0.2508,  0.5009]],

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.2984, -0.1301, -0.0033,  ..., -0.1002, -0.8986,  0.0752]],

        ...,

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.2986, -0.0864,  0.2624,  ...,  0.0460,  0.3023,  0.9572]],

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.7214,  0.1568,  0.6823,  ...,  0.5216, -0.5148,  0.0282]],

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.3801,  0.3509,  1.8601,  ...,  0.6641,  0.3705,  0.6558]]]), mem_padding_mask: tensor([[ True,  True,  True, False],
        [ True,  True,  True, False],
        [ True,  True,  True, False],
        ...,
        [ True,  True,  True, False],
        [ True,  True,  True, False],
        [ True,  True,  True, False]]), save_period: tensor([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3.])])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(835)_det_instances2results()
-> bboxes_dict = self.bbox_coder.decode(bbox_dict, img_metas=img_metas)[0]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(152)decode()
-> predictions_list.append(self.decode_single(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(57)decode_single()
-> max_num = self.max_num
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(58)decode_single()
-> max_num = min(cls_scores.size(0), self.max_num)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(60)decode_single()
-> cls_scores = cls_scores.sigmoid()
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(61)decode_single()
-> _, indexs = cls_scores.max(dim=-1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(62)decode_single()
-> labels = indexs % self.num_classes
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(64)decode_single()
-> _, bbox_index = track_scores.topk(max_num)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(66)decode_single()
-> labels = labels[bbox_index]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(67)decode_single()
-> bbox_preds = bbox_preds[bbox_index]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(68)decode_single()
-> track_scores = track_scores[bbox_index]
(Pdb) torch.Size([300])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(69)decode_single()
-> obj_idxes = obj_idxes[bbox_index]
(Pdb) tensor([336, 633, 111, 900,  13, 344, 636, 678, 225, 221, 756, 380, 324, 130,
         89, 463, 564,  90, 757,  81, 856,  95, 417, 525, 894, 341, 657, 763,
         52, 481, 114, 896, 807, 247, 561, 365, 289, 796, 377, 312, 294,  46,
        723, 640,  41, 655, 765, 121, 338, 779, 514, 381, 434, 186, 370, 110,
        825, 334, 844, 517, 375,  65, 681,  74, 666, 830, 626,  62, 133,  40,
        210, 329, 158, 129,  37, 590, 193, 373, 744, 855, 139, 340, 828,   1,
         47, 371, 594, 422, 144, 882, 103, 308, 862, 661, 677, 351, 143,  86,
        246, 222, 382, 287, 122, 364, 793, 228, 746,  23, 834, 504,  57, 356,
         48, 885,  38, 267, 831, 191, 278, 827, 802, 425, 500, 362, 809, 337,
        404, 806, 861, 424, 196, 332, 345, 413, 581, 310, 211, 641, 703, 487,
        261, 109, 610,  30, 440, 195, 466, 236, 265, 611, 840, 614, 680, 215,
        576, 117, 239, 475, 537, 292, 430, 262, 449, 872, 586, 577, 865, 814,
        378, 496, 115, 597, 398, 208, 762, 311, 224, 273,  17, 704, 754, 805,
         83, 216, 632, 484, 688,  87, 263, 719, 243, 671, 616, 761,  75, 276,
         18, 826, 316, 409, 405, 235, 174, 730, 858,  67,  92, 698, 168,  71,
        335, 428,   2, 519, 752, 322, 368, 769, 442, 877, 750, 471, 361,  44,
        152,  25, 603, 346, 431, 309, 786, 682, 845, 495, 841, 436, 458, 291,
        406, 120, 630, 170, 234, 772, 878, 200, 355, 767, 670, 692, 627, 571,
        788, 374, 634, 454, 837, 728,  50, 789, 618, 874,  54, 446, 645, 535,
        758,  29, 708, 429, 689, 715, 219, 258, 113,  32,   7, 202, 572, 326,
        887, 869,  55, 238, 485, 271, 658, 470, 768, 450, 587, 388, 426, 145,
        596, 549,  66, 889, 602, 231])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(71)decode_single()
-> scores = track_scores
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(73)decode_single()
-> final_box_preds = denormalize_bbox(bbox_preds, self.pc_range)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(74)decode_single()
-> final_scores = track_scores
(Pdb) torch.Size([300, 9])
(Pdb) *** NameError: name 'bbox_pred' is not defined
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(152)decode()
-> predictions_list.append(self.decode_single(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(74)decode_single()
-> final_scores = track_scores
(Pdb)  69  	        obj_idxes = obj_idxes[bbox_index]
 70  	
 71  	        scores = track_scores
 72  	
 73  	        final_box_preds = denormalize_bbox(bbox_preds, self.pc_range)
 74  ->	        final_scores = track_scores
 75  	        final_preds = labels
 76  	
 77  	        # use score threshold
 78  	        if self.score_threshold is not None:
 79  	            thresh_mask = final_scores > self.score_threshold
(Pdb) torch.Size([300, 10])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(152)decode()
-> predictions_list.append(self.decode_single(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(835)_det_instances2results()
-> bboxes_dict = self.bbox_coder.decode(bbox_dict, img_metas=img_metas)[0]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(777)simple_test_track()
-> results = self._det_instances2results(track_instances_fordet, results, img_metas)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(292)forward_test()
-> result_track = self.simple_test_track(img, l2g_t, l2g_r_mat, img_metas, timestamp)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(777)simple_test_track()
-> results = self._det_instances2results(track_instances_fordet, results, img_metas)
(Pdb) Instances(num_instances=904, image_height=1, image_width=1, fields=[ref_pts: tensor([[ 0.0873,  0.7337, -0.0045],
        [-1.0938,  0.9581, -0.0067],
        [ 1.6437,  0.2710, -0.0953],
        ...,
        [-0.1737, -0.4143, -0.4898],
        [-0.0294, -1.0461, -0.6533],
        [-0.4897,  1.7039,  0.0219]]), query: tensor([[ 0.9794,  1.4678,  2.2049,  ..., -0.8909, -0.0528, -0.0377],
        [-0.1857,  0.0648, -0.3255,  ...,  0.8429,  0.9830,  1.0372],
        [ 0.9206, -2.1922, -1.2307,  ..., -0.6641, -0.4396,  1.1959],
        ...,
        [-0.2811,  0.2311,  0.3120,  ...,  0.5009,  0.5522,  1.2820],
        [ 0.2085,  0.1125,  0.4716,  ...,  0.8579, -0.2597,  0.8865],
        [ 0.2643,  0.3359,  0.2067,  ...,  0.2732, -0.6491,  0.4089]]), output_embedding: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.7269,  0.3169, -0.3318,  ...,  0.5516, -0.5739,  0.2653],
        [ 0.3517, -0.3560, -0.0971,  ...,  0.4976, -0.8458,  0.1177],
        [-0.8541, -0.0137, -0.5999,  ...,  0.0939, -0.4618,  0.3946]]), obj_idxes: tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1,  0,  1,  2]), matched_gt_idxes: tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1]), disappear_time: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), iou: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), scores: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.8401, 0.8999, 0.8660]), track_scores: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), pred_boxes: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-4.4362e+00, -1.0457e+01, -5.7496e-01,  ...,  9.9731e-01,
         -1.2011e-03, -9.9059e-04],
        [-7.5262e-01, -2.4579e+01,  6.6525e-01,  ..., -9.8844e-01,
          8.8571e-02,  5.5166e+00],
        [-1.2292e+01,  3.5435e+01, -3.3134e-01,  ..., -9.8280e-01,
         -2.9149e-01,  1.2141e+00]]), pred_logits: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-6.4774, -8.0849, -7.5573,  ...,  1.6590, -5.5511, -4.6095],
        [ 2.1958, -6.2505, -7.5734,  ..., -9.5285, -7.1040, -6.2322],
        [-8.0861, -7.3184, -7.0678,  ..., -5.5766,  1.8664, -5.3478]]), mem_bank: tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        ...,

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.5029, -0.2620,  0.0386,  ...,  0.0127,  0.3238, -0.2907]],

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.2549,  0.2009,  0.5347,  ...,  0.1464,  0.1376,  0.4046]],

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.2789, -0.3221,  0.8840,  ...,  0.7337,  0.1182,  0.8018]]]), mem_padding_mask: tensor([[ True,  True,  True,  True],
        [ True,  True,  True,  True],
        [ True,  True,  True,  True],
        ...,
        [ True,  True,  True, False],
        [ True,  True,  True, False],
        [ True,  True,  True, False]]), save_period: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 3., 3., 3.])])
(Pdb) torch.Size([904, 512])
(Pdb) torch.Size([904])
(Pdb) tensor([-1,  0,  1,  2])
(Pdb) torch.Size([904, 10])
(Pdb) tensor([[-4.4362e+00, -1.0457e+01, -5.7496e-01,  5.4815e-01, -1.9604e+00,
          8.2555e-02,  2.6890e-02,  9.9731e-01, -1.2011e-03, -9.9059e-04],
        [-7.5262e-01, -2.4579e+01,  6.6525e-01,  1.5121e+00, -2.2621e+00,
          4.3397e-01, -1.8351e-02, -9.8844e-01,  8.8571e-02,  5.5166e+00],
        [-1.2292e+01,  3.5435e+01, -3.3134e-01, -2.0525e-01, -9.5619e-01,
          5.5846e-01,  1.1792e-01, -9.8280e-01, -2.9149e-01,  1.2141e+00]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(835)_det_instances2results()
-> bboxes_dict = self.bbox_coder.decode(bbox_dict, img_metas=img_metas)[0]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(152)decode()
-> predictions_list.append(self.decode_single(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(74)decode_single()
-> final_scores = track_scores
(Pdb) *** Newest frame
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(75)decode_single()
-> final_preds = labels
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(78)decode_single()
-> if self.score_threshold is not None:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(79)decode_single()
-> thresh_mask = final_scores > self.score_threshold
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(81)decode_single()
-> if self.with_nms:
(Pdb) torch.Size([300])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(94)decode_single()
-> if self.post_center_range is not None:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(95)decode_single()
-> self.post_center_range = torch.tensor(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(96)decode_single()
-> self.post_center_range, device=scores.device)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(95)decode_single()
-> self.post_center_range = torch.tensor(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(97)decode_single()
-> mask = (final_box_preds[..., :3] >=
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(98)decode_single()
-> self.post_center_range[:3]).all(1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(97)decode_single()
-> mask = (final_box_preds[..., :3] >=
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(98)decode_single()
-> self.post_center_range[:3]).all(1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(97)decode_single()
-> mask = (final_box_preds[..., :3] >=
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(99)decode_single()
-> mask &= (final_box_preds[..., :3] <=
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(100)decode_single()
-> self.post_center_range[3:]).all(1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(99)decode_single()
-> mask &= (final_box_preds[..., :3] <=
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(100)decode_single()
-> self.post_center_range[3:]).all(1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(99)decode_single()
-> mask &= (final_box_preds[..., :3] <=
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(102)decode_single()
-> if self.score_threshold:
(Pdb) torch.Size([300])
(Pdb) tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(104)decode_single()
-> if not with_mask:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(106)decode_single()
-> if self.with_nms:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(109)decode_single()
-> boxes3d = final_box_preds[mask]
(Pdb) torch.Size([300, 9])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(110)decode_single()
-> scores = final_scores[mask]
(Pdb) torch.Size([300, 9])
(Pdb) torch.Size([300, 9])
(Pdb) tensor([[-7.5262e-01, -2.4579e+01, -2.2621e+00,  1.9450e+00,  4.5364e+00,
          1.5434e+00, -3.1230e+00,  8.8571e-02,  5.5166e+00],
        [-1.2292e+01,  3.5435e+01, -9.5619e-01,  7.1796e-01,  8.1444e-01,
          1.7480e+00,  3.0222e+00, -2.9149e-01,  1.2141e+00],
        [-4.4362e+00, -1.0457e+01, -1.9604e+00,  5.6273e-01,  1.7301e+00,
          1.0861e+00,  2.6956e-02, -1.2011e-03, -9.9059e-04]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(111)decode_single()
-> labels = final_preds[mask]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(112)decode_single()
-> track_scores = track_scores[mask]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(113)decode_single()
-> obj_idxes = obj_idxes[mask]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(115)decode_single()
-> 'bboxes': boxes3d,
(Pdb) torch.Size([300])
(Pdb) tensor([1, 2, 0])
(Pdb) tensor([ 1,  2,  0, -2, -1, -1, -1, -1, -1, -1])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(116)decode_single()
-> 'scores': scores,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(117)decode_single()
-> 'labels': labels,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(118)decode_single()
-> 'track_scores': track_scores,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(119)decode_single()
-> 'obj_idxes': obj_idxes,
(Pdb) tensor([[-7.5262e-01, -2.4579e+01, -2.2621e+00,  1.9450e+00,  4.5364e+00,
          1.5434e+00, -3.1230e+00,  8.8571e-02,  5.5166e+00],
        [-1.2292e+01,  3.5435e+01, -9.5619e-01,  7.1796e-01,  8.1444e-01,
          1.7480e+00,  3.0222e+00, -2.9149e-01,  1.2141e+00],
        [-4.4362e+00, -1.0457e+01, -1.9604e+00,  5.6273e-01,  1.7301e+00,
          1.0861e+00,  2.6956e-02, -1.2011e-03, -9.9059e-04],
        [ 3.1940e-02, -6.2492e-02, -7.7301e-01,  1.7408e+00,  4.1469e+00,
          1.5712e+00, -3.1400e+00, -1.7210e-01,  6.9688e+00]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py(152)decode()
-> predictions_list.append(self.decode_single(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(835)_det_instances2results()
-> bboxes_dict = self.bbox_coder.decode(bbox_dict, img_metas=img_metas)[0]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(777)simple_test_track()
-> results = self._det_instances2results(track_instances_fordet, results, img_metas)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(292)forward_test()
-> result_track = self.simple_test_track(img, l2g_t, l2g_r_mat, img_metas, timestamp)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(777)simple_test_track()
-> results = self._det_instances2results(track_instances_fordet, results, img_metas)
(Pdb) 772  	                    "track_query_embeddings", "track_bbox_results",
773  	                    "boxes_3d", "scores_3d", "labels_3d", "track_scores", "track_ids"]
774  	        if self.with_motion_head:
775  	            get_keys += ["sdc_boxes_3d", "sdc_scores_3d", "sdc_track_scores", "sdc_track_bbox_results", "sdc_embedding"]
776  	        results[0].update({k: frame_res[k] for k in get_keys})
777  ->	        results = self._det_instances2results(track_instances_fordet, results, img_metas)
778  	        return results
779  	
780  	    def _track_instances2results(self, track_instances, img_metas, with_mask=True):
781  	        bbox_dict = dict(
782  	            cls_scores=track_instances.pred_logits,
(Pdb) LiDARInstance3DBoxes(
    tensor([[ 0.0319, -0.0625, -0.7730,  1.7408,  4.1469,  1.5712, -3.1400, -0.1721,
          6.9688]]))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(778)simple_test_track()
-> return results
(Pdb) --Return--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(778)simple_test_track()->[{'bev_embed': tensor([[[-0....6, -0.1223]]]), 'bev_pos': tensor([[[[ 1...,  0.1637]]]]), 'boxes_3d': LiDARInstance...9.9059e-04]])), 'boxes_3d_det': LiDARInstance...2.4743e-03]])), ...}]
-> return results
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(294)forward_test()
-> import pdb; pdb.set_trace()
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(297)forward_test()
-> result_track[0] = self.upsample_bev_if_tiny(result_track[0])
(Pdb) *** AttributeError: 'list' object has no attribute 'shape'
(Pdb) 1
(Pdb) dict_keys(['bev_embed', 'bev_pos', 'track_query_embeddings', 'track_bbox_results', 'boxes_3d', 'scores_3d', 'labels_3d', 'track_scores', 'track_ids', 'sdc_boxes_3d', 'sdc_scores_3d', 'sdc_track_scores', 'sdc_track_bbox_results', 'sdc_embedding', 'boxes_3d_det', 'scores_3d_det', 'labels_3d_det'])
(Pdb) *** AttributeError: 'LiDARInstance3DBoxes' object has no attribute 'shape'
(Pdb) *** AttributeError: 'dict' object has no attribute 'boxes_3d_det'
(Pdb) LiDARInstance3DBoxes(
    tensor([[-7.5262e-01, -2.4579e+01, -2.2621e+00,  ..., -3.1230e+00,
          8.8571e-02,  5.5166e+00],
        [-1.2292e+01,  3.5435e+01, -9.5619e-01,  ...,  3.0222e+00,
         -2.9149e-01,  1.2141e+00],
        [-4.4362e+00, -1.0457e+01, -1.9604e+00,  ...,  2.6956e-02,
         -1.2011e-03, -9.9059e-04],
        ...,
        [ 1.8037e+01,  3.3991e+01, -8.9774e-01,  ..., -1.5380e+00,
         -2.2969e-03,  2.4320e-03],
        [-3.1892e+01,  2.3425e+01, -3.6607e-01,  ..., -1.6160e+00,
         -1.5298e-03,  2.2810e-03],
        [ 4.1979e+01, -3.3673e+01, -1.8873e+00,  ..., -2.0587e+00,
          7.7411e-02, -2.4743e-03]]))
(Pdb) torch.Size([300, 9])
(Pdb) tensor([[-7.5262e-01, -2.4579e+01, -2.2621e+00,  1.9450e+00,  4.5364e+00,
          1.5434e+00, -3.1230e+00,  8.8571e-02,  5.5166e+00],
        [-1.2292e+01,  3.5435e+01, -9.5619e-01,  7.1796e-01,  8.1444e-01,
          1.7480e+00,  3.0222e+00, -2.9149e-01,  1.2141e+00],
        [-4.4362e+00, -1.0457e+01, -1.9604e+00,  5.6273e-01,  1.7301e+00,
          1.0861e+00,  2.6956e-02, -1.2011e-03, -9.9059e-04],
        [ 3.1940e-02, -6.2492e-02, -7.7301e-01,  1.7408e+00,  4.1469e+00,
          1.5712e+00, -3.1400e+00, -1.7210e-01,  6.9688e+00]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(83)forward()
-> return self.forward_test(**kwargs)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) > /Users/liangming.xu/code/UniAD/tools/test.py(230)main()
-> result = model(return_loss=False, rescale=True, **data)
(Pdb) {'img_metas': [DataContainer([[{'filename': ['samples/CAM_FRONT/n015-2018-07-11-11-54-16+0800__CAM_FRONT__1531281439762460.jpg', 'samples/CAM_FRONT_RIGHT/n015-2018-07-11-11-54-16+0800__CAM_FRONT_RIGHT__1531281439770339.jpg', 'samples/CAM_FRONT_LEFT/n015-2018-07-11-11-54-16+0800__CAM_FRONT_LEFT__1531281439754844.jpg', 'samples/CAM_BACK/n015-2018-07-11-11-54-16+0800__CAM_BACK__1531281439787525.jpg', 'samples/CAM_BACK_LEFT/n015-2018-07-11-11-54-16+0800__CAM_BACK_LEFT__1531281439797423.jpg', 'samples/CAM_BACK_RIGHT/n015-2018-07-11-11-54-16+0800__CAM_BACK_RIGHT__1531281439777893.jpg'], 'ori_shape': [(900, 1600, 3), (900, 1600, 3), (900, 1600, 3), (900, 1600, 3), (900, 1600, 3), (900, 1600, 3)], 'img_shape': [(928, 1600, 3), (928, 1600, 3), (928, 1600, 3), (928, 1600, 3), (928, 1600, 3), (928, 1600, 3)], 'lidar2img': [array([[ 1.26627559e+03,  8.16148979e+02,  2.34810021e+01,
        -3.18154452e+02],
       [ 8.20197736e+00,  5.15017451e+02, -1.25701292e+03,
        -6.23147848e+02],
       [-1.40386752e-04,  9.99826412e-01,  1.86313382e-02,
        -4.08345062e-01],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         1.00000000e+00]]), array([[ 1.36762656e+03, -6.09329941e+02, -2.93866508e+01,
        -4.88278951e+02],
       [ 4.00515200e+02,  3.02814667e+02, -1.25816665e+03,
        -7.27414947e+02],
       [ 8.35612690e-01,  5.49300529e-01,  4.51244948e-03,
        -5.99209745e-01],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         1.00000000e+00]]), array([[ 5.77311626e+01,  1.51596208e+03,  3.63975328e+01,
        -2.18250397e+02],
       [-3.88930720e+02,  3.06818032e+02, -1.26659495e+03,
        -6.70505207e+02],
       [-8.17283232e-01,  5.76116432e-01,  1.17463061e-02,
        -4.94588509e-01],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         1.00000000e+00]]), array([[-8.14104309e+02, -8.24305561e+02, -1.40809559e+01,
        -8.53779192e+02],
       [ 4.97707025e+00, -4.75681493e+02, -8.12804655e+02,
        -7.22636077e+02],
       [-5.95219763e-03, -9.99953673e-01, -7.56466193e-03,
        -1.02865681e+00],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         1.00000000e+00]]), array([[-1.14927124e+03,  9.41249910e+02,  8.10632934e+00,
        -6.23383802e+02],
       [-4.42325964e+02, -1.14445443e+02, -1.27022717e+03,
        -5.23664062e+02],
       [-9.48288437e-01, -3.16059480e-01, -2.92479827e-02,
        -4.41690327e-01],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         1.00000000e+00]]), array([[ 3.01084167e+02, -1.46414075e+03, -6.05995991e+01,
        -3.57072460e+02],
       [ 4.60790032e+02, -1.29083750e+02, -1.26829887e+03,
        -5.97854268e+02],
       [ 9.33277897e-01, -3.58619863e-01, -1.95999939e-02,
        -5.04299162e-01],
       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
         1.00000000e+00]])], 'pad_shape': [(928, 1600, 3), (928, 1600, 3), (928, 1600, 3), (928, 1600, 3), (928, 1600, 3), (928, 1600, 3)], 'scale_factor': 1.0, 'flip': False, 'pcd_horizontal_flip': False, 'pcd_vertical_flip': False, 'box_type_3d': <class 'projects.mmdet3d_plugin.core.bbox.lidar_box3d.LiDARInstance3DBoxes'>, 'img_norm_cfg': {'mean': array([103.53 , 116.28 , 123.675], dtype=float32), 'std': array([1., 1., 1.], dtype=float32), 'to_rgb': False}, 'sample_idx': '30e55a3ec6184d8cb1944b39ba19d622', 'prev_idx': '', 'next_idx': 'cc18fde20db74d30825b0b60ec511b7b', 'pcd_scale_factor': 1.0, 'pts_filename': '/mnt/petrelfs/yangjiazhi/e2e_proj/data/nuscenes/samples/LIDAR_TOP/n015-2018-07-11-11-54-16+0800__LIDAR_TOP__1531281439800013.pcd.bin', 'scene_token': 'c3ab8ee2c1a54068a72d7eb4cf22e43d', 'can_bus': array([ 7.32061444e+02,  9.49067674e+02,  0.00000000e+00,  4.15899266e-01,
        4.15899266e-01,  4.15899266e-01,  4.15899266e-01,  4.44573660e-01,
        4.35957390e-01,  9.72841627e+00, -8.77811294e-03,  3.47160618e-03,
        8.12374502e-02,  9.18768394e+00,  0.00000000e+00,  0.00000000e+00,
        2.28367239e+00,  1.30844790e+02])}]])], 'img': [DataContainer([tensor([[[[[-37.5300, -37.5300, -37.5300,  ...,  81.4700,  80.4700,
             76.4700],
           [-40.5300, -40.5300, -41.5300,  ...,  83.4700,  81.4700,
             77.4700],
           [-41.5300, -41.5300, -41.5300,  ...,  81.4700,  77.4700,
             72.4700],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[-54.2800, -54.2800, -54.2800,  ...,  64.7200,  63.7200,
             59.7200],
           [-57.2800, -57.2800, -58.2800,  ...,  66.7200,  64.7200,
             60.7200],
           [-55.2800, -55.2800, -55.2800,  ...,  64.7200,  60.7200,
             55.7200],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[-62.6750, -62.6750, -62.6750,  ...,  52.3250,  51.3250,
             47.3250],
           [-65.6750, -65.6750, -66.6750,  ...,  54.3250,  52.3250,
             48.3250],
           [-66.6750, -66.6750, -66.6750,  ...,  52.3250,  48.3250,
             43.3250],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]]],


         [[[104.4700, 108.4700, 116.4700,  ...,  96.4700,  96.4700,
             96.4700],
           [129.4700, 130.4700, 132.4700,  ...,  96.4700,  96.4700,
             96.4700],
           [145.4700, 143.4700, 140.4700,  ...,  96.4700,  95.4700,
             95.4700],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[ 82.7200,  86.7200,  94.7200,  ...,  78.7200,  78.7200,
             78.7200],
           [107.7200, 108.7200, 110.7200,  ...,  78.7200,  78.7200,
             78.7200],
           [123.7200, 121.7200, 118.7200,  ...,  78.7200,  77.7200,
             77.7200],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[ 72.3250,  76.3250,  84.3250,  ...,  68.3250,  68.3250,
             68.3250],
           [ 97.3250,  98.3250, 100.3250,  ...,  68.3250,  68.3250,
             68.3250],
           [113.3250, 111.3250, 108.3250,  ...,  68.3250,  67.3250,
             67.3250],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]]],


         [[[-36.5300, -39.5300, -41.5300,  ..., 148.4700, 148.4700,
            148.4700],
           [-30.5300, -33.5300, -35.5300,  ..., 149.4700, 149.4700,
            149.4700],
           [-26.5300, -29.5300, -33.5300,  ..., 151.4700, 151.4700,
            151.4700],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[-49.2800, -52.2800, -57.2800,  ..., 130.7200, 130.7200,
            130.7200],
           [-43.2800, -46.2800, -51.2800,  ..., 131.7200, 131.7200,
            131.7200],
           [-39.2800, -42.2800, -46.2800,  ..., 133.7200, 133.7200,
            133.7200],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[-62.6750, -65.6750, -69.6750,  ..., 120.3250, 120.3250,
            120.3250],
           [-56.6750, -59.6750, -63.6750,  ..., 121.3250, 121.3250,
            121.3250],
           [-52.6750, -55.6750, -59.6750,  ..., 123.3250, 123.3250,
            123.3250],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]]],


         [[[116.4700, 115.4700, 114.4700,  ..., -43.5300, -43.5300,
            -43.5300],
           [116.4700, 115.4700, 115.4700,  ..., -43.5300, -43.5300,
            -43.5300],
           [116.4700, 116.4700, 115.4700,  ..., -44.5300, -44.5300,
            -45.5300],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[100.7200,  99.7200,  98.7200,  ..., -57.2800, -57.2800,
            -57.2800],
           [100.7200,  99.7200,  99.7200,  ..., -57.2800, -57.2800,
            -57.2800],
           [100.7200, 100.7200,  99.7200,  ..., -58.2800, -58.2800,
            -59.2800],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[ 95.3250,  94.3250,  93.3250,  ..., -68.6750, -68.6750,
            -68.6750],
           [ 95.3250,  94.3250,  94.3250,  ..., -68.6750, -68.6750,
            -68.6750],
           [ 95.3250,  95.3250,  94.3250,  ..., -69.6750, -69.6750,
            -70.6750],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]]],


         [[[-19.5300, -17.5300, -14.5300,  ..., -36.5300, -35.5300,
            -34.5300],
           [ -1.5300,  -0.5300,   0.4700,  ..., -31.5300, -30.5300,
            -30.5300],
           [  3.4700,   3.4700,   3.4700,  ..., -24.5300, -24.5300,
            -24.5300],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[-44.2800, -42.2800, -39.2800,  ..., -60.2800, -59.2800,
            -58.2800],
           [-26.2800, -25.2800, -24.2800,  ..., -55.2800, -54.2800,
            -54.2800],
           [-21.2800, -21.2800, -21.2800,  ..., -46.2800, -46.2800,
            -46.2800],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[-57.6750, -55.6750, -52.6750,  ..., -71.6750, -70.6750,
            -69.6750],
           [-39.6750, -38.6750, -37.6750,  ..., -66.6750, -65.6750,
            -65.6750],
           [-34.6750, -34.6750, -34.6750,  ..., -57.6750, -57.6750,
            -57.6750],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]]],


         [[[-45.5300, -44.5300, -44.5300,  ...,  96.4700,  96.4700,
             96.4700],
           [-44.5300, -44.5300, -43.5300,  ...,  96.4700,  96.4700,
             96.4700],
           [-45.5300, -44.5300, -43.5300,  ...,  96.4700,  96.4700,
             96.4700],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[-61.2800, -60.2800, -60.2800,  ...,  81.7200,  81.7200,
             81.7200],
           [-60.2800, -60.2800, -59.2800,  ...,  81.7200,  81.7200,
             81.7200],
           [-61.2800, -60.2800, -59.2800,  ...,  81.7200,  81.7200,
             81.7200],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]],

          [[-73.6750, -72.6750, -72.6750,  ...,  73.3250,  73.3250,
             73.3250],
           [-72.6750, -72.6750, -71.6750,  ...,  73.3250,  73.3250,
             73.3250],
           [-73.6750, -72.6750, -71.6750,  ...,  73.3250,  73.3250,
             73.3250],
           ...,
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000],
           [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,
              0.0000]]]]])])], 'timestamp': [tensor([1.5313e+09], dtype=torch.float64)], 'l2g_r_mat': tensor([[[ 0.7552,  0.6555, -0.0043],
         [-0.6550,  0.7544, -0.0432],
         [-0.0251,  0.0355,  0.9991]]]), 'l2g_t': tensor([[731.4192, 949.8059,   1.8220]]), 'gt_lane_labels': [tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
         2, 2, 2, 2, 3]])], 'gt_lane_bboxes': [tensor([[[110,  75, 125, 154],
         [ 90, 176, 103, 199],
         [172,   0, 185,   8],
         [ 73,  54, 103, 184],
         [116,  75, 132, 155],
         [123,  49, 126,  67],
         [140,  18, 150,  24],
         [137,   1, 151,   7],
         [147,  39, 149,  42],
         [144,  45, 146,  48],
         [109,   2, 120,   6],
         [105,   0, 107,   1],
         [125,   7, 130,  18],
         [132,   5, 135,  14],
         [ 91,   0, 105,   4],
         [ 92,   5, 109,  10],
         [114,  42, 126,  46],
         [112,  36, 125,  40],
         [127,  16, 131,  29],
         [134,  14, 138,  27],
         [ 98,  39, 112,  44],
         [ 98,  45, 114,  51],
         [ 98,   0, 196, 199],
         [138,   0, 172,  17],
         [122,   0, 137,   5],
         [ 58,   0,  96, 199],
         [ 76,  49, 119, 199],
         [128,  25, 153,  67],
         [ 58,   0, 194, 199]]])], 'gt_lane_masks': [tensor([[[[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         ...,

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.uint8)], 'gt_segmentation': [tensor([[[[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         ...,

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]]]])], 'gt_instance': [tensor([[[[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         ...,

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]],

         [[0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          ...,
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0],
          [0, 0, 0,  ..., 0, 0, 0]]]])], 'gt_centerness': [tensor([[[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           ...,
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00]]],


         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           ...,
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00]]],


         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           ...,
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00]]],


         ...,


         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           ...,
           [1.4220e-07, 1.7910e-06, 1.8064e-05,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [1.1302e-07, 1.4236e-06, 1.4358e-05,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [7.1933e-08, 9.0602e-07, 9.1378e-06,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00]]],


         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           ...,
           [1.4220e-07, 1.7910e-06, 1.8064e-05,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [1.1302e-07, 1.4236e-06, 1.4358e-05,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [7.1933e-08, 9.0602e-07, 9.1378e-06,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00]]],


         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           ...,
           [1.4220e-07, 1.7910e-06, 1.8064e-05,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [1.1302e-07, 1.4236e-06, 1.4358e-05,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00],
           [7.1933e-08, 9.0602e-07, 9.1378e-06,  ..., 0.0000e+00,
            0.0000e+00, 0.0000e+00]]]]])], 'gt_offset': [tensor([[[[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         ...,


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]]]])], 'gt_flow': [tensor([[[[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         ...,


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]]]])], 'gt_backward_flow': [tensor([[[[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         ...,


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]],


         [[[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]],

          [[255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.]]]]])], 'gt_occ_has_invalid_frame': [tensor([True])], 'gt_occ_img_is_valid': [tensor([[False, False,  True,  True,  True,  True,  True,  True,  True]])], 'sdc_planning': [tensor([[[[-0.1268,  4.7767, -3.1895],
          [-0.4839,  9.5961, -3.2457],
          [-1.1293, 14.3364, -3.3080],
          [-2.1167, 19.1896, -3.3725],
          [-3.3965, 23.8905, -3.4379],
          [-5.2542, 29.4554, -3.4954]]]], dtype=torch.float64)], 'sdc_planning_mask': [tensor([[[[1., 1.],
          [1., 1.],
          [1., 1.],
          [1., 1.],
          [1., 1.],
          [1., 1.]]]], dtype=torch.float64)], 'command': [tensor([1])]}
(Pdb) dict_keys(['img_metas', 'img', 'timestamp', 'l2g_r_mat', 'l2g_t', 'gt_lane_labels', 'gt_lane_bboxes', 'gt_lane_masks', 'gt_segmentation', 'gt_instance', 'gt_centerness', 'gt_offset', 'gt_flow', 'gt_backward_flow', 'gt_occ_has_invalid_frame', 'gt_occ_img_is_valid', 'sdc_planning', 'sdc_planning_mask', 'command'])
(Pdb) [tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
         2, 2, 2, 2, 3]])]
(Pdb) [tensor([[[110,  75, 125, 154],
         [ 90, 176, 103, 199],
         [172,   0, 185,   8],
         [ 73,  54, 103, 184],
         [116,  75, 132, 155],
         [123,  49, 126,  67],
         [140,  18, 150,  24],
         [137,   1, 151,   7],
         [147,  39, 149,  42],
         [144,  45, 146,  48],
         [109,   2, 120,   6],
         [105,   0, 107,   1],
         [125,   7, 130,  18],
         [132,   5, 135,  14],
         [ 91,   0, 105,   4],
         [ 92,   5, 109,  10],
         [114,  42, 126,  46],
         [112,  36, 125,  40],
         [127,  16, 131,  29],
         [134,  14, 138,  27],
         [ 98,  39, 112,  44],
         [ 98,  45, 114,  51],
         [ 98,   0, 196, 199],
         [138,   0, 172,  17],
         [122,   0, 137,   5],
         [ 58,   0,  96, 199],
         [ 76,  49, 119, 199],
         [128,  25, 153,  67],
         [ 58,   0, 194, 199]]])]
(Pdb) [tensor([1])]
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(83)forward()
-> return self.forward_test(**kwargs)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(297)forward_test()
-> result_track[0] = self.upsample_bev_if_tiny(result_track[0])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(299)forward_test()
-> bev_embed = result_track[0]["bev_embed"]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(301)forward_test()
-> if self.with_seg_head:
(Pdb) torch.Size([40000, 1, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(302)forward_test()
-> result_seg =  self.seg_head.forward_test(bev_embed, gt_lane_labels, gt_lane_masks, img_metas, rescale)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1117)__getattr__()
-> def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1118)__getattr__()
-> if '_parameters' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1119)__getattr__()
-> _parameters = self.__dict__['_parameters']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1120)__getattr__()
-> if name in _parameters:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1122)__getattr__()
-> if '_buffers' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1123)__getattr__()
-> _buffers = self.__dict__['_buffers']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1124)__getattr__()
-> if name in _buffers:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1126)__getattr__()
-> if '_modules' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1127)__getattr__()
-> modules = self.__dict__['_modules']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1128)__getattr__()
-> if name in modules:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()
-> return modules[name]
(Pdb) --Return--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()->PansegformerH... )
    )
  )
)
-> return modules[name]
(Pdb) --Call--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(1006)forward_test()
-> def forward_test(self,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(1012)forward_test()
-> import pdb; pdb.set_trace()
(Pdb) 1007 	                    pts_feats=None,
1008 	                    gt_lane_labels=None,
1009 	                    gt_lane_masks=None,
1010 	                    img_metas=None,
1011 	                    rescale=False):
1012 ->	        import pdb; pdb.set_trace()
1013 	        bbox_list = [dict() for i in range(len(img_metas))]
1014 	
1015 	        pred_seg_dict = self(pts_feats)
1016 	        results = self.get_bboxes(pred_seg_dict['outputs_classes'],
1017 	                                           pred_seg_dict['outputs_coords'],
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(1013)forward_test()
-> bbox_list = [dict() for i in range(len(img_metas))]
(Pdb) (Pdb) (Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(1015)forward_test()
-> pred_seg_dict = self(pts_feats)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1045)_call_impl()
-> def _call_impl(self, *input, **kwargs):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1046)_call_impl()
-> forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(178)new_func()
-> @functools.wraps(old_func)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(182)new_func()
-> if not isinstance(args[0], torch.nn.Module):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(185)new_func()
-> if not (hasattr(args[0], 'fp16_enabled') and args[0].fp16_enabled):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(186)new_func()
-> return old_func(*args, **kwargs)
(Pdb) --Call--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(181)forward()
-> @force_fp32(apply_to=('bev_embed', ))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(207)forward()
-> _, bs, _ = bev_embed.shape
(Pdb) *** SyntaxError: invalid syntax
(Pdb) torch.Size([40000, 1, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(209)forward()
-> mlvl_feats = [torch.reshape(bev_embed, (bs, self.bev_h, self.bev_w ,-1)).permute(0, 3, 1, 2)]
(Pdb) 200
(Pdb) 200
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(210)forward()
-> img_masks = mlvl_feats[0].new_zeros((bs, self.bev_h, self.bev_w))
(Pdb) *** AttributeError: 'list' object has no attribute 'shape'
(Pdb) 1
(Pdb) torch.Size([1, 256, 200, 200])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(212)forward()
-> hw_lvl = [feat_lvl.shape[-2:] for feat_lvl in mlvl_feats]
(Pdb) torch.Size([1, 200, 200])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(213)forward()
-> mlvl_masks = []
(Pdb) *** AttributeError: 'list' object has no attribute 'shape'
(Pdb) *** AttributeError: 'torch.Size' object has no attribute 'shape'
(Pdb) torch.Size([200, 200])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(214)forward()
-> mlvl_positional_encodings = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(215)forward()
-> for feat in mlvl_feats:
(Pdb) 1
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(216)forward()
-> mlvl_masks.append(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(217)forward()
-> F.interpolate(img_masks[None],
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(218)forward()
-> size=feat.shape[-2:]).to(torch.bool).squeeze(0))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(217)forward()
-> F.interpolate(img_masks[None],
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(218)forward()
-> size=feat.shape[-2:]).to(torch.bool).squeeze(0))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(217)forward()
-> F.interpolate(img_masks[None],
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(218)forward()
-> size=feat.shape[-2:]).to(torch.bool).squeeze(0))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(217)forward()
-> F.interpolate(img_masks[None],
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(216)forward()
-> mlvl_masks.append(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(219)forward()
-> mlvl_positional_encodings.append(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(220)forward()
-> self.positional_encoding(mlvl_masks[-1]))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(219)forward()
-> mlvl_positional_encodings.append(
(Pdb) *** IndexError: list index out of range
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(215)forward()
-> for feat in mlvl_feats:
(Pdb) torch.Size([1, 256, 200, 200])
(Pdb) torch.Size([1, 200, 200])
(Pdb) tensor([[[False, False, False,  ..., False, False, False],
         [False, False, False,  ..., False, False, False],
         [False, False, False,  ..., False, False, False],
         ...,
         [False, False, False,  ..., False, False, False],
         [False, False, False,  ..., False, False, False],
         [False, False, False,  ..., False, False, False]]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(222)forward()
-> query_embeds = None
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(223)forward()
-> if not self.as_two_stage:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(224)forward()
-> query_embeds = self.query_embedding.weight
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(225)forward()
-> import pdb; pdb.set_trace()
(Pdb) torch.Size([300, 512])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(227)forward()
-> enc_outputs_class, enc_outputs_coord = self.transformer(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(228)forward()
-> mlvl_feats,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(229)forward()
-> mlvl_masks,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(230)forward()
-> query_embeds,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(231)forward()
-> mlvl_positional_encodings,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(232)forward()
-> reg_branches=self.reg_branches if self.with_box_refine else None,  # noqa:E501
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(233)forward()
-> cls_branches=self.cls_branches if self.as_two_stage else None  # noqa:E501
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(227)forward()
-> enc_outputs_class, enc_outputs_coord = self.transformer(
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1045)_call_impl()
-> def _call_impl(self, *input, **kwargs):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1046)_call_impl()
-> forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(178)new_func()
-> @functools.wraps(old_func)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(182)new_func()
-> if not isinstance(args[0], torch.nn.Module):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(185)new_func()
-> if not (hasattr(args[0], 'fp16_enabled') and args[0].fp16_enabled):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(186)new_func()
-> return old_func(*args, **kwargs)
(Pdb) --Call--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(224)forward()
-> @force_fp32(apply_to=('mlvl_feats', 'query_embed', 'mlvl_pos_embeds'))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(282)forward()
-> assert self.as_two_stage or query_embed is not None
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(283)forward()
-> feat_flatten = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(284)forward()
-> mask_flatten = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(285)forward()
-> lvl_pos_embed_flatten = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(286)forward()
-> spatial_shapes = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(287)forward()
-> for lvl, (feat, mask, pos_embed) in enumerate(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(288)forward()
-> zip(mlvl_feats, mlvl_masks, mlvl_pos_embeds)):
(Pdb) *** AttributeError: 'list' object has no attribute 'shape'
(Pdb) torch.Size([1, 256, 200, 200])
(Pdb) torch.Size([1, 200, 200])
(Pdb) torch.Size([1, 256, 200, 200])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(287)forward()
-> for lvl, (feat, mask, pos_embed) in enumerate(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(289)forward()
-> bs, c, h, w = feat.shape
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(290)forward()
-> spatial_shape = (h, w)
(Pdb) 1
(Pdb) 256
(Pdb) 
Documented commands (type help <topic>):
========================================
EOF    c          d        h         list      q        rv       undisplay
a      cl         debug    help      ll        quit     s        unt      
alias  clear      disable  ignore    longlist  r        source   until    
args   commands   display  interact  n         restart  step     up       
b      condition  down     j         next      return   tbreak   w        
break  cont       enable   jump      p         retval   u        whatis   
bt     continue   exit     l         pp        run      unalias  where    

Miscellaneous help topics:
==========================
exec  pdb

(Pdb) 200
(Pdb)   /Users/liangming.xu/code/UniAD/tools/test.py(274)<module>()
-> main()
  /Users/liangming.xu/code/UniAD/tools/test.py(230)main()
-> result = model(return_loss=False, rescale=True, **data)
  /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(83)forward()
-> return self.forward_test(**kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(302)forward_test()
-> result_seg =  self.seg_head.forward_test(bev_embed, gt_lane_labels, gt_lane_masks, img_metas, rescale)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(1015)forward_test()
-> pred_seg_dict = self(pts_feats)
  /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
  /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(186)new_func()
-> return old_func(*args, **kwargs)
  /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(227)forward()
-> enc_outputs_class, enc_outputs_coord = self.transformer(
  /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
  /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(186)new_func()
-> return old_func(*args, **kwargs)
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(290)forward()
-> spatial_shape = (h, w)
(Pdb) 200
(Pdb) 285  	        lvl_pos_embed_flatten = []
286  	        spatial_shapes = []
287  	        for lvl, (feat, mask, pos_embed) in enumerate(
288  	                zip(mlvl_feats, mlvl_masks, mlvl_pos_embeds)):
289  	            bs, c, h, w = feat.shape
290  ->	            spatial_shape = (h, w)
291  	            spatial_shapes.append(spatial_shape)
292  	            feat = feat.flatten(2).transpose(1, 2)
293  	            mask = mask.flatten(1)
294  	            pos_embed = pos_embed.flatten(2).transpose(1, 2)
295  	            lvl_pos_embed = pos_embed + self.level_embeds[lvl].view(1, 1, -1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(291)forward()
-> spatial_shapes.append(spatial_shape)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(292)forward()
-> feat = feat.flatten(2).transpose(1, 2)
(Pdb) torch.Size([1, 256, 200, 200])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(293)forward()
-> mask = mask.flatten(1)
(Pdb) torch.Size([1, 40000, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(294)forward()
-> pos_embed = pos_embed.flatten(2).transpose(1, 2)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(295)forward()
-> lvl_pos_embed = pos_embed + self.level_embeds[lvl].view(1, 1, -1)
(Pdb) torch.Size([1, 40000, 256])
(Pdb) torch.Size([4, 256])
(Pdb) 0
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(296)forward()
-> lvl_pos_embed_flatten.append(lvl_pos_embed)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(297)forward()
-> feat_flatten.append(feat)
(Pdb) torch.Size([1, 40000, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(298)forward()
-> mask_flatten.append(mask)
(Pdb) torch.Size([1, 40000])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(287)forward()
-> for lvl, (feat, mask, pos_embed) in enumerate(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(299)forward()
-> feat_flatten = torch.cat(feat_flatten, 1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(300)forward()
-> mask_flatten = torch.cat(mask_flatten, 1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(301)forward()
-> lvl_pos_embed_flatten = torch.cat(lvl_pos_embed_flatten, 1)
(Pdb) torch.Size([1, 40000, 256])
(Pdb) torch.Size([1, 40000])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(302)forward()
-> spatial_shapes = torch.as_tensor(spatial_shapes,
(Pdb) torch.Size([1, 40000, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(303)forward()
-> dtype=torch.long,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(304)forward()
-> device=feat_flatten.device)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(302)forward()
-> spatial_shapes = torch.as_tensor(spatial_shapes,
(Pdb) [(200, 200)]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(305)forward()
-> level_start_index = torch.cat((spatial_shapes.new_zeros(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(306)forward()
-> (1, )), spatial_shapes.prod(1).cumsum(0)[:-1]))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(305)forward()
-> level_start_index = torch.cat((spatial_shapes.new_zeros(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(306)forward()
-> (1, )), spatial_shapes.prod(1).cumsum(0)[:-1]))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(305)forward()
-> level_start_index = torch.cat((spatial_shapes.new_zeros(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(307)forward()
-> valid_ratios = torch.stack(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(308)forward()
-> [self.get_valid_ratio(m) for m in mlvl_masks], 1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(307)forward()
-> valid_ratios = torch.stack(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(311)forward()
-> self.get_reference_points(spatial_shapes,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(312)forward()
-> valid_ratios,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(313)forward()
-> device=feat.device)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(311)forward()
-> self.get_reference_points(spatial_shapes,
(Pdb) --Call--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(154)get_reference_points()
-> @staticmethod
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(171)get_reference_points()
-> reference_points_list = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(172)get_reference_points()
-> for lvl, (H, W) in enumerate(spatial_shapes):
(Pdb) tensor([[200, 200]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(174)get_reference_points()
-> ref_y, ref_x = torch.meshgrid(
(Pdb) 0
(Pdb) 169  	                shape (bs, num_keys, num_levels, 2).
170  	        """
171  	        reference_points_list = []
172  	        for lvl, (H, W) in enumerate(spatial_shapes):
173  	            #  TODO  check this 0.5
174  ->	            ref_y, ref_x = torch.meshgrid(
175  	                torch.linspace(0.5,
176  	                               H - 0.5,
177  	                               H,
178  	                               dtype=torch.float32,
179  	                               device=device),
(Pdb) torch.Size([1, 1, 2])
(Pdb) tensor([[[1., 1.]]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(175)get_reference_points()
-> torch.linspace(0.5,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(176)get_reference_points()
-> H - 0.5,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(177)get_reference_points()
-> H,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(178)get_reference_points()
-> dtype=torch.float32,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(179)get_reference_points()
-> device=device),
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(175)get_reference_points()
-> torch.linspace(0.5,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(180)get_reference_points()
-> torch.linspace(0.5,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(181)get_reference_points()
-> W - 0.5,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(182)get_reference_points()
-> W,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(183)get_reference_points()
-> dtype=torch.float32,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(184)get_reference_points()
-> device=device))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(180)get_reference_points()
-> torch.linspace(0.5,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(174)get_reference_points()
-> ref_y, ref_x = torch.meshgrid(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(185)get_reference_points()
-> ref_y = ref_y.reshape(-1)[None] / (valid_ratios[:, None, lvl, 1] *
(Pdb) torch.Size([200, 200])
(Pdb) tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000])
(Pdb) tensor([1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000])
(Pdb) tensor([  0.5000,   1.5000,   2.5000,   3.5000,   4.5000,   5.5000,   6.5000,
          7.5000,   8.5000,   9.5000,  10.5000,  11.5000,  12.5000,  13.5000,
         14.5000,  15.5000,  16.5000,  17.5000,  18.5000,  19.5000,  20.5000,
         21.5000,  22.5000,  23.5000,  24.5000,  25.5000,  26.5000,  27.5000,
         28.5000,  29.5000,  30.5000,  31.5000,  32.5000,  33.5000,  34.5000,
         35.5000,  36.5000,  37.5000,  38.5000,  39.5000,  40.5000,  41.5000,
         42.5000,  43.5000,  44.5000,  45.5000,  46.5000,  47.5000,  48.5000,
         49.5000,  50.5000,  51.5000,  52.5000,  53.5000,  54.5000,  55.5000,
         56.5000,  57.5000,  58.5000,  59.5000,  60.5000,  61.5000,  62.5000,
         63.5000,  64.5000,  65.5000,  66.5000,  67.5000,  68.5000,  69.5000,
         70.5000,  71.5000,  72.5000,  73.5000,  74.5000,  75.5000,  76.5000,
         77.5000,  78.5000,  79.5000,  80.5000,  81.5000,  82.5000,  83.5000,
         84.5000,  85.5000,  86.5000,  87.5000,  88.5000,  89.5000,  90.5000,
         91.5000,  92.5000,  93.5000,  94.5000,  95.5000,  96.5000,  97.5000,
         98.5000,  99.5000, 100.5000, 101.5000, 102.5000, 103.5000, 104.5000,
        105.5000, 106.5000, 107.5000, 108.5000, 109.5000, 110.5000, 111.5000,
        112.5000, 113.5000, 114.5000, 115.5000, 116.5000, 117.5000, 118.5000,
        119.5000, 120.5000, 121.5000, 122.5000, 123.5000, 124.5000, 125.5000,
        126.5000, 127.5000, 128.5000, 129.5000, 130.5000, 131.5000, 132.5000,
        133.5000, 134.5000, 135.5000, 136.5000, 137.5000, 138.5000, 139.5000,
        140.5000, 141.5000, 142.5000, 143.5000, 144.5000, 145.5000, 146.5000,
        147.5000, 148.5000, 149.5000, 150.5000, 151.5000, 152.5000, 153.5000,
        154.5000, 155.5000, 156.5000, 157.5000, 158.5000, 159.5000, 160.5000,
        161.5000, 162.5000, 163.5000, 164.5000, 165.5000, 166.5000, 167.5000,
        168.5000, 169.5000, 170.5000, 171.5000, 172.5000, 173.5000, 174.5000,
        175.5000, 176.5000, 177.5000, 178.5000, 179.5000, 180.5000, 181.5000,
        182.5000, 183.5000, 184.5000, 185.5000, 186.5000, 187.5000, 188.5000,
        189.5000, 190.5000, 191.5000, 192.5000, 193.5000, 194.5000, 195.5000,
        196.5000, 197.5000, 198.5000, 199.5000])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(186)get_reference_points()
-> H)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(185)get_reference_points()
-> ref_y = ref_y.reshape(-1)[None] / (valid_ratios[:, None, lvl, 1] *
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(187)get_reference_points()
-> ref_x = ref_x.reshape(-1)[None] / (valid_ratios[:, None, lvl, 0] *
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(188)get_reference_points()
-> W)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(187)get_reference_points()
-> ref_x = ref_x.reshape(-1)[None] / (valid_ratios[:, None, lvl, 0] *
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(189)get_reference_points()
-> ref = torch.stack((ref_x, ref_y), -1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(190)get_reference_points()
-> reference_points_list.append(ref)
(Pdb) torch.Size([1, 40000, 2])
(Pdb) <module 'torch.nn' from '/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/__init__.py'>
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(172)get_reference_points()
-> for lvl, (H, W) in enumerate(spatial_shapes):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(191)get_reference_points()
-> reference_points = torch.cat(reference_points_list, 1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(192)get_reference_points()
-> reference_points = reference_points[:, :, None] * valid_ratios[:, None]
(Pdb) torch.Size([1, 40000, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(193)get_reference_points()
-> return reference_points
(Pdb) --Return--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(193)get_reference_points()->tensor([[[[0....5, 0.9975]]]])
-> return reference_points
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(310)forward()
-> reference_points = \
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(315)forward()
-> feat_flatten = feat_flatten.permute(1, 0, 2)  # (H*W, bs, embed_dims)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(316)forward()
-> lvl_pos_embed_flatten = lvl_pos_embed_flatten.permute(
(Pdb) torch.Size([40000, 1, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(317)forward()
-> 1, 0, 2)  # (H*W, bs, embed_dims)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(316)forward()
-> lvl_pos_embed_flatten = lvl_pos_embed_flatten.permute(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(318)forward()
-> import pdb; pdb.set_trace()
(Pdb) torch.Size([40000, 1, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(319)forward()
-> memory = self.encoder(query=feat_flatten,
(Pdb) (Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(320)forward()
-> key=None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(321)forward()
-> value=None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(322)forward()
-> query_pos=lvl_pos_embed_flatten,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(323)forward()
-> query_key_padding_mask=mask_flatten,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(324)forward()
-> spatial_shapes=spatial_shapes,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(325)forward()
-> reference_points=reference_points,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(326)forward()
-> level_start_index=level_start_index,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(327)forward()
-> valid_ratios=valid_ratios,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(319)forward()
-> memory = self.encoder(query=feat_flatten,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(328)forward()
-> **kwargs)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py(319)forward()
-> memory = self.encoder(query=feat_flatten,
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1045)_call_impl()
-> def _call_impl(self, *input, **kwargs):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1046)_call_impl()
-> forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmdet/models/utils/transformer.py(112)forward()
-> def forward(self, *args, **kwargs):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmdet/models/utils/transformer.py(118)forward()
-> x = super(DetrTransformerEncoder, self).forward(*args, **kwargs)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(549)forward()
-> def forward(self,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(584)forward()
-> for layer in self.layers:
(Pdb) ModuleList(
  (0): BaseTransformerLayer(
    (attentions): ModuleList(
      (0): MultiScaleDeformableAttention(
        (dropout): Dropout(p=0.1, inplace=False)
        (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
        (attention_weights): Linear(in_features=256, out_features=128, bias=True)
        (value_proj): Linear(in_features=256, out_features=256, bias=True)
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (ffns): ModuleList(
      (0): FFN(
        (activate): ReLU(inplace=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=256, out_features=512, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=512, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
      )
    )
    (norms): ModuleList(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
  )
  (1): BaseTransformerLayer(
    (attentions): ModuleList(
      (0): MultiScaleDeformableAttention(
        (dropout): Dropout(p=0.1, inplace=False)
        (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
        (attention_weights): Linear(in_features=256, out_features=128, bias=True)
        (value_proj): Linear(in_features=256, out_features=256, bias=True)
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (ffns): ModuleList(
      (0): FFN(
        (activate): ReLU(inplace=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=256, out_features=512, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=512, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
      )
    )
    (norms): ModuleList(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
  )
  (2): BaseTransformerLayer(
    (attentions): ModuleList(
      (0): MultiScaleDeformableAttention(
        (dropout): Dropout(p=0.1, inplace=False)
        (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
        (attention_weights): Linear(in_features=256, out_features=128, bias=True)
        (value_proj): Linear(in_features=256, out_features=256, bias=True)
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (ffns): ModuleList(
      (0): FFN(
        (activate): ReLU(inplace=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=256, out_features=512, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=512, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
      )
    )
    (norms): ModuleList(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
  )
  (3): BaseTransformerLayer(
    (attentions): ModuleList(
      (0): MultiScaleDeformableAttention(
        (dropout): Dropout(p=0.1, inplace=False)
        (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
        (attention_weights): Linear(in_features=256, out_features=128, bias=True)
        (value_proj): Linear(in_features=256, out_features=256, bias=True)
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (ffns): ModuleList(
      (0): FFN(
        (activate): ReLU(inplace=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=256, out_features=512, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=512, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
      )
    )
    (norms): ModuleList(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
  )
  (4): BaseTransformerLayer(
    (attentions): ModuleList(
      (0): MultiScaleDeformableAttention(
        (dropout): Dropout(p=0.1, inplace=False)
        (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
        (attention_weights): Linear(in_features=256, out_features=128, bias=True)
        (value_proj): Linear(in_features=256, out_features=256, bias=True)
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (ffns): ModuleList(
      (0): FFN(
        (activate): ReLU(inplace=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=256, out_features=512, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=512, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
      )
    )
    (norms): ModuleList(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
  )
  (5): BaseTransformerLayer(
    (attentions): ModuleList(
      (0): MultiScaleDeformableAttention(
        (dropout): Dropout(p=0.1, inplace=False)
        (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
        (attention_weights): Linear(in_features=256, out_features=128, bias=True)
        (value_proj): Linear(in_features=256, out_features=256, bias=True)
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (ffns): ModuleList(
      (0): FFN(
        (activate): ReLU(inplace=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=256, out_features=512, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=512, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
      )
    )
    (norms): ModuleList(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
  )
)
(Pdb) 579  	                shape [bs, num_keys]. Default: None.
580  	
581  	        Returns:
582  	            Tensor:  results with shape [num_queries, bs, embed_dims].
583  	        """
584  ->	        for layer in self.layers:
585  	            query = layer(
586  	                query,
587  	                key,
588  	                value,
589  	                query_pos=query_pos,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(585)forward()
-> query = layer(
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(586)forward()
-> query,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(587)forward()
-> key,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(588)forward()
-> value,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(585)forward()
-> query = layer(
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(589)forward()
-> query_pos=query_pos,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(590)forward()
-> key_pos=key_pos,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(591)forward()
-> attn_masks=attn_masks,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(592)forward()
-> query_key_padding_mask=query_key_padding_mask,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(593)forward()
-> key_padding_mask=key_padding_mask,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(585)forward()
-> query = layer(
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(594)forward()
-> **kwargs)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(585)forward()
-> query = layer(
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1045)_call_impl()
-> def _call_impl(self, *input, **kwargs):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1046)_call_impl()
-> forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(412)forward()
-> def forward(self,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(453)forward()
-> norm_index = 0
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(454)forward()
-> attn_index = 0
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(455)forward()
-> ffn_index = 0
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(456)forward()
-> identity = query
(Pdb) *** AttributeError: 'NoneType' object has no attribute 'shape'
(Pdb) *** AttributeError: 'NoneType' object has no attribute 'shape'
(Pdb) torch.Size([40000, 1, 256])
(Pdb) *** NameError: name 'reference_points' is not defined
(Pdb) 451  	        """
452  	
453  	        norm_index = 0
454  	        attn_index = 0
455  	        ffn_index = 0
456  ->	        identity = query
457  	        if attn_masks is None:
458  	            attn_masks = [None for _ in range(self.num_attn)]
459  	        elif isinstance(attn_masks, torch.Tensor):
460  	            attn_masks = [
461  	                copy.deepcopy(attn_masks) for _ in range(self.num_attn)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(457)forward()
-> if attn_masks is None:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(458)forward()
-> attn_masks = [None for _ in range(self.num_attn)]
(Pdb) *** AttributeError: 'NoneType' object has no attribute 'shape'
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(471)forward()
-> for layer in self.operation_order:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(472)forward()
-> if layer == 'self_attn':
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(473)forward()
-> temp_key = temp_value = query
(Pdb) 'self_attn'
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(474)forward()
-> query = self.attentions[attn_index](
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(475)forward()
-> query,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(476)forward()
-> temp_key,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(477)forward()
-> temp_value,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(478)forward()
-> identity if self.pre_norm else None,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(474)forward()
-> query = self.attentions[attn_index](
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(479)forward()
-> query_pos=query_pos,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(480)forward()
-> key_pos=query_pos,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(481)forward()
-> attn_mask=attn_masks[attn_index],
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(482)forward()
-> key_padding_mask=query_key_padding_mask,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(474)forward()
-> query = self.attentions[attn_index](
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(483)forward()
-> **kwargs)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py(474)forward()
-> query = self.attentions[attn_index](
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1045)_call_impl()
-> def _call_impl(self, *input, **kwargs):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1046)_call_impl()
-> forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(303)new_func()
-> @functools.wraps(old_func)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(306)new_func()
-> args_info = getfullargspec(old_func)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(308)new_func()
-> func_name = old_func.__name__
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(309)new_func()
-> if cls_name is not None:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(310)new_func()
-> func_name = f'{cls_name}.{func_name}'
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(311)new_func()
-> if args:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(312)new_func()
-> arg_names = args_info.args[:len(args)]
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(313)new_func()
-> for src_arg_name, dst_arg_name in name_dict.items():
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(314)new_func()
-> if src_arg_name in arg_names:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(313)new_func()
-> for src_arg_name, dst_arg_name in name_dict.items():
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(320)new_func()
-> if kwargs:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(321)new_func()
-> for src_arg_name, dst_arg_name in name_dict.items():
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(322)new_func()
-> if src_arg_name in kwargs:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(321)new_func()
-> for src_arg_name, dst_arg_name in name_dict.items():
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/misc.py(340)new_func()
-> output = old_func(*args, **kwargs)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(251)forward()
-> @deprecated_api_warning({'residual': 'identity'},
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(300)forward()
-> if value is None:
(Pdb) 295  	
296  	        Returns:
297  	             Tensor: forwarded results with shape [num_query, bs, embed_dims].
298  	        """
299  	
300  ->	        if value is None:
301  	            value = query
302  	
303  	        if identity is None:
304  	            identity = query
305  	        if query_pos is not None:
(Pdb) torch.Size([40000, 1, 256])
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(303)forward()
-> if identity is None:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(304)forward()
-> identity = query
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(305)forward()
-> if query_pos is not None:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(306)forward()
-> query = query + query_pos
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(307)forward()
-> if not self.batch_first:
(Pdb) torch.Size([40000, 1, 256])
(Pdb) torch.Size([40000, 1, 256])
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(309)forward()
-> query = query.permute(1, 0, 2)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(310)forward()
-> value = value.permute(1, 0, 2)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(312)forward()
-> bs, num_query, _ = query.shape
(Pdb) torch.Size([1, 40000, 256])
(Pdb) torch.Size([1, 40000, 256])
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(313)forward()
-> bs, num_value, _ = value.shape
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(314)forward()
-> assert (spatial_shapes[:, 0] * spatial_shapes[:, 1]).sum() == num_value
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(316)forward()
-> value = self.value_proj(value)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(317)forward()
-> if key_padding_mask is not None:
(Pdb) torch.Size([1, 40000, 1, 2])
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(318)forward()
-> value = value.masked_fill(key_padding_mask[..., None], 0.0)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(319)forward()
-> value = value.view(bs, num_value, self.num_heads, -1)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(320)forward()
-> sampling_offsets = self.sampling_offsets(query).view(
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(321)forward()
-> bs, num_query, self.num_heads, self.num_levels, self.num_points, 2)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(320)forward()
-> sampling_offsets = self.sampling_offsets(query).view(
(Pdb) *** NameError: name 'sampling_offsets' is not defined
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(322)forward()
-> attention_weights = self.attention_weights(query).view(
(Pdb) torch.Size([1, 40000, 8, 4, 4, 2])
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(323)forward()
-> bs, num_query, self.num_heads, self.num_levels * self.num_points)
(Pdb) 4
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(322)forward()
-> attention_weights = self.attention_weights(query).view(
(Pdb) torch.Size([1, 40000, 256])
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(324)forward()
-> attention_weights = attention_weights.softmax(-1)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(326)forward()
-> attention_weights = attention_weights.view(bs, num_query,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(327)forward()
-> self.num_heads,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(328)forward()
-> self.num_levels,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(329)forward()
-> self.num_points)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(326)forward()
-> attention_weights = attention_weights.view(bs, num_query,
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(330)forward()
-> if reference_points.shape[-1] == 2:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(331)forward()
-> offset_normalizer = torch.stack(
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(332)forward()
-> [spatial_shapes[..., 1], spatial_shapes[..., 0]], -1)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(331)forward()
-> offset_normalizer = torch.stack(
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(333)forward()
-> sampling_locations = reference_points[:, :, None, :, None, :] \
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(334)forward()
-> + sampling_offsets \
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(335)forward()
-> / offset_normalizer[None, None, None, :, None, :]
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(334)forward()
-> + sampling_offsets \
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(333)forward()
-> sampling_locations = reference_points[:, :, None, :, None, :] \
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(345)forward()
-> if torch.cuda.is_available() and value.is_cuda:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(350)forward()
-> output = multi_scale_deformable_attn_pytorch(
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(351)forward()
-> value, spatial_shapes, sampling_locations, attention_weights)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(350)forward()
-> output = multi_scale_deformable_attn_pytorch(
(Pdb) RuntimeError: The size of tensor a (4) must match the size of tensor b (16) at non-singleton dimension 3
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/ops/multi_scale_deform_attn.py(350)forward()
-> output = multi_scale_deformable_attn_pytorch(
(Pdb) *** NameError: name 'out' is not defined
(Pdb) torch.Size([1, 40000, 8, 32])
(Pdb) torch.Size([1, 40000, 8, 4, 4, 2])
(Pdb) torch.Size([1, 2])
(Pdb) tensor([[200, 200]])
(Pdb) torch.Size([1, 40000, 8, 4, 4])
(Pdb) 345  	        if torch.cuda.is_available() and value.is_cuda:
346  	            output = MultiScaleDeformableAttnFunction.apply(
347  	                value, spatial_shapes, level_start_index, sampling_locations,
348  	                attention_weights, self.im2col_step)
349  	        else:
350  ->	            output = multi_scale_deformable_attn_pytorch(
351  	                value, spatial_shapes, sampling_locations, attention_weights)
352  	
353  	        output = self.output_proj(output)
354  	
355  	        if not self.batch_first:
(Pdb) torch.Size([1, 40000, 8, 32])
(Pdb) 