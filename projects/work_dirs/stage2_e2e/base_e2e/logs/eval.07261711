NOTE: Redirects are currently not supported in Windows or MacOs.
/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : ./tools/test.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 1
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:28596
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_f42z7jy8/none_jckcqv2j
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=28596
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_f42z7jy8/none_jckcqv2j/attempt_0/0/error.json
projects.mmdet3d_plugin
======
Loading NuScenes tables for version v1.0-trainval...
23 category,
8 attribute,
4 visibility,
64386 instance,
12 sensor,
10200 calibrated_sensor,
2631083 ego_pose,
68 log,
850 scene,
34149 sample,
2631083 sample_data,
1166187 sample_annotation,
4 map,
Done loading in 20.932 seconds.
======
Reverse indexing ...
Done reverse indexing in 5.2 seconds.
======
load checkpoint from local path: ./ckpts/uniad_base_e2e.pth
2023-07-26 17:11:53,336 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.0.conv2 is upgraded to version 2.
2023-07-26 17:11:53,342 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.1.conv2 is upgraded to version 2.
2023-07-26 17:11:53,346 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.2.conv2 is upgraded to version 2.
2023-07-26 17:11:53,350 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.3.conv2 is upgraded to version 2.
2023-07-26 17:11:53,354 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.4.conv2 is upgraded to version 2.
2023-07-26 17:11:53,358 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.5.conv2 is upgraded to version 2.
2023-07-26 17:11:53,362 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.6.conv2 is upgraded to version 2.
2023-07-26 17:11:53,366 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.7.conv2 is upgraded to version 2.
2023-07-26 17:11:53,370 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.8.conv2 is upgraded to version 2.
2023-07-26 17:11:53,374 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.9.conv2 is upgraded to version 2.
2023-07-26 17:11:53,378 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.10.conv2 is upgraded to version 2.
2023-07-26 17:11:53,382 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.11.conv2 is upgraded to version 2.
2023-07-26 17:11:53,386 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.12.conv2 is upgraded to version 2.
2023-07-26 17:11:53,390 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.13.conv2 is upgraded to version 2.
2023-07-26 17:11:53,394 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.14.conv2 is upgraded to version 2.
2023-07-26 17:11:53,397 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.15.conv2 is upgraded to version 2.
2023-07-26 17:11:53,400 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.16.conv2 is upgraded to version 2.
2023-07-26 17:11:53,404 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.17.conv2 is upgraded to version 2.
2023-07-26 17:11:53,407 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.18.conv2 is upgraded to version 2.
2023-07-26 17:11:53,411 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.19.conv2 is upgraded to version 2.
2023-07-26 17:11:53,415 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.20.conv2 is upgraded to version 2.
2023-07-26 17:11:53,418 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.21.conv2 is upgraded to version 2.
2023-07-26 17:11:53,421 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.22.conv2 is upgraded to version 2.
2023-07-26 17:11:53,424 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.0.conv2 is upgraded to version 2.
2023-07-26 17:11:53,429 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.1.conv2 is upgraded to version 2.
2023-07-26 17:11:53,432 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.2.conv2 is upgraded to version 2.
The model and loaded state dict do not match exactly

size mismatch for seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
unexpected key in source state_dict: bbox_size_fc.weight, bbox_size_fc.bias, pts_bbox_head.query_embedding.weight, pts_bbox_head.transformer.reference_points.weight, pts_bbox_head.transformer.reference_points.bias

> /Users/liangming.xu/code/UniAD/tools/test.py(230)main()
-> result = model(return_loss=False, rescale=True, **data)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(724)simple_test_track()
-> bs = img.size(0)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(672)_forward_single_frame_inference()
-> "pred_logits": output_classes,
(Pdb) 667  	        last_ref_pts = det_output["last_ref_points"]
668  	        query_feats = det_output["query_feats"]
669  	        import pdb; pdb.set_trace()
670  	
671  	        out = {
672  ->	            "pred_logits": output_classes,
673  	            "pred_boxes": output_coords,
674  	            "ref_pts": last_ref_pts,
675  	            "bev_embed": bev_embed,
676  	            "query_embeddings": query_feats,
677  	            "all_past_traj_preds": det_output["all_past_traj_preds"],
(Pdb) torch.Size([1, 901, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(673)_forward_single_frame_inference()
-> "pred_boxes": output_coords,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(674)_forward_single_frame_inference()
-> "ref_pts": last_ref_pts,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(675)_forward_single_frame_inference()
-> "bev_embed": bev_embed,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(676)_forward_single_frame_inference()
-> "query_embeddings": query_feats,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(677)_forward_single_frame_inference()
-> "all_past_traj_preds": det_output["all_past_traj_preds"],
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(678)_forward_single_frame_inference()
-> "bev_pos": bev_pos,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(671)_forward_single_frame_inference()
-> out = {
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(682)_forward_single_frame_inference()
-> track_scores = output_classes[-1, 0, :].sigmoid().max(dim=-1).values
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(684)_forward_single_frame_inference()
-> track_instances.scores = track_scores
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(686)_forward_single_frame_inference()
-> track_instances.pred_logits = output_classes[-1, 0]  # [300, num_cls]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(687)_forward_single_frame_inference()
-> track_instances.pred_boxes = output_coords[-1, 0]  # [300, box_dim]
(Pdb) torch.Size([901, 10])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(688)_forward_single_frame_inference()
-> track_instances.output_embedding = query_feats[-1][0]  # [300, feat_dim]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(689)_forward_single_frame_inference()
-> track_instances.ref_pts = last_ref_pts[0]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(691)_forward_single_frame_inference()
-> track_instances.obj_idxes[900] = -2
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(693)_forward_single_frame_inference()
-> self.track_base.update(track_instances, None)
(Pdb) --Call--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/tracker.py(16)update()
-> def update(self, track_instances: Instances, iou_thre=None):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/tracker.py(17)update()
-> track_instances.disappear_time[track_instances.scores >= self.score_thresh] = 0
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/tracker.py(18)update()
-> for i in range(len(track_instances)):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/tracker.py(20)update()
-> track_instances.obj_idxes[i] == -1
(Pdb) 901
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/tracker.py(19)update()
-> if (
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(693)_forward_single_frame_inference()
-> self.track_base.update(track_instances, None)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(724)simple_test_track()
-> bs = img.size(0)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(693)_forward_single_frame_inference()
-> self.track_base.update(track_instances, None)
(Pdb) 688  	        track_instances.output_embedding = query_feats[-1][0]  # [300, feat_dim]
689  	        track_instances.ref_pts = last_ref_pts[0]
690  	        # hard_code: assume the 901 query is sdc query
691  	        track_instances.obj_idxes[900] = -2
692  	        """ update track base """
693  ->	        self.track_base.update(track_instances, None)
694  	
695  	        active_index = (track_instances.obj_idxes>=0) & (track_instances.scores >= self.track_base.filter_score_thresh)    # filter out sleep objects
696  	        out.update(self.select_active_track_query(track_instances, active_index, img_metas))
697  	        out.update(self.select_sdc_track_query(track_instances[track_instances.obj_idxes==-2], img_metas))
698  	
(Pdb) torch.Size([901, 256])
(Pdb) torch.Size([6, 1, 901, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py(297)forward_test()
-> result_track[0] = self.upsample_bev_if_tiny(result_track[0])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(1013)forward_test()
-> bbox_list = [dict() for i in range(len(img_metas))]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py(227)forward()
-> enc_outputs_class, enc_outputs_coord = self.transformer(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(170)forward_test()
-> track_query = outs_track['track_query_embeddings'][None, None, ...]
(Pdb) 165  	
166  	    def forward_test(self, bev_embed, outs_track={}, outs_seg={}):
167  	        import pdb; pdb.set_trace()
168  	
169  	        """Test function"""
170  ->	        track_query = outs_track['track_query_embeddings'][None, None, ...]
171  	        track_boxes = outs_track['track_bbox_results']
172  	
173  	        track_query = torch.cat([track_query, outs_track['sdc_embedding'][None, None, None, :]], dim=2)
174  	        sdc_track_boxes = outs_track['sdc_track_bbox_results']
175  	
(Pdb) torch.Size([3, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(171)forward_test()
-> track_boxes = outs_track['track_bbox_results']
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(173)forward_test()
-> track_query = torch.cat([track_query, outs_track['sdc_embedding'][None, None, None, :]], dim=2)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(174)forward_test()
-> sdc_track_boxes = outs_track['sdc_track_bbox_results']
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(176)forward_test()
-> track_boxes[0][0].tensor = torch.cat([track_boxes[0][0].tensor, sdc_track_boxes[0][0].tensor], dim=0)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(177)forward_test()
-> track_boxes[0][1] = torch.cat([track_boxes[0][1], sdc_track_boxes[0][1]], dim=0)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(178)forward_test()
-> track_boxes[0][2] = torch.cat([track_boxes[0][2], sdc_track_boxes[0][2]], dim=0)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(179)forward_test()
-> track_boxes[0][3] = torch.cat([track_boxes[0][3], sdc_track_boxes[0][3]], dim=0)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(180)forward_test()
-> memory, memory_mask, memory_pos, lane_query, _, lane_query_pos, hw_lvl = outs_seg['args_tuple']
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(181)forward_test()
-> outs_motion = self(bev_embed, track_query, lane_query, lane_query_pos, track_boxes)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1045)_call_impl()
-> def _call_impl(self, *input, **kwargs):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1046)_call_impl()
-> forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(90)new_func()
-> @functools.wraps(old_func)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(94)new_func()
-> if not isinstance(args[0], torch.nn.Module):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(97)new_func()
-> if not (hasattr(args[0], 'fp16_enabled') and args[0].fp16_enabled):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(98)new_func()
-> return old_func(*args, **kwargs)
(Pdb) --Call--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(213)forward()
-> @auto_fp16(apply_to=('bev_embed', 'track_query', 'lane_query', 'lane_query_pos', 'lane_query_embed', 'prev_bev'))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(240)forward()
-> dtype = track_query.dtype
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py(98)new_func()
-> return old_func(*args, **kwargs)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(181)forward_test()
-> outs_motion = self(bev_embed, track_query, lane_query, lane_query_pos, track_boxes)
(Pdb) 176  	        track_boxes[0][0].tensor = torch.cat([track_boxes[0][0].tensor, sdc_track_boxes[0][0].tensor], dim=0)
177  	        track_boxes[0][1] = torch.cat([track_boxes[0][1], sdc_track_boxes[0][1]], dim=0)
178  	        track_boxes[0][2] = torch.cat([track_boxes[0][2], sdc_track_boxes[0][2]], dim=0)
179  	        track_boxes[0][3] = torch.cat([track_boxes[0][3], sdc_track_boxes[0][3]], dim=0)
180  	        memory, memory_mask, memory_pos, lane_query, _, lane_query_pos, hw_lvl = outs_seg['args_tuple']
181  ->	        outs_motion = self(bev_embed, track_query, lane_query, lane_query_pos, track_boxes)
182  	        traj_results = self.get_trajs(outs_motion, track_boxes)
183  	        bboxes, scores, labels, bbox_index, mask = track_boxes[0]
184  	        outs_motion['track_scores'] = scores[None, :]
185  	        labels[-1] = 0
186  	        def filter_vehicle_query(outs_motion, labels, vehicle_id_list):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(241)forward()
-> device = track_query.device
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(242)forward()
-> num_groups = self.kmeans_anchors.shape[0]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(245)forward()
-> track_query = track_query[:, -1]
(Pdb) torch.Size([1, 300, 256])
(Pdb) torch.Size([1, 300, 256])
(Pdb) *** AttributeError: 'list' object has no attribute 'keys'
(Pdb) *** AttributeError: 'list' object has no attribute 'keys'
(Pdb) 1
(Pdb) *** AttributeError: 'LiDARInstance3DBoxes' object has no attribute 'keys'
(Pdb) LiDARInstance3DBoxes(
    tensor([[-7.5262e-01, -2.4579e+01, -2.2621e+00,  1.9450e+00,  4.5364e+00,
          1.5434e+00, -3.1230e+00,  8.8571e-02,  5.5166e+00],
        [-1.2292e+01,  3.5435e+01, -9.5619e-01,  7.1796e-01,  8.1444e-01,
          1.7480e+00,  3.0222e+00, -2.9149e-01,  1.2141e+00],
        [-4.4362e+00, -1.0457e+01, -1.9604e+00,  5.6273e-01,  1.7301e+00,
          1.0861e+00,  2.6956e-02, -1.2011e-03, -9.9059e-04],
        [ 3.1940e-02, -6.2492e-02, -7.7301e-01,  1.7408e+00,  4.1469e+00,
          1.5712e+00, -3.1400e+00, -1.7210e-01,  6.9688e+00]]))
(Pdb) *** NameError: name 'bev_embe' is not defined
(Pdb) torch.Size([40000, 1, 256])
(Pdb) 240  	        dtype = track_query.dtype
241  	        device = track_query.device
242  	        num_groups = self.kmeans_anchors.shape[0]
243  	
244  	        # extract the last frame of the track query
245  ->	        track_query = track_query[:, -1]
246  	
247  	        # encode the center point of the track query
248  	        reference_points_track = self._extract_tracking_centers(
249  	            track_bbox_results, self.pc_range)
250  	        track_query_pos = self.boxes_query_embedding_layer(pos2posemb2d(reference_points_track.to(device)))  # B, A, D
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(248)forward()
-> reference_points_track = self._extract_tracking_centers(
(Pdb) torch.Size([1, 4, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(249)forward()
-> track_bbox_results, self.pc_range)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(248)forward()
-> reference_points_track = self._extract_tracking_centers(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(250)forward()
-> track_query_pos = self.boxes_query_embedding_layer(pos2posemb2d(reference_points_track.to(device)))  # B, A, D
(Pdb) torch.Size([1, 4, 2])
(Pdb) tensor([[[0.4927, 0.2600],
         [0.3800, 0.8460],
         [0.4567, 0.3979],
         [0.5003, 0.4994]]])
(Pdb) *** AttributeError: 'MotionHead' object has no attribute 'embed_dim'
(Pdb) *** AttributeError: 'int' object has no attribute 'shape'
(Pdb) 256
(Pdb) torch.Size([1, 4, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(254)forward()
-> learnable_query_pos = self.learnable_motion_query_embedding.weight.to(dtype)  # latent anchor (P*G, D)
(Pdb) torch.Size([1, 4, 256])
(Pdb) torch.Size([24, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(255)forward()
-> learnable_query_pos = torch.stack(torch.split(learnable_query_pos, self.num_anchor, dim=0))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(260)forward()
-> agent_level_anchors = self.kmeans_anchors.to(dtype).to(device).view(num_groups, self.num_anchor, self.predict_steps, 2).detach()
(Pdb) torch.Size([4, 6, 256])
(Pdb) torch.Size([4, 6, 12, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(261)forward()
-> scene_level_ego_anchors = anchor_coordinate_transform(agent_level_anchors, track_bbox_results, with_translation_transform=True)  # B, A, G, P ,12 ,2
(Pdb) *** AttributeError: 'list' object has no attribute 'shape'
(Pdb) *** AttributeError: 'LiDARInstance3DBoxes' object has no attribute 'shape'
(Pdb) --Call--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(78)anchor_coordinate_transform()
-> def anchor_coordinate_transform(anchors, bbox_results, with_translation_transform=True, with_rotation_transform=True):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(91)anchor_coordinate_transform()
-> batch_size = len(bbox_results)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(92)anchor_coordinate_transform()
-> batched_anchors = []
(Pdb) 1
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(93)anchor_coordinate_transform()
-> transformed_anchors = anchors[None, ...] # expand num agents: num_groups, num_modes, 12, 2 -> 1, ...
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(94)anchor_coordinate_transform()
-> for i in range(batch_size):
(Pdb) torch.Size([1, 4, 6, 12, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(95)anchor_coordinate_transform()
-> bboxes, scores, labels, bbox_index, mask = bbox_results[i]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(96)anchor_coordinate_transform()
-> yaw = bboxes.yaw.to(transformed_anchors.device)
(Pdb) *** AttributeError: 'list' object has no attribute 'shape'
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(97)anchor_coordinate_transform()
-> bbox_centers = bboxes.gravity_center.to(transformed_anchors.device)
(Pdb) *** AttributeError: 'LiDARInstance3DBoxes' object has no attribute 'shape'
(Pdb) torch.Size([4])
(Pdb) LiDARInstance3DBoxes(
    tensor([[-7.5262e-01, -2.4579e+01, -2.2621e+00,  1.9450e+00,  4.5364e+00,
          1.5434e+00, -3.1230e+00,  8.8571e-02,  5.5166e+00],
        [-1.2292e+01,  3.5435e+01, -9.5619e-01,  7.1796e-01,  8.1444e-01,
          1.7480e+00,  3.0222e+00, -2.9149e-01,  1.2141e+00],
        [-4.4362e+00, -1.0457e+01, -1.9604e+00,  5.6273e-01,  1.7301e+00,
          1.0861e+00,  2.6956e-02, -1.2011e-03, -9.9059e-04],
        [ 3.1940e-02, -6.2492e-02, -7.7301e-01,  1.7408e+00,  4.1469e+00,
          1.5712e+00, -3.1400e+00, -1.7210e-01,  6.9688e+00]]))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(98)anchor_coordinate_transform()
-> if with_rotation_transform:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(99)anchor_coordinate_transform()
-> angle = yaw - 3.1415953 # num_agents, 1
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(100)anchor_coordinate_transform()
-> rot_yaw = rot_2d(angle) # num_agents, 2, 2
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(101)anchor_coordinate_transform()
-> rot_yaw = rot_yaw[:, None, None,:, :] # num_agents, 1, 1, 2, 2
(Pdb) torch.Size([4])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(102)anchor_coordinate_transform()
-> transformed_anchors = rearrange(transformed_anchors, 'b g m t c -> b g m c t')  # 1, num_groups, num_modes, 12, 2 -> 1, num_groups, num_modes, 2, 12
(Pdb) torch.Size([4, 1, 1, 2, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(103)anchor_coordinate_transform()
-> transformed_anchors = torch.matmul(rot_yaw, transformed_anchors)# -> num_agents, num_groups, num_modes, 12, 2
(Pdb) torch.Size([1, 4, 6, 2, 12])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(104)anchor_coordinate_transform()
-> transformed_anchors = rearrange(transformed_anchors, 'b g m c t -> b g m t c')
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(105)anchor_coordinate_transform()
-> if with_translation_transform:
(Pdb) tensor([[[[[-7.9228e-02,  4.0815e+00],
           [-1.6153e-01,  8.2296e+00],
           [-2.4567e-01,  1.2433e+01],
           ...,
           [-7.9254e-01,  4.2335e+01],
           [-8.5250e-01,  4.6540e+01],
           [-9.0589e-01,  5.0704e+01]],

          [[-5.0555e-04,  2.0548e-02],
           [-1.0992e-03,  3.6916e-02],
           [-1.6939e-03,  4.9966e-02],
           ...,
           [-6.4499e-03,  1.4823e-01],
           [-7.7329e-03,  1.7574e-01],
           [-9.2551e-03,  2.0829e-01]],

          [[-1.8672e-02,  2.7486e+00],
           [-1.8041e-03,  5.5209e+00],
           [ 5.2087e-02,  8.3039e+00],
           ...,
           [ 1.2750e+00,  2.7306e+01],
           [ 1.5177e+00,  2.9870e+01],
           [ 1.7659e+00,  3.2390e+01]],

          [[-1.2916e-01,  6.1720e+00],
           [-2.7693e-01,  1.2410e+01],
           [-4.4413e-01,  1.8706e+01],
           ...,
           [-2.1553e+00,  6.3354e+01],
           [-2.4664e+00,  6.9695e+01],
           [-2.7899e+00,  7.6001e+01]],

          [[-2.9305e-01,  2.3963e+00],
           [-8.7330e-01,  4.8214e+00],
           [-1.7702e+00,  7.2420e+00],
           ...,
           [-1.6398e+01,  2.2142e+01],
           [-1.9351e+01,  2.3893e+01],
           [-2.2422e+01,  2.5576e+01]],

          [[-3.4695e-03,  1.4132e+00],
           [ 1.6951e-02,  2.7976e+00],
           [ 6.3374e-02,  4.1596e+00],
           ...,
           [ 1.1093e+00,  1.3352e+01],
           [ 1.3324e+00,  1.4643e+01],
           [ 1.5637e+00,  1.5929e+01]]],


         [[[ 2.8643e-04,  2.4279e-02],
           [ 5.2706e-04,  4.5146e-02],
           [ 9.5848e-04,  6.3093e-02],
           ...,
           [ 9.8932e-03,  2.0323e-01],
           [ 1.1985e-02,  2.3732e-01],
           [ 1.4606e-02,  2.7622e-01]],

          [[-8.6279e-02,  2.7634e+00],
           [-2.0066e-01,  5.5257e+00],
           [-3.3715e-01,  8.2821e+00],
           ...,
           [-1.5135e+00,  2.7160e+01],
           [-1.6644e+00,  2.9749e+01],
           [-1.7925e+00,  3.2306e+01]],

          [[-1.1520e-01,  6.3491e+00],
           [-2.2657e-01,  1.2741e+01],
           [-3.3450e-01,  1.9177e+01],
           ...,
           [-8.4334e-01,  6.4389e+01],
           [-8.8736e-01,  7.0820e+01],
           [-9.4074e-01,  7.7249e+01]],

          [[-3.8477e-02,  1.5001e+00],
           [-7.9303e-02,  3.0001e+00],
           [-1.3111e-01,  4.4988e+00],
           ...,
           [-1.1012e+00,  1.4586e+01],
           [-1.2563e+00,  1.5947e+01],
           [-1.4032e+00,  1.7275e+01]],

          [[-5.5385e-02,  4.3119e+00],
           [-1.0810e-01,  8.6611e+00],
           [-1.5704e-01,  1.3006e+01],
           ...,
           [-7.1308e-01,  4.2793e+01],
           [-8.9351e-01,  4.6808e+01],
           [-1.1060e+00,  5.0775e+01]],

          [[ 3.0302e-02,  2.9206e+00],
           [ 3.5296e-01,  5.8387e+00],
           [ 1.0133e+00,  8.7756e+00],
           ...,
           [ 1.6434e+01,  2.6181e+01],
           [ 1.9861e+01,  2.8073e+01],
           [ 2.3430e+01,  2.9895e+01]]],


         [[[ 1.7535e-03,  3.9362e-01],
           [ 1.2750e-02,  7.7901e-01],
           [ 3.5796e-02,  1.1557e+00],
           ...,
           [ 4.0327e-01,  3.5732e+00],
           [ 4.6275e-01,  3.8934e+00],
           [ 5.2146e-01,  4.2099e+00]],

          [[-1.2816e-03,  1.9311e-02],
           [-2.6171e-03,  3.4868e-02],
           [-4.2546e-03,  4.6340e-02],
           ...,
           [-1.7588e-02,  9.9370e-02],
           [-1.9693e-02,  1.1632e-01],
           [-2.1621e-02,  1.3692e-01]],

          [[-1.4808e-02,  7.5774e-01],
           [-2.8310e-02,  1.5180e+00],
           [-4.0143e-02,  2.2786e+00],
           ...,
           [-9.1247e-02,  7.5349e+00],
           [-9.6849e-02,  8.2695e+00],
           [-1.0323e-01,  8.9981e+00]],

          [[-4.1107e-02,  1.4416e+00],
           [-7.7811e-02,  2.8933e+00],
           [-1.1021e-01,  4.3504e+00],
           ...,
           [-2.6008e-01,  1.4115e+01],
           [-2.6715e-01,  1.5409e+01],
           [-2.7067e-01,  1.6680e+01]],

          [[-5.7869e-02,  6.1875e-01],
           [-1.6227e-01,  1.2336e+00],
           [-3.1811e-01,  1.8411e+00],
           ...,
           [-2.4170e+00,  5.5891e+00],
           [-2.7751e+00,  6.0537e+00],
           [-3.1318e+00,  6.5050e+00]],

          [[-7.1940e-03,  5.8900e-01],
           [-1.0708e-02,  1.1805e+00],
           [-1.0113e-02,  1.7729e+00],
           ...,
           [ 7.9599e-02,  5.8588e+00],
           [ 9.6433e-02,  6.4241e+00],
           [ 1.1305e-01,  6.9836e+00]]],


         [[[-6.1306e-04,  1.9415e-03],
           [-1.2962e-03,  4.2202e-03],
           [-1.8756e-03,  6.3729e-03],
           ...,
           [-4.8788e-03,  1.7432e-02],
           [-5.4898e-03,  1.7617e-02],
           [-6.2266e-03,  1.7571e-02]],

          [[ 3.5102e-04, -2.6450e-02],
           [ 1.9073e-03, -5.5273e-02],
           [ 2.9980e-03, -8.3670e-02],
           ...,
           [-4.9242e-03, -2.2795e-01],
           [-5.5999e-03, -2.3603e-01],
           [-5.8279e-03, -2.3945e-01]],

          [[ 4.6165e-01,  2.8805e-04],
           [ 9.5144e-01,  3.2659e-02],
           [ 1.4383e+00,  8.8631e-02],
           ...,
           [ 4.9794e+00,  1.3378e+00],
           [ 5.3566e+00,  1.6155e+00],
           [ 5.6918e+00,  1.8950e+00]],

          [[-3.2126e-01,  2.3099e-02],
           [-6.7258e-01,  5.0103e-02],
           [-9.7570e-01,  6.4955e-02],
           ...,
           [-2.4368e+00,  1.5608e-01],
           [-2.5350e+00,  1.5205e-01],
           [-2.6201e+00,  1.5712e-01]],

          [[-5.2121e-02,  1.5582e-03],
           [-1.0751e-01,  3.2424e-03],
           [-1.5937e-01,  5.8105e-03],
           ...,
           [-4.1546e-01,  2.2654e-02],
           [-4.3363e-01,  2.4708e-02],
           [-4.4852e-01,  2.6191e-02]],

          [[ 5.2885e-02,  9.4057e-03],
           [ 1.0713e-01,  1.7520e-02],
           [ 1.5977e-01,  2.4179e-02],
           ...,
           [ 3.5846e-01,  3.7388e-02],
           [ 3.6239e-01,  3.7463e-02],
           [ 3.6307e-01,  3.6670e-02]]]],



        [[[[ 4.8287e-01,  4.0536e+00],
           [ 9.7186e-01,  8.1736e+00],
           [ 1.4667e+00,  1.2349e+01],
           ...,
           [ 5.0374e+00,  4.2041e+01],
           [ 5.5564e+00,  4.6215e+01],
           [ 6.0763e+00,  5.0347e+01]],

          [[ 2.3253e-03,  2.0422e-02],
           [ 3.9885e-03,  3.6716e-02],
           [ 5.1942e-03,  4.9724e-02],
           ...,
           [ 1.3998e-02,  1.4771e-01],
           [ 1.6511e-02,  1.7514e-01],
           [ 1.9480e-02,  2.0759e-01]],

          [[ 3.5954e-01,  2.7251e+00],
           [ 7.5753e-01,  5.4687e+00],
           [ 1.1937e+00,  8.2178e+00],
           ...,
           [ 5.0183e+00,  2.6871e+01],
           [ 5.6115e+00,  2.9378e+01],
           [ 6.2039e+00,  3.1839e+01]],

          [[ 7.2092e-01,  6.1311e+00],
           [ 1.4325e+00,  1.2330e+01],
           [ 2.1328e+00,  1.8589e+01],
           ...,
           [ 6.5786e+00,  6.3048e+01],
           [ 7.1426e+00,  6.9372e+01],
           [ 7.6893e+00,  7.5662e+01]],

          [[ 3.9317e-02,  2.4139e+00],
           [-2.0189e-01,  4.8957e+00],
           [-7.5737e-01,  7.4166e+00],
           ...,
           [-1.3197e+01,  2.4187e+01],
           [-1.5881e+01,  2.6328e+01],
           [-1.8691e+01,  2.8417e+01]],

          [[ 1.9093e-01,  1.4003e+00],
           [ 4.0156e-01,  2.7687e+00],
           [ 6.3485e-01,  4.1113e+00],
           ...,
           [ 2.9352e+00,  1.3073e+01],
           [ 3.3337e+00,  1.4321e+01],
           [ 3.7396e+00,  1.5562e+01]]],


         [[[ 3.6229e-03,  2.4009e-02],
           [ 6.7311e-03,  4.4644e-02],
           [ 9.6268e-03,  6.2361e-02],
           ...,
           [ 3.7751e-02,  1.9994e-01],
           [ 4.4510e-02,  2.3341e-01],
           [ 5.2456e-02,  2.7158e-01]],

          [[ 2.9460e-01,  2.7490e+00],
           [ 5.6122e-01,  5.5008e+00],
           [ 8.0513e-01,  8.2498e+00],
           ...,
           [ 2.2364e+00,  2.7110e+01],
           [ 2.4429e+00,  2.9695e+01],
           [ 2.6677e+00,  3.2246e+01]],

          [[ 7.5910e-01,  6.3046e+00],
           [ 1.5279e+00,  1.2651e+01],
           [ 2.3061e+00,  1.9041e+01],
           ...,
           [ 8.0204e+00,  6.3893e+01],
           [ 8.8612e+00,  7.0269e+01],
           [ 9.6926e+00,  7.6645e+01]],

          [[ 1.6821e-01,  1.4911e+00],
           [ 3.3407e-01,  2.9825e+00],
           [ 4.8887e-01,  4.4740e+00],
           ...,
           [ 9.1529e-01,  1.4598e+01],
           [ 9.4882e-01,  1.5968e+01],
           [ 9.8605e-01,  1.7304e+01]],

          [[ 5.3817e-01,  4.2785e+00],
           [ 1.0841e+00,  8.5936e+00],
           [ 1.6332e+00,  1.2904e+01],
           ...,
           [ 5.1792e+00,  4.2484e+01],
           [ 5.5528e+00,  4.6487e+01],
           [ 5.8878e+00,  5.0444e+01]],

          [[ 4.3170e-01,  2.8887e+00],
           [ 1.1526e+00,  5.7346e+00],
           [ 2.2106e+00,  8.5528e+00],
           ...,
           [ 1.9879e+01,  2.3671e+01],
           [ 2.3534e+01,  2.5075e+01],
           [ 2.7319e+01,  2.6389e+01]]],


         [[[ 5.5873e-02,  3.8964e-01],
           [ 1.1977e-01,  7.6985e-01],
           [ 1.9441e-01,  1.1398e+00],
           ...,
           [ 8.9088e-01,  3.4838e+00],
           [ 9.9383e-01,  3.7928e+00],
           [ 1.0955e+00,  4.0981e+00]],

          [[ 1.3865e-03,  1.9304e-02],
           [ 2.2033e-03,  3.4896e-02],
           [ 2.1591e-03,  4.6485e-02],
           ...,
           [-3.7544e-03,  1.0084e-01],
           [-3.5077e-03,  1.1793e-01],
           [-2.5836e-03,  1.3859e-01]],

          [[ 8.9549e-02,  7.5258e-01],
           [ 1.8074e-01,  1.5075e+00],
           [ 2.7362e-01,  2.2624e+00],
           ...,
           [ 9.4593e-01,  7.4759e+00],
           [ 1.0414e+00,  8.2043e+00],
           [ 1.1353e+00,  8.9268e+00]],

          [[ 1.5756e-01,  1.4336e+00],
           [ 3.2086e-01,  2.8765e+00],
           [ 4.8917e-01,  4.3242e+00],
           ...,
           [ 1.6837e+00,  1.4017e+01],
           [ 1.8547e+00,  1.5300e+01],
           [ 2.0259e+00,  1.6558e+01]],

          [[ 2.7781e-02,  6.2083e-01],
           [ 8.9358e-03,  1.2442e+00],
           [-6.1870e-02,  1.8674e+00],
           ...,
           [-1.6253e+00,  5.8684e+00],
           [-1.9161e+00,  6.3778e+00],
           [-2.2074e+00,  6.8739e+00]],

          [[ 7.3882e-02,  5.8439e-01],
           [ 1.5176e-01,  1.1708e+00],
           [ 2.3382e-01,  1.7575e+00],
           ...,
           [ 8.8463e-01,  5.7922e+00],
           [ 9.7906e-01,  6.3498e+00],
           [ 1.0725e+00,  6.9017e+00]]],


         [[[-3.4022e-04,  2.0073e-03],
           [-7.0343e-04,  4.3583e-03],
           [-9.8129e-04,  6.5703e-03],
           ...,
           [-2.4349e-03,  1.7938e-02],
           [-3.0147e-03,  1.8204e-02],
           [-3.7509e-03,  1.8260e-02]],

          [[-3.2902e-03, -2.6247e-02],
           [-5.7128e-03, -5.5010e-02],
           [-8.5380e-03, -8.3288e-02],
           ...,
           [-3.6229e-02, -2.2511e-01],
           [-3.8009e-02, -2.3302e-01],
           [-3.8705e-02, -2.3637e-01]],

          [[ 4.5730e-01, -6.3208e-02],
           [ 9.4689e-01, -9.8507e-02],
           [ 1.4368e+00, -1.1003e-01],
           ...,
           [ 5.1161e+00,  6.4025e-01],
           [ 5.5279e+00,  8.6346e-01],
           [ 5.8983e+00,  1.0941e+00]],

          [[-3.1503e-01,  6.7064e-02],
           [-6.5930e-01,  1.4213e-01],
           [-9.5749e-01,  1.9853e-01],
           ...,
           [-2.3922e+00,  4.8974e-01],
           [-2.4900e+00,  4.9925e-01],
           [-2.5736e+00,  5.1598e-01]],

          [[-5.1412e-02,  8.7119e-03],
           [-1.0604e-01,  1.7998e-02],
           [-1.5706e-01,  2.7674e-02],
           ...,
           [-4.0839e-01,  7.9578e-02],
           [-4.2611e-01,  8.4113e-02],
           [-4.4066e-01,  8.7629e-02]],

          [[ 5.3676e-02,  2.0429e-03],
           [ 1.0852e-01,  2.6192e-03],
           [ 1.6158e-01,  1.9758e-03],
           ...,
           [ 3.6020e-01, -1.2268e-02],
           [ 3.6410e-01, -1.2734e-02],
           [ 3.6466e-01, -1.3613e-02]]]],



        [[[[ 1.1348e-01, -4.0807e+00],
           [ 2.3058e-01, -8.2280e+00],
           [ 3.5000e-01, -1.2431e+01],
           ...,
           [ 1.1478e+00, -4.2326e+01],
           [ 1.2430e+00, -4.6531e+01],
           [ 1.3314e+00, -5.0695e+01]],

          [[ 6.7797e-04, -2.0543e-02],
           [ 1.4089e-03, -3.6905e-02],
           [ 2.1132e-03, -4.9950e-02],
           ...,
           [ 7.6936e-03, -1.4817e-01],
           [ 9.2074e-03, -1.7567e-01],
           [ 1.1003e-02, -2.0821e-01]],

          [[ 4.1738e-02, -2.7484e+00],
           [ 4.8135e-02, -5.5207e+00],
           [ 1.7600e-02, -8.3040e+00],
           ...,
           [-1.0458e+00, -2.7315e+01],
           [-1.2670e+00, -2.9882e+01],
           [-1.4940e+00, -3.2404e+01]],

          [[ 1.8095e-01, -6.1707e+00],
           [ 3.8106e-01, -1.2407e+01],
           [ 6.0109e-01, -1.8701e+01],
           ...,
           [ 2.6869e+00, -6.3334e+01],
           [ 3.0511e+00, -6.9672e+01],
           [ 3.4276e+00, -7.5974e+01]],

          [[ 3.1314e-01, -2.3938e+00],
           [ 9.1373e-01, -4.8139e+00],
           [ 1.8309e+00, -7.2268e+00],
           ...,
           [ 1.6584e+01, -2.2003e+01],
           [ 1.9551e+01, -2.3730e+01],
           [ 2.2636e+01, -2.5387e+01]],

          [[ 1.5329e-02, -1.4131e+00],
           [ 6.5272e-03, -2.7977e+00],
           [-2.8466e-02, -4.1599e+00],
           ...,
           [-9.9725e-01, -1.3361e+01],
           [-1.2095e+00, -1.4654e+01],
           [-1.4300e+00, -1.5941e+01]]],


         [[[-8.2672e-05, -2.4281e-02],
           [-1.4819e-04, -4.5148e-02],
           [-4.2898e-04, -6.3098e-02],
           ...,
           [-8.1873e-03, -2.0331e-01],
           [-9.9932e-03, -2.3741e-01],
           [-1.2287e-02, -2.7633e-01]],

          [[ 1.0947e-01, -2.7626e+00],
           [ 2.4703e-01, -5.5239e+00],
           [ 4.0664e-01, -8.2790e+00],
           ...,
           [ 1.7414e+00, -2.7147e+01],
           [ 1.9140e+00, -2.9734e+01],
           [ 2.0636e+00, -3.2290e+01]],

          [[ 1.6848e-01, -6.3479e+00],
           [ 3.3348e-01, -1.2738e+01],
           [ 4.9542e-01, -1.9173e+01],
           ...,
           [ 1.3836e+00, -6.4380e+01],
           [ 1.4816e+00, -7.0810e+01],
           [ 1.5890e+00, -7.7239e+01]],

          [[ 5.1064e-02, -1.4997e+00],
           [ 1.0448e-01, -2.9993e+00],
           [ 1.6886e-01, -4.4975e+00],
           ...,
           [ 1.2235e+00, -1.4576e+01],
           [ 1.3901e+00, -1.5936e+01],
           [ 1.5481e+00, -1.7263e+01]],

          [[ 9.1568e-02, -4.3113e+00],
           [ 1.8078e-01, -8.6599e+00],
           [ 2.6617e-01, -1.3004e+01],
           ...,
           [ 1.0722e+00, -4.2786e+01],
           [ 1.2863e+00, -4.6799e+01],
           [ 1.5320e+00, -5.0764e+01]],

          [[-5.7920e-03, -2.9207e+00],
           [-3.0396e-01, -5.8414e+00],
           [-9.3961e-01, -8.7838e+00],
           ...,
           [-1.6214e+01, -2.6318e+01],
           [-1.9625e+01, -2.8239e+01],
           [-2.3179e+01, -3.0091e+01]]],


         [[[ 1.5498e-03, -3.9362e-01],
           [-6.2123e-03, -7.7908e-01],
           [-2.6096e-02, -1.1560e+00],
           ...,
           [-3.7327e-01, -3.5765e+00],
           [-4.3006e-01, -3.8972e+00],
           [-4.8612e-01, -4.2141e+00]],

          [[ 1.4436e-03, -1.9300e-02],
           [ 2.9096e-03, -3.4845e-02],
           [ 4.6434e-03, -4.6303e-02],
           ...,
           [ 1.8422e-02, -9.9219e-02],
           [ 2.0669e-02, -1.1615e-01],
           [ 2.2769e-02, -1.3674e-01]],

          [[ 2.1166e-02, -7.5759e-01],
           [ 4.1048e-02, -1.5177e+00],
           [ 5.9263e-02, -2.2782e+00],
           ...,
           [ 1.5448e-01, -7.5339e+00],
           [ 1.6624e-01, -8.2684e+00],
           [ 1.7874e-01, -8.9969e+00]],

          [[ 5.3204e-02, -1.4412e+00],
           [ 1.0209e-01, -2.8926e+00],
           [ 1.4671e-01, -4.3493e+00],
           ...,
           [ 3.7853e-01, -1.4113e+01],
           [ 3.9645e-01, -1.5407e+01],
           [ 4.1064e-01, -1.6677e+01]],

          [[ 6.3059e-02, -6.1824e-01],
           [ 1.7262e-01, -1.2322e+00],
           [ 3.3355e-01, -1.8384e+00],
           ...,
           [ 2.4638e+00, -5.5686e+00],
           [ 2.8258e+00, -6.0302e+00],
           [ 3.1863e+00, -6.4785e+00]],

          [[ 1.2137e-02, -5.8892e-01],
           [ 2.0615e-02, -1.1804e+00],
           [ 2.4991e-02, -1.7728e+00],
           ...,
           [-3.0430e-02, -5.8593e+00],
           [-4.2519e-02, -6.4247e+00],
           [-5.4446e-02, -6.9843e+00]]],


         [[[ 6.2933e-04, -1.9362e-03],
           [ 1.3315e-03, -4.2092e-03],
           [ 1.9290e-03, -6.3569e-03],
           ...,
           [ 5.0249e-03, -1.7391e-02],
           [ 5.6375e-03, -1.7570e-02],
           [ 6.3738e-03, -1.7518e-02]],

          [[-5.7298e-04,  2.6447e-02],
           [-2.3711e-03,  5.5255e-02],
           [-3.7001e-03,  8.3642e-02],
           ...,
           [ 3.0111e-03,  2.2799e-01],
           [ 3.6189e-03,  2.3607e-01],
           [ 3.8182e-03,  2.3949e-01]],

          [[-4.6163e-01, -4.1622e-03],
           [-9.5113e-01, -4.0642e-02],
           [-1.4375e+00, -1.0070e-01],
           ...,
           [-4.9680e+00, -1.3795e+00],
           [-5.3429e+00, -1.6604e+00],
           [-5.6757e+00, -1.9427e+00]],

          [[ 3.2144e-01, -2.0402e-02],
           [ 6.7298e-01, -4.4457e-02],
           [ 9.7621e-01, -5.6765e-02],
           ...,
           [ 2.4380e+00, -1.3563e-01],
           [ 2.5362e+00, -1.3077e-01],
           [ 2.6213e+00, -1.3513e-01]],

          [[ 5.2132e-02, -1.1208e-03],
           [ 1.0753e-01, -2.3401e-03],
           [ 1.5942e-01, -4.4729e-03],
           ...,
           [ 4.1563e-01, -1.9167e-02],
           [ 4.3382e-01, -2.1068e-02],
           [ 4.4873e-01, -2.2426e-02]],

          [[-5.2804e-02, -9.8492e-03],
           [-1.0698e-01, -1.8419e-02],
           [-1.5956e-01, -2.5519e-02],
           ...,
           [-3.5814e-01, -4.0395e-02],
           [-3.6206e-01, -4.0503e-02],
           [-3.6275e-01, -3.9715e-02]]]],



        [[[[-9.9216e-03,  4.0822e+00],
           [-2.1784e-02,  8.2312e+00],
           [-3.4540e-02,  1.2436e+01],
           ...,
           [-7.3674e-02,  4.2342e+01],
           [-6.2230e-02,  4.6548e+01],
           [-4.4899e-02,  5.0713e+01]],

          [[-1.5661e-04,  2.0554e-02],
           [-4.7224e-04,  3.6929e-02],
           [-8.4536e-04,  4.9987e-02],
           ...,
           [-3.9323e-03,  1.4832e-01],
           [-4.7480e-03,  1.7585e-01],
           [-5.7174e-03,  2.0842e-01]],

          [[ 2.7996e-02,  2.7486e+00],
           [ 9.1930e-02,  5.5202e+00],
           [ 1.9306e-01,  8.3018e+00],
           ...,
           [ 1.7384e+00,  2.7280e+01],
           [ 2.0246e+00,  2.9840e+01],
           [ 2.3155e+00,  3.2355e+01]],

          [[-2.4357e-02,  6.1733e+00],
           [-6.6198e-02,  1.2413e+01],
           [-1.2649e-01,  1.8711e+01],
           ...,
           [-1.0794e+00,  6.3382e+01],
           [-1.2827e+00,  6.9727e+01],
           [-1.4992e+00,  7.6037e+01]],

          [[-2.5232e-01,  2.4010e+00],
           [-7.9132e-01,  4.8355e+00],
           [-1.6470e+00,  7.2710e+00],
           ...,
           [-1.6020e+01,  2.2417e+01],
           [-1.8943e+01,  2.4218e+01],
           [-2.1985e+01,  2.5953e+01]],

          [[ 2.0524e-02,  1.4131e+00],
           [ 6.4446e-02,  2.7969e+00],
           [ 1.3399e-01,  4.1579e+00],
           ...,
           [ 1.3359e+00,  1.3331e+01],
           [ 1.5808e+00,  1.4618e+01],
           [ 1.8339e+00,  1.5900e+01]]],


         [[[ 6.9860e-04,  2.4271e-02],
           [ 1.2935e-03,  4.5130e-02],
           [ 2.0295e-03,  6.3067e-02],
           ...,
           [ 1.3342e-02,  2.0304e-01],
           [ 1.6013e-02,  2.3708e-01],
           [ 1.9293e-02,  2.7593e-01]],

          [[-3.9350e-02,  2.7645e+00],
           [-1.0682e-01,  5.5284e+00],
           [-1.9649e-01,  8.2867e+00],
           ...,
           [-1.0521e+00,  2.7182e+01],
           [-1.1591e+00,  2.9773e+01],
           [-1.2438e+00,  3.2332e+01]],

          [[-7.3944e-03,  6.3501e+00],
           [-1.0222e-02,  1.2743e+01],
           [-8.8719e-03,  1.9180e+01],
           ...,
           [ 2.4998e-01,  6.4394e+01],
           [ 3.1514e-01,  7.0825e+01],
           [ 3.7092e-01,  7.7254e+01]],

          [[-1.3003e-02,  1.5005e+00],
           [-2.8356e-02,  3.0010e+00],
           [-5.4716e-02,  4.5003e+00],
           ...,
           [-8.5339e-01,  1.4602e+01],
           [-9.8541e-01,  1.5966e+01],
           [-1.1097e+00,  1.7296e+01]],

          [[ 1.7830e-02,  4.3122e+00],
           [ 3.8958e-02,  8.6617e+00],
           [ 6.3794e-02,  1.3007e+01],
           ...,
           [ 1.3563e-02,  4.2799e+01],
           [-9.8665e-02,  4.6817e+01],
           [-2.4378e-01,  5.0786e+01]],

          [[ 7.9883e-02,  2.9197e+00],
           [ 4.5204e-01,  5.8318e+00],
           [ 1.1621e+00,  8.7571e+00],
           ...,
           [ 1.6877e+01,  2.5898e+01],
           [ 2.0335e+01,  2.7732e+01],
           [ 2.3935e+01,  2.9493e+01]]],


         [[[ 8.4362e-03,  3.9354e-01],
           [ 2.5974e-02,  7.7868e-01],
           [ 5.5413e-02,  1.1550e+00],
           ...,
           [ 4.6388e-01,  3.5659e+00],
           [ 5.2879e-01,  3.8850e+00],
           [ 5.9286e-01,  4.2004e+00]],

          [[-9.5354e-04,  1.9330e-02],
           [-2.0248e-03,  3.4907e-02],
           [-3.4673e-03,  4.6405e-02],
           ...,
           [-1.5899e-02,  9.9654e-02],
           [-1.7716e-02,  1.1664e-01],
           [-1.9293e-02,  1.3727e-01]],

          [[-1.9408e-03,  7.5789e-01],
           [-2.5329e-03,  1.5183e+00],
           [-1.4512e-03,  2.2789e+00],
           ...,
           [ 3.6693e-02,  7.5354e+00],
           [ 4.3564e-02,  8.2700e+00],
           [ 4.9552e-02,  8.9985e+00]],

          [[-1.6625e-02,  1.4421e+00],
           [-2.8678e-02,  2.8942e+00],
           [-3.6331e-02,  4.3516e+00],
           ...,
           [-2.0398e-02,  1.4118e+01],
           [-5.4920e-03,  1.5412e+01],
           [ 1.2553e-02,  1.6682e+01]],

          [[-4.7355e-02,  6.1964e-01],
           [-1.4130e-01,  1.2362e+00],
           [-2.8681e-01,  1.8463e+00],
           ...,
           [-2.3217e+00,  5.6293e+00],
           [-2.6719e+00,  6.0999e+00],
           [-3.0209e+00,  6.5573e+00]],

          [[ 2.8070e-03,  5.8904e-01],
           [ 9.3365e-03,  1.1805e+00],
           [ 1.9990e-02,  1.7729e+00],
           ...,
           [ 1.7906e-01,  5.8566e+00],
           [ 2.0549e-01,  6.4216e+00],
           [ 2.3161e-01,  6.9807e+00]]],


         [[[-5.8001e-04,  1.9516e-03],
           [-1.2243e-03,  4.2416e-03],
           [-1.7671e-03,  6.4038e-03],
           ...,
           [-4.5821e-03,  1.7513e-02],
           [-5.1899e-03,  1.7707e-02],
           [-5.9274e-03,  1.7674e-02]],

          [[-9.8103e-05, -2.6453e-02],
           [ 9.6858e-04, -5.5298e-02],
           [ 1.5770e-03, -8.3709e-02],
           ...,
           [-8.7937e-03, -2.2784e-01],
           [-9.6064e-03, -2.3590e-01],
           [-9.8924e-03, -2.3932e-01]],

          [[ 4.6159e-01, -7.5499e-03],
           [ 9.5185e-01,  1.6501e-02],
           [ 1.4396e+00,  6.4199e-02],
           ...,
           [ 5.0014e+00,  1.2531e+00],
           [ 5.3833e+00,  1.5244e+00],
           [ 5.7231e+00,  1.7981e+00]],

          [[-3.2082e-01,  2.8550e-02],
           [-6.7163e-01,  6.1515e-02],
           [-9.7446e-01,  8.1511e-02],
           ...,
           [-2.4338e+00,  1.9743e-01],
           [-2.5320e+00,  1.9507e-01],
           [-2.6170e+00,  2.0158e-01]],

          [[-5.2087e-02,  2.4429e-03],
           [-1.0744e-01,  5.0673e-03],
           [-1.5925e-01,  8.5155e-03],
           ...,
           [-4.1501e-01,  2.9704e-02],
           [-4.3315e-01,  3.2067e-02],
           [-4.4801e-01,  3.3802e-02]],

          [[ 5.3037e-02,  8.5065e-03],
           [ 1.0741e-01,  1.5699e-02],
           [ 1.6016e-01,  2.1463e-02],
           ...,
           [ 3.5905e-01,  3.1297e-02],
           [ 3.6298e-01,  3.1305e-02],
           [ 3.6364e-01,  3.0500e-02]]]]])
(Pdb) torch.Size([4, 4, 6, 12, 2])
(Pdb) torch.Size([4, 6, 12, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(106)anchor_coordinate_transform()
-> transformed_anchors = bbox_centers[:, None, None, None, :2] + transformed_anchors
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(107)anchor_coordinate_transform()
-> batched_anchors.append(transformed_anchors)
(Pdb) torch.Size([4, 4, 6, 12, 2])
(Pdb) 102  	            transformed_anchors = rearrange(transformed_anchors, 'b g m t c -> b g m c t')  # 1, num_groups, num_modes, 12, 2 -> 1, num_groups, num_modes, 2, 12
103  	            transformed_anchors = torch.matmul(rot_yaw, transformed_anchors)# -> num_agents, num_groups, num_modes, 12, 2
104  	            transformed_anchors = rearrange(transformed_anchors, 'b g m c t -> b g m t c')
105  	        if with_translation_transform:
106  	            transformed_anchors = bbox_centers[:, None, None, None, :2] + transformed_anchors
107  ->	        batched_anchors.append(transformed_anchors)
108  	    return torch.stack(batched_anchors)
109  	
110  	
111  	def trajectory_coordinate_transform(trajectory, bbox_results, with_translation_transform=True, with_rotation_transform=True):
112  	    """
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(94)anchor_coordinate_transform()
-> for i in range(batch_size):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(108)anchor_coordinate_transform()
-> return torch.stack(batched_anchors)
(Pdb) --Return--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/models/utils/functional.py(108)anchor_coordinate_transform()->tensor([[[[[[...992e-02]]]]]])
-> return torch.stack(batched_anchors)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(262)forward()
-> scene_level_offset_anchors = anchor_coordinate_transform(agent_level_anchors, track_bbox_results, with_translation_transform=False)  # B, A, G, P ,12 ,2
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(264)forward()
-> agent_level_norm = norm_points(agent_level_anchors, self.pc_range)
(Pdb) torch.Size([1, 4, 4, 6, 12, 2])
(Pdb) torch.Size([4, 6, 12, 2])
(Pdb) *** AttributeError: 'list' object has no attribute 'shape'
(Pdb) [LiDARInstance3DBoxes(
    tensor([[-7.5262e-01, -2.4579e+01, -2.2621e+00,  1.9450e+00,  4.5364e+00,
          1.5434e+00, -3.1230e+00,  8.8571e-02,  5.5166e+00],
        [-1.2292e+01,  3.5435e+01, -9.5619e-01,  7.1796e-01,  8.1444e-01,
          1.7480e+00,  3.0222e+00, -2.9149e-01,  1.2141e+00],
        [-4.4362e+00, -1.0457e+01, -1.9604e+00,  5.6273e-01,  1.7301e+00,
          1.0861e+00,  2.6956e-02, -1.2011e-03, -9.9059e-04],
        [ 3.1940e-02, -6.2492e-02, -7.7301e-01,  1.7408e+00,  4.1469e+00,
          1.5712e+00, -3.1400e+00, -1.7210e-01,  6.9688e+00]])), tensor([0.8999, 0.8660, 0.8401, 0.4058]), tensor([0, 8, 7, 0]), tensor([1, 2, 0, 0]), tensor([True, True, True])]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(265)forward()
-> scene_level_ego_norm = norm_points(scene_level_ego_anchors, self.pc_range)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(266)forward()
-> scene_level_offset_norm = norm_points(scene_level_offset_anchors, self.pc_range)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(269)forward()
-> agent_level_embedding = self.agent_level_embedding_layer(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(270)forward()
-> pos2posemb2d(agent_level_norm[..., -1, :]))  # G, P, D
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(269)forward()
-> agent_level_embedding = self.agent_level_embedding_layer(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(271)forward()
-> scene_level_ego_embedding = self.scene_level_ego_embedding_layer(
(Pdb) torch.Size([4, 6, 256])
(Pdb) 266  	        scene_level_offset_norm = norm_points(scene_level_offset_anchors, self.pc_range)
267  	
268  	        # we only use the last point of the anchor
269  	        agent_level_embedding = self.agent_level_embedding_layer(
270  	            pos2posemb2d(agent_level_norm[..., -1, :]))  # G, P, D
271  ->	        scene_level_ego_embedding = self.scene_level_ego_embedding_layer(
272  	            pos2posemb2d(scene_level_ego_norm[..., -1, :]))  # B, A, G, P , D
273  	        scene_level_offset_embedding = self.scene_level_offset_embedding_layer(
274  	            pos2posemb2d(scene_level_offset_norm[..., -1, :]))  # B, A, G, P , D
275  	
276  	        batch_size, num_agents = scene_level_ego_embedding.shape[:2]
(Pdb) torch.Size([4, 6, 12, 2])
(Pdb) torch.Size([4, 6, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(272)forward()
-> pos2posemb2d(scene_level_ego_norm[..., -1, :]))  # B, A, G, P , D
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(271)forward()
-> scene_level_ego_embedding = self.scene_level_ego_embedding_layer(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(273)forward()
-> scene_level_offset_embedding = self.scene_level_offset_embedding_layer(
(Pdb) torch.Size([1, 4, 4, 6, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(274)forward()
-> pos2posemb2d(scene_level_offset_norm[..., -1, :]))  # B, A, G, P , D
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(273)forward()
-> scene_level_offset_embedding = self.scene_level_offset_embedding_layer(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(276)forward()
-> batch_size, num_agents = scene_level_ego_embedding.shape[:2]
(Pdb) torch.Size([1, 4, 4, 6, 256])
(Pdb) torch.Size([1, 4])
(Pdb) *** NameError: name 'agent_level_embeddin' is not defined
(Pdb) torch.Size([4, 6, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(277)forward()
-> agent_level_embedding = agent_level_embedding[None,None, ...].expand(batch_size, num_agents, -1, -1, -1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(278)forward()
-> learnable_embed = learnable_query_pos[None, None, ...].expand(batch_size, num_agents, -1, -1, -1)
(Pdb) torch.Size([1, 4, 4, 6, 256])
(Pdb) torch.Size([4, 6, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(283)forward()
-> scene_level_offset_anchors = self.group_mode_query_pos(track_bbox_results, scene_level_offset_anchors)
(Pdb) --Call--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(356)group_mode_query_pos()
-> def group_mode_query_pos(self, bbox_results, mode_query_pos):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(367)group_mode_query_pos()
-> batch_size = len(bbox_results)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(368)group_mode_query_pos()
-> agent_num = mode_query_pos.shape[1]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(369)group_mode_query_pos()
-> batched_mode_query_pos = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(370)group_mode_query_pos()
-> self.cls2group = self.cls2group.to(mode_query_pos.device)
(Pdb) tensor([0, 0, 0, 0, 0, 3, 1, 1, 2, 3])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(373)group_mode_query_pos()
-> for i in range(batch_size):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(374)group_mode_query_pos()
-> bboxes, scores, labels, bbox_index, mask = bbox_results[i]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(375)group_mode_query_pos()
-> label = labels.to(mode_query_pos.device)
(Pdb) tensor([0, 8, 7, 0])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(376)group_mode_query_pos()
-> grouped_label = self.cls2group[label]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(377)group_mode_query_pos()
-> grouped_mode_query_pos = []
(Pdb) tensor([0, 2, 1, 0])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(378)group_mode_query_pos()
-> for j in range(agent_num):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(379)group_mode_query_pos()
-> grouped_mode_query_pos.append(
(Pdb) torch.Size([1, 4, 4, 6, 12, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(380)group_mode_query_pos()
-> mode_query_pos[i, j, grouped_label[j]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(379)group_mode_query_pos()
-> grouped_mode_query_pos.append(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(378)group_mode_query_pos()
-> for j in range(agent_num):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(379)group_mode_query_pos()
-> grouped_mode_query_pos.append(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(380)group_mode_query_pos()
-> mode_query_pos[i, j, grouped_label[j]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(379)group_mode_query_pos()
-> grouped_mode_query_pos.append(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(378)group_mode_query_pos()
-> for j in range(agent_num):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(379)group_mode_query_pos()
-> grouped_mode_query_pos.append(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(380)group_mode_query_pos()
-> mode_query_pos[i, j, grouped_label[j]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(379)group_mode_query_pos()
-> grouped_mode_query_pos.append(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(378)group_mode_query_pos()
-> for j in range(agent_num):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(379)group_mode_query_pos()
-> grouped_mode_query_pos.append(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(380)group_mode_query_pos()
-> mode_query_pos[i, j, grouped_label[j]])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(379)group_mode_query_pos()
-> grouped_mode_query_pos.append(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(378)group_mode_query_pos()
-> for j in range(agent_num):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(381)group_mode_query_pos()
-> batched_mode_query_pos.append(torch.stack(grouped_mode_query_pos))
(Pdb) *** AttributeError: 'list' object has no attribute 'shape'
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(373)group_mode_query_pos()
-> for i in range(batch_size):
(Pdb) torch.Size([4, 6, 12, 2])
(Pdb) *** IndexError: list index out of range
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(382)group_mode_query_pos()
-> return torch.stack(batched_mode_query_pos)
(Pdb) --Return--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(382)group_mode_query_pos()->tensor([[[[[-...5900e+01]]]]])
-> return torch.stack(batched_mode_query_pos)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(287)forward()
-> agent_level_embedding = self.group_mode_query_pos(
(Pdb) 282  	        # B, A, G, P ,12 ,2 -> B, A, P ,12 ,2
283  	        scene_level_offset_anchors = self.group_mode_query_pos(track_bbox_results, scene_level_offset_anchors)
284  	
285  	        # select class embedding
286  	        # B, A, G, P , D-> B, A, P , D
287  ->	        agent_level_embedding = self.group_mode_query_pos(
288  	            track_bbox_results, agent_level_embedding)
289  	        scene_level_ego_embedding = self.group_mode_query_pos(
290  	            track_bbox_results, scene_level_ego_embedding)  # B, A, G, P , D-> B, A, P , D
291  	
292  	        # B, A, G, P , D -> B, A, P , D
(Pdb) torch.Size([1, 4, 6, 12, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(288)forward()
-> track_bbox_results, agent_level_embedding)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(287)forward()
-> agent_level_embedding = self.group_mode_query_pos(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(289)forward()
-> scene_level_ego_embedding = self.group_mode_query_pos(
(Pdb) torch.Size([1, 4, 6, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(290)forward()
-> track_bbox_results, scene_level_ego_embedding)  # B, A, G, P , D-> B, A, P , D
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(289)forward()
-> scene_level_ego_embedding = self.group_mode_query_pos(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(293)forward()
-> scene_level_offset_embedding = self.group_mode_query_pos(
(Pdb) torch.Size([1, 4, 6, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(294)forward()
-> track_bbox_results, scene_level_offset_embedding)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(293)forward()
-> scene_level_offset_embedding = self.group_mode_query_pos(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(295)forward()
-> learnable_embed = self.group_mode_query_pos(
(Pdb) 290  	            track_bbox_results, scene_level_ego_embedding)  # B, A, G, P , D-> B, A, P , D
291  	
292  	        # B, A, G, P , D -> B, A, P , D
293  	        scene_level_offset_embedding = self.group_mode_query_pos(
294  	            track_bbox_results, scene_level_offset_embedding)
295  ->	        learnable_embed = self.group_mode_query_pos(
296  	            track_bbox_results, learnable_embed)
297  	
298  	        init_reference = scene_level_offset_anchors.detach()
299  	
300  	        outputs_traj_scores = []
(Pdb) torch.Size([1, 4, 4, 6, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(296)forward()
-> track_bbox_results, learnable_embed)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(295)forward()
-> learnable_embed = self.group_mode_query_pos(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(298)forward()
-> init_reference = scene_level_offset_anchors.detach()
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(300)forward()
-> outputs_traj_scores = []
(Pdb) torch.Size([1, 4, 6, 12, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(301)forward()
-> outputs_trajs = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(303)forward()
-> inter_states, inter_references = self.motionformer(
(Pdb) MotionTransformerDecoder(
  (intention_interaction_layers): IntentionInteraction(
    (interaction_transformer): TransformerEncoderLayer(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
      )
      (linear1): Linear(in_features=256, out_features=512, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (linear2): Linear(in_features=512, out_features=256, bias=True)
      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
    )
  )
  (track_agent_interaction_layers): ModuleList(
    (0): TrackAgentInteraction(
      (interaction_transformer): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=512, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=512, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (1): TrackAgentInteraction(
      (interaction_transformer): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=512, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=512, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (2): TrackAgentInteraction(
      (interaction_transformer): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=512, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=512, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (map_interaction_layers): ModuleList(
    (0): MapInteraction(
      (interaction_transformer): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=512, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=512, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (1): MapInteraction(
      (interaction_transformer): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=512, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=512, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (2): MapInteraction(
      (interaction_transformer): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=512, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=512, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (bev_interaction_layers): ModuleList(
    (0): MotionTransformerAttentionLayer(
      (attentions): ModuleList(
        (0): MotionDeformableAttention(
          (dropout): Dropout(p=0.1, inplace=False)
          (sampling_offsets): Linear(in_features=256, out_features=768, bias=True)
          (attention_weights): Linear(in_features=256, out_features=384, bias=True)
          (value_proj): Linear(in_features=256, out_features=256, bias=True)
          (output_proj): Sequential(
            (0): Linear(in_features=3072, out_features=256, bias=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): ReLU(inplace=True)
          )
        )
      )
      (ffns): ModuleList(
        (0): FFN(
          (activate): ReLU(inplace=True)
          (layers): Sequential(
            (0): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.1, inplace=False)
            )
            (1): Linear(in_features=512, out_features=256, bias=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (dropout_layer): Identity()
        )
      )
      (norms): ModuleList(
        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): MotionTransformerAttentionLayer(
      (attentions): ModuleList(
        (0): MotionDeformableAttention(
          (dropout): Dropout(p=0.1, inplace=False)
          (sampling_offsets): Linear(in_features=256, out_features=768, bias=True)
          (attention_weights): Linear(in_features=256, out_features=384, bias=True)
          (value_proj): Linear(in_features=256, out_features=256, bias=True)
          (output_proj): Sequential(
            (0): Linear(in_features=3072, out_features=256, bias=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): ReLU(inplace=True)
          )
        )
      )
      (ffns): ModuleList(
        (0): FFN(
          (activate): ReLU(inplace=True)
          (layers): Sequential(
            (0): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.1, inplace=False)
            )
            (1): Linear(in_features=512, out_features=256, bias=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (dropout_layer): Identity()
        )
      )
      (norms): ModuleList(
        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): MotionTransformerAttentionLayer(
      (attentions): ModuleList(
        (0): MotionDeformableAttention(
          (dropout): Dropout(p=0.1, inplace=False)
          (sampling_offsets): Linear(in_features=256, out_features=768, bias=True)
          (attention_weights): Linear(in_features=256, out_features=384, bias=True)
          (value_proj): Linear(in_features=256, out_features=256, bias=True)
          (output_proj): Sequential(
            (0): Linear(in_features=3072, out_features=256, bias=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): ReLU(inplace=True)
          )
        )
      )
      (ffns): ModuleList(
        (0): FFN(
          (activate): ReLU(inplace=True)
          (layers): Sequential(
            (0): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.1, inplace=False)
            )
            (1): Linear(in_features=512, out_features=256, bias=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (dropout_layer): Identity()
        )
      )
      (norms): ModuleList(
        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (static_dynamic_fuser): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=256, bias=True)
  )
  (dynamic_embed_fuser): Sequential(
    (0): Linear(in_features=768, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=256, bias=True)
  )
  (in_query_fuser): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=256, bias=True)
  )
  (out_query_fuser): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=256, bias=True)
  )
)
(Pdb) 298  	        init_reference = scene_level_offset_anchors.detach()
299  	
300  	        outputs_traj_scores = []
301  	        outputs_trajs = []
302  	
303  ->	        inter_states, inter_references = self.motionformer(
304  	            track_query,  # B, A_track, D
305  	            lane_query,  # B, M, D
306  	            track_query_pos=track_query_pos,
307  	            lane_query_pos=lane_query_pos,
308  	            track_bbox_results=track_bbox_results,
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1117)__getattr__()
-> def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1118)__getattr__()
-> if '_parameters' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1119)__getattr__()
-> _parameters = self.__dict__['_parameters']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1120)__getattr__()
-> if name in _parameters:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1122)__getattr__()
-> if '_buffers' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1123)__getattr__()
-> _buffers = self.__dict__['_buffers']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1124)__getattr__()
-> if name in _buffers:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1126)__getattr__()
-> if '_modules' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1127)__getattr__()
-> modules = self.__dict__['_modules']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1128)__getattr__()
-> if name in modules:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()
-> return modules[name]
(Pdb) --Return--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()->MotionTransfo...as=True)
  )
)
-> return modules[name]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(304)forward()
-> track_query,  # B, A_track, D
(Pdb) 299  	
300  	        outputs_traj_scores = []
301  	        outputs_trajs = []
302  	
303  	        inter_states, inter_references = self.motionformer(
304  ->	            track_query,  # B, A_track, D
305  	            lane_query,  # B, M, D
306  	            track_query_pos=track_query_pos,
307  	            lane_query_pos=lane_query_pos,
308  	            track_bbox_results=track_bbox_results,
309  	            bev_embed=bev_embed,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(305)forward()
-> lane_query,  # B, M, D
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(306)forward()
-> track_query_pos=track_query_pos,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(307)forward()
-> lane_query_pos=lane_query_pos,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(308)forward()
-> track_bbox_results=track_bbox_results,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(309)forward()
-> bev_embed=bev_embed,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(310)forward()
-> reference_trajs=init_reference,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(311)forward()
-> traj_reg_branches=self.traj_reg_branches,
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1117)__getattr__()
-> def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1118)__getattr__()
-> if '_parameters' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1119)__getattr__()
-> _parameters = self.__dict__['_parameters']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1120)__getattr__()
-> if name in _parameters:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1122)__getattr__()
-> if '_buffers' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1123)__getattr__()
-> _buffers = self.__dict__['_buffers']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1124)__getattr__()
-> if name in _buffers:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1126)__getattr__()
-> if '_modules' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1127)__getattr__()
-> modules = self.__dict__['_modules']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1128)__getattr__()
-> if name in modules:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()
-> return modules[name]
(Pdb) --Return--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()->ModuleList(
 ...as=True)
  )
)
-> return modules[name]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(312)forward()
-> traj_cls_branches=self.traj_cls_branches,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(314)forward()
-> agent_level_embedding=agent_level_embedding,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(315)forward()
-> scene_level_ego_embedding=scene_level_ego_embedding,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(316)forward()
-> scene_level_offset_embedding=scene_level_offset_embedding,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(317)forward()
-> learnable_embed=learnable_embed,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(319)forward()
-> agent_level_embedding_layer=self.agent_level_embedding_layer,
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1117)__getattr__()
-> def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1118)__getattr__()
-> if '_parameters' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1119)__getattr__()
-> _parameters = self.__dict__['_parameters']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1120)__getattr__()
-> if name in _parameters:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1122)__getattr__()
-> if '_buffers' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1123)__getattr__()
-> _buffers = self.__dict__['_buffers']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1124)__getattr__()
-> if name in _buffers:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1126)__getattr__()
-> if '_modules' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1127)__getattr__()
-> modules = self.__dict__['_modules']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1128)__getattr__()
-> if name in modules:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()
-> return modules[name]
(Pdb) --Return--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()->Sequential(
 ..., bias=True)
)
-> return modules[name]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(320)forward()
-> scene_level_ego_embedding_layer=self.scene_level_ego_embedding_layer,
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1117)__getattr__()
-> def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1118)__getattr__()
-> if '_parameters' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1119)__getattr__()
-> _parameters = self.__dict__['_parameters']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1120)__getattr__()
-> if name in _parameters:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1122)__getattr__()
-> if '_buffers' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1123)__getattr__()
-> _buffers = self.__dict__['_buffers']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1124)__getattr__()
-> if name in _buffers:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1126)__getattr__()
-> if '_modules' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1127)__getattr__()
-> modules = self.__dict__['_modules']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1128)__getattr__()
-> if name in modules:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()
-> return modules[name]
(Pdb) --Return--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()->Sequential(
 ..., bias=True)
)
-> return modules[name]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(321)forward()
-> scene_level_offset_embedding_layer=self.scene_level_offset_embedding_layer,
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1117)__getattr__()
-> def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1118)__getattr__()
-> if '_parameters' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1119)__getattr__()
-> _parameters = self.__dict__['_parameters']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1120)__getattr__()
-> if name in _parameters:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1122)__getattr__()
-> if '_buffers' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1123)__getattr__()
-> _buffers = self.__dict__['_buffers']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1124)__getattr__()
-> if name in _buffers:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1126)__getattr__()
-> if '_modules' in self.__dict__:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1127)__getattr__()
-> modules = self.__dict__['_modules']
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1128)__getattr__()
-> if name in modules:
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()
-> return modules[name]
(Pdb) --Return--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1129)__getattr__()->Sequential(
 ..., bias=True)
)
-> return modules[name]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(322)forward()
-> spatial_shapes=torch.tensor(
(Pdb) 317  	            learnable_embed=learnable_embed,
318  	            # anchor positional embeddings layers
319  	            agent_level_embedding_layer=self.agent_level_embedding_layer,
320  	            scene_level_ego_embedding_layer=self.scene_level_ego_embedding_layer,
321  	            scene_level_offset_embedding_layer=self.scene_level_offset_embedding_layer,
322  ->	            spatial_shapes=torch.tensor(
323  	                [[self.bev_h, self.bev_w]], device=device),
324  	            level_start_index=torch.tensor([0], device=device))
325  	
326  	        for lvl in range(inter_states.shape[0]):
327  	            outputs_class = self.traj_cls_branches[lvl](inter_states[lvl])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(323)forward()
-> [[self.bev_h, self.bev_w]], device=device),
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(322)forward()
-> spatial_shapes=torch.tensor(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(324)forward()
-> level_start_index=torch.tensor([0], device=device))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py(303)forward()
-> inter_states, inter_references = self.motionformer(
(Pdb) --Call--
> /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1045)_call_impl()
-> def _call_impl(self, *input, **kwargs):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1046)_call_impl()
-> forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1050)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1049)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py(1051)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) --Call--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head_plugin/modules.py(62)forward()
-> def forward(self,
(Pdb) 
Traceback (most recent call last):
  File "./tools/test.py", line 274, in <module>
    main()
  File "./tools/test.py", line 230, in main
    result = model(return_loss=False, rescale=True, **data)
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py", line 83, in forward
    return self.forward_test(**kwargs)
  File "/Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py", line 305, in forward_test
    result_motion, outs_motion = self.motion_head.forward_test(bev_embed, outs_track=result_track[0], outs_seg=result_seg[0])
  File "/Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py", line 181, in forward_test
    outs_motion = self(bev_embed, track_query, lane_query, lane_query_pos, track_boxes)
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
    return old_func(*args, **kwargs)
  File "/Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py", line 303, in forward
    inter_states, inter_references = self.motionformer(
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/dense_heads/motion_head_plugin/modules.py", line 62, in forward
    def forward(self,
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/bdb.py", line 90, in trace_dispatch
    return self.dispatch_call(frame, arg)
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/bdb.py", line 135, in dispatch_call
    if self.quitting: raise BdbQuit
bdb.BdbQuit
