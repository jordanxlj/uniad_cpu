NOTE: Redirects are currently not supported in Windows or MacOs.
/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : ./tools/test.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 1
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:28596
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_61pw8f5z/none_g71webgy
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=28596
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_61pw8f5z/none_g71webgy/attempt_0/0/error.json
Traceback (most recent call last):
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/config.py", line 101, in _validate_py_syntax
    ast.parse(content)
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/ast.py", line 47, in parse
    return compile(source, filename, mode, flags,
  File "<unknown>", line 332
    occ_head=dict(
    ^
SyntaxError: invalid syntax

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./tools/test.py", line 273, in <module>
    main()
  File "./tools/test.py", line 125, in main
    cfg = Config.fromfile(args.config)
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/config.py", line 331, in fromfile
    cfg_dict, cfg_text = Config._file2dict(filename,
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/config.py", line 205, in _file2dict
    Config._validate_py_syntax(filename)
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/mmcv/utils/config.py", line 103, in _validate_py_syntax
    raise SyntaxError('There are syntax errors in config '
SyntaxError: There are syntax errors in config file /Users/liangming.xu/code/UniAD/projects/configs/stage2_e2e/base_e2e.py: invalid syntax (<unknown>, line 332)
Exception ignored in: <function _TemporaryFileCloser.__del__ at 0x1322fdee0>
Traceback (most recent call last):
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/tempfile.py", line 440, in __del__
    self.close()
  File "/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/tempfile.py", line 436, in close
    unlink(self.name)
FileNotFoundError: [Errno 2] No such file or directory: '/var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/tmpydnyx3br/tmpyab8l26n.py'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 77553) of binary: /opt/homebrew/anaconda3/envs/uniad/bin/python
ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed
INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 3/3 attempts left; will restart worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=1
  master_addr=127.0.0.1
  master_port=28596
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_61pw8f5z/none_g71webgy/attempt_1/0/error.json
