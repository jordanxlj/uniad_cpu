NOTE: Redirects are currently not supported in Windows or MacOs.
/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : ./tools/test.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 1
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:28596
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_qhm3uuqn/none_z1qqm1m5
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=28596
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_qhm3uuqn/none_z1qqm1m5/attempt_0/0/error.json
projects.mmdet3d_plugin
======
Loading NuScenes tables for version v1.0-trainval...
23 category,
8 attribute,
4 visibility,
64386 instance,
12 sensor,
10200 calibrated_sensor,
2631083 ego_pose,
68 log,
850 scene,
34149 sample,
2631083 sample_data,
1166187 sample_annotation,
4 map,
Done loading in 21.689 seconds.
======
Reverse indexing ...
Done reverse indexing in 5.3 seconds.
======
load checkpoint from local path: ./ckpts/uniad_base_e2e.pth
2023-07-24 10:30:43,337 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.0.conv2 is upgraded to version 2.
2023-07-24 10:30:43,341 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.1.conv2 is upgraded to version 2.
2023-07-24 10:30:43,343 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.2.conv2 is upgraded to version 2.
2023-07-24 10:30:43,346 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.3.conv2 is upgraded to version 2.
2023-07-24 10:30:43,348 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.4.conv2 is upgraded to version 2.
2023-07-24 10:30:43,350 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.5.conv2 is upgraded to version 2.
2023-07-24 10:30:43,353 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.6.conv2 is upgraded to version 2.
2023-07-24 10:30:43,355 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.7.conv2 is upgraded to version 2.
2023-07-24 10:30:43,358 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.8.conv2 is upgraded to version 2.
2023-07-24 10:30:43,360 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.9.conv2 is upgraded to version 2.
2023-07-24 10:30:43,363 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.10.conv2 is upgraded to version 2.
2023-07-24 10:30:43,368 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.11.conv2 is upgraded to version 2.
2023-07-24 10:30:43,379 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.12.conv2 is upgraded to version 2.
2023-07-24 10:30:43,382 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.13.conv2 is upgraded to version 2.
2023-07-24 10:30:43,416 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.14.conv2 is upgraded to version 2.
2023-07-24 10:30:43,438 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.15.conv2 is upgraded to version 2.
2023-07-24 10:30:43,442 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.16.conv2 is upgraded to version 2.
2023-07-24 10:30:43,446 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.17.conv2 is upgraded to version 2.
2023-07-24 10:30:43,450 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.18.conv2 is upgraded to version 2.
2023-07-24 10:30:43,454 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.19.conv2 is upgraded to version 2.
2023-07-24 10:30:43,458 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.20.conv2 is upgraded to version 2.
2023-07-24 10:30:43,462 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.21.conv2 is upgraded to version 2.
2023-07-24 10:30:43,466 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.22.conv2 is upgraded to version 2.
2023-07-24 10:30:43,471 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.0.conv2 is upgraded to version 2.
2023-07-24 10:30:43,482 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.1.conv2 is upgraded to version 2.
2023-07-24 10:30:43,487 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.2.conv2 is upgraded to version 2.
The model and loaded state dict do not match exactly

unexpected key in source state_dict: bbox_size_fc.weight, bbox_size_fc.bias, seg_head.transformer.level_embeds, seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.0.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.0.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.0.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.0.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.0.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.0.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.0.norms.0.weight, seg_head.transformer.encoder.layers.0.norms.0.bias, seg_head.transformer.encoder.layers.0.norms.1.weight, seg_head.transformer.encoder.layers.0.norms.1.bias, seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.1.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.1.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.1.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.1.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.1.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.1.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.1.norms.0.weight, seg_head.transformer.encoder.layers.1.norms.0.bias, seg_head.transformer.encoder.layers.1.norms.1.weight, seg_head.transformer.encoder.layers.1.norms.1.bias, seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.2.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.2.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.2.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.2.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.2.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.2.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.2.norms.0.weight, seg_head.transformer.encoder.layers.2.norms.0.bias, seg_head.transformer.encoder.layers.2.norms.1.weight, seg_head.transformer.encoder.layers.2.norms.1.bias, seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.3.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.3.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.3.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.3.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.3.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.3.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.3.norms.0.weight, seg_head.transformer.encoder.layers.3.norms.0.bias, seg_head.transformer.encoder.layers.3.norms.1.weight, seg_head.transformer.encoder.layers.3.norms.1.bias, seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.4.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.4.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.4.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.4.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.4.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.4.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.4.norms.0.weight, seg_head.transformer.encoder.layers.4.norms.0.bias, seg_head.transformer.encoder.layers.4.norms.1.weight, seg_head.transformer.encoder.layers.4.norms.1.bias, seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.5.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.5.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.5.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.5.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.5.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.5.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.5.norms.0.weight, seg_head.transformer.encoder.layers.5.norms.0.bias, seg_head.transformer.encoder.layers.5.norms.1.weight, seg_head.transformer.encoder.layers.5.norms.1.bias, seg_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.0.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.0.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.0.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.0.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.0.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.0.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.0.norms.0.weight, seg_head.transformer.decoder.layers.0.norms.0.bias, seg_head.transformer.decoder.layers.0.norms.1.weight, seg_head.transformer.decoder.layers.0.norms.1.bias, seg_head.transformer.decoder.layers.0.norms.2.weight, seg_head.transformer.decoder.layers.0.norms.2.bias, seg_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.1.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.1.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.1.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.1.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.1.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.1.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.1.norms.0.weight, seg_head.transformer.decoder.layers.1.norms.0.bias, seg_head.transformer.decoder.layers.1.norms.1.weight, seg_head.transformer.decoder.layers.1.norms.1.bias, seg_head.transformer.decoder.layers.1.norms.2.weight, seg_head.transformer.decoder.layers.1.norms.2.bias, seg_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.2.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.2.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.2.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.2.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.2.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.2.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.2.norms.0.weight, seg_head.transformer.decoder.layers.2.norms.0.bias, seg_head.transformer.decoder.layers.2.norms.1.weight, seg_head.transformer.decoder.layers.2.norms.1.bias, seg_head.transformer.decoder.layers.2.norms.2.weight, seg_head.transformer.decoder.layers.2.norms.2.bias, seg_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.3.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.3.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.3.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.3.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.3.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.3.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.3.norms.0.weight, seg_head.transformer.decoder.layers.3.norms.0.bias, seg_head.transformer.decoder.layers.3.norms.1.weight, seg_head.transformer.decoder.layers.3.norms.1.bias, seg_head.transformer.decoder.layers.3.norms.2.weight, seg_head.transformer.decoder.layers.3.norms.2.bias, seg_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.4.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.4.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.4.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.4.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.4.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.4.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.4.norms.0.weight, seg_head.transformer.decoder.layers.4.norms.0.bias, seg_head.transformer.decoder.layers.4.norms.1.weight, seg_head.transformer.decoder.layers.4.norms.1.bias, seg_head.transformer.decoder.layers.4.norms.2.weight, seg_head.transformer.decoder.layers.4.norms.2.bias, seg_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.5.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.5.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.5.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.5.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.5.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.5.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.5.norms.0.weight, seg_head.transformer.decoder.layers.5.norms.0.bias, seg_head.transformer.decoder.layers.5.norms.1.weight, seg_head.transformer.decoder.layers.5.norms.1.bias, seg_head.transformer.decoder.layers.5.norms.2.weight, seg_head.transformer.decoder.layers.5.norms.2.bias, seg_head.transformer.reference_points.weight, seg_head.transformer.reference_points.bias, seg_head.bev_embedding.weight, seg_head.cls_branches.0.weight, seg_head.cls_branches.0.bias, seg_head.cls_branches.1.weight, seg_head.cls_branches.1.bias, seg_head.cls_branches.2.weight, seg_head.cls_branches.2.bias, seg_head.cls_branches.3.weight, seg_head.cls_branches.3.bias, seg_head.cls_branches.4.weight, seg_head.cls_branches.4.bias, seg_head.cls_branches.5.weight, seg_head.cls_branches.5.bias, seg_head.reg_branches.0.0.weight, seg_head.reg_branches.0.0.bias, seg_head.reg_branches.0.2.weight, seg_head.reg_branches.0.2.bias, seg_head.reg_branches.0.4.weight, seg_head.reg_branches.0.4.bias, seg_head.reg_branches.1.0.weight, seg_head.reg_branches.1.0.bias, seg_head.reg_branches.1.2.weight, seg_head.reg_branches.1.2.bias, seg_head.reg_branches.1.4.weight, seg_head.reg_branches.1.4.bias, seg_head.reg_branches.2.0.weight, seg_head.reg_branches.2.0.bias, seg_head.reg_branches.2.2.weight, seg_head.reg_branches.2.2.bias, seg_head.reg_branches.2.4.weight, seg_head.reg_branches.2.4.bias, seg_head.reg_branches.3.0.weight, seg_head.reg_branches.3.0.bias, seg_head.reg_branches.3.2.weight, seg_head.reg_branches.3.2.bias, seg_head.reg_branches.3.4.weight, seg_head.reg_branches.3.4.bias, seg_head.reg_branches.4.0.weight, seg_head.reg_branches.4.0.bias, seg_head.reg_branches.4.2.weight, seg_head.reg_branches.4.2.bias, seg_head.reg_branches.4.4.weight, seg_head.reg_branches.4.4.bias, seg_head.reg_branches.5.0.weight, seg_head.reg_branches.5.0.bias, seg_head.reg_branches.5.2.weight, seg_head.reg_branches.5.2.bias, seg_head.reg_branches.5.4.weight, seg_head.reg_branches.5.4.bias, seg_head.query_embedding.weight, seg_head.stuff_query.weight, seg_head.reg_branches2.0.0.weight, seg_head.reg_branches2.0.0.bias, seg_head.reg_branches2.0.2.weight, seg_head.reg_branches2.0.2.bias, seg_head.reg_branches2.0.4.weight, seg_head.reg_branches2.0.4.bias, seg_head.reg_branches2.1.0.weight, seg_head.reg_branches2.1.0.bias, seg_head.reg_branches2.1.2.weight, seg_head.reg_branches2.1.2.bias, seg_head.reg_branches2.1.4.weight, seg_head.reg_branches2.1.4.bias, seg_head.reg_branches2.2.0.weight, seg_head.reg_branches2.2.0.bias, seg_head.reg_branches2.2.2.weight, seg_head.reg_branches2.2.2.bias, seg_head.reg_branches2.2.4.weight, seg_head.reg_branches2.2.4.bias, seg_head.reg_branches2.3.0.weight, seg_head.reg_branches2.3.0.bias, seg_head.reg_branches2.3.2.weight, seg_head.reg_branches2.3.2.bias, seg_head.reg_branches2.3.4.weight, seg_head.reg_branches2.3.4.bias, seg_head.cls_thing_branches.0.weight, seg_head.cls_thing_branches.0.bias, seg_head.cls_thing_branches.1.weight, seg_head.cls_thing_branches.1.bias, seg_head.cls_thing_branches.2.weight, seg_head.cls_thing_branches.2.bias, seg_head.cls_thing_branches.3.weight, seg_head.cls_thing_branches.3.bias, seg_head.cls_stuff_branches.0.weight, seg_head.cls_stuff_branches.0.bias, seg_head.cls_stuff_branches.1.weight, seg_head.cls_stuff_branches.1.bias, seg_head.cls_stuff_branches.2.weight, seg_head.cls_stuff_branches.2.bias, seg_head.cls_stuff_branches.3.weight, seg_head.cls_stuff_branches.3.bias, seg_head.cls_stuff_branches.4.weight, seg_head.cls_stuff_branches.4.bias, seg_head.cls_stuff_branches.5.weight, seg_head.cls_stuff_branches.5.bias, seg_head.things_mask_head.blocks.0.head_norm1.weight, seg_head.things_mask_head.blocks.0.head_norm1.bias, seg_head.things_mask_head.blocks.0.attn.q.weight, seg_head.things_mask_head.blocks.0.attn.q.bias, seg_head.things_mask_head.blocks.0.attn.k.weight, seg_head.things_mask_head.blocks.0.attn.k.bias, seg_head.things_mask_head.blocks.0.attn.v.weight, seg_head.things_mask_head.blocks.0.attn.v.bias, seg_head.things_mask_head.blocks.0.attn.proj.weight, seg_head.things_mask_head.blocks.0.attn.proj.bias, seg_head.things_mask_head.blocks.0.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.0.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.0.attn.linear.0.weight, seg_head.things_mask_head.blocks.0.attn.linear.0.bias, seg_head.things_mask_head.blocks.0.head_norm2.weight, seg_head.things_mask_head.blocks.0.head_norm2.bias, seg_head.things_mask_head.blocks.0.mlp.fc1.weight, seg_head.things_mask_head.blocks.0.mlp.fc1.bias, seg_head.things_mask_head.blocks.0.mlp.fc2.weight, seg_head.things_mask_head.blocks.0.mlp.fc2.bias, seg_head.things_mask_head.blocks.1.head_norm1.weight, seg_head.things_mask_head.blocks.1.head_norm1.bias, seg_head.things_mask_head.blocks.1.attn.q.weight, seg_head.things_mask_head.blocks.1.attn.q.bias, seg_head.things_mask_head.blocks.1.attn.k.weight, seg_head.things_mask_head.blocks.1.attn.k.bias, seg_head.things_mask_head.blocks.1.attn.v.weight, seg_head.things_mask_head.blocks.1.attn.v.bias, seg_head.things_mask_head.blocks.1.attn.proj.weight, seg_head.things_mask_head.blocks.1.attn.proj.bias, seg_head.things_mask_head.blocks.1.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.1.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.1.attn.linear.0.weight, seg_head.things_mask_head.blocks.1.attn.linear.0.bias, seg_head.things_mask_head.blocks.1.head_norm2.weight, seg_head.things_mask_head.blocks.1.head_norm2.bias, seg_head.things_mask_head.blocks.1.mlp.fc1.weight, seg_head.things_mask_head.blocks.1.mlp.fc1.bias, seg_head.things_mask_head.blocks.1.mlp.fc2.weight, seg_head.things_mask_head.blocks.1.mlp.fc2.bias, seg_head.things_mask_head.blocks.2.head_norm1.weight, seg_head.things_mask_head.blocks.2.head_norm1.bias, seg_head.things_mask_head.blocks.2.attn.q.weight, seg_head.things_mask_head.blocks.2.attn.q.bias, seg_head.things_mask_head.blocks.2.attn.k.weight, seg_head.things_mask_head.blocks.2.attn.k.bias, seg_head.things_mask_head.blocks.2.attn.v.weight, seg_head.things_mask_head.blocks.2.attn.v.bias, seg_head.things_mask_head.blocks.2.attn.proj.weight, seg_head.things_mask_head.blocks.2.attn.proj.bias, seg_head.things_mask_head.blocks.2.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.2.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.2.attn.linear.0.weight, seg_head.things_mask_head.blocks.2.attn.linear.0.bias, seg_head.things_mask_head.blocks.2.head_norm2.weight, seg_head.things_mask_head.blocks.2.head_norm2.bias, seg_head.things_mask_head.blocks.2.mlp.fc1.weight, seg_head.things_mask_head.blocks.2.mlp.fc1.bias, seg_head.things_mask_head.blocks.2.mlp.fc2.weight, seg_head.things_mask_head.blocks.2.mlp.fc2.bias, seg_head.things_mask_head.blocks.3.head_norm1.weight, seg_head.things_mask_head.blocks.3.head_norm1.bias, seg_head.things_mask_head.blocks.3.attn.q.weight, seg_head.things_mask_head.blocks.3.attn.q.bias, seg_head.things_mask_head.blocks.3.attn.k.weight, seg_head.things_mask_head.blocks.3.attn.k.bias, seg_head.things_mask_head.blocks.3.attn.v.weight, seg_head.things_mask_head.blocks.3.attn.v.bias, seg_head.things_mask_head.blocks.3.attn.proj.weight, seg_head.things_mask_head.blocks.3.attn.proj.bias, seg_head.things_mask_head.blocks.3.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.3.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.3.attn.linear.0.weight, seg_head.things_mask_head.blocks.3.attn.linear.0.bias, seg_head.things_mask_head.blocks.3.head_norm2.weight, seg_head.things_mask_head.blocks.3.head_norm2.bias, seg_head.things_mask_head.blocks.3.mlp.fc1.weight, seg_head.things_mask_head.blocks.3.mlp.fc1.bias, seg_head.things_mask_head.blocks.3.mlp.fc2.weight, seg_head.things_mask_head.blocks.3.mlp.fc2.bias, seg_head.things_mask_head.attnen.q.weight, seg_head.things_mask_head.attnen.q.bias, seg_head.things_mask_head.attnen.k.weight, seg_head.things_mask_head.attnen.k.bias, seg_head.things_mask_head.attnen.linear_l1.0.weight, seg_head.things_mask_head.attnen.linear_l1.0.bias, seg_head.things_mask_head.attnen.linear.0.weight, seg_head.things_mask_head.attnen.linear.0.bias, seg_head.stuff_mask_head.blocks.0.head_norm1.weight, seg_head.stuff_mask_head.blocks.0.head_norm1.bias, seg_head.stuff_mask_head.blocks.0.attn.q.weight, seg_head.stuff_mask_head.blocks.0.attn.q.bias, seg_head.stuff_mask_head.blocks.0.attn.k.weight, seg_head.stuff_mask_head.blocks.0.attn.k.bias, seg_head.stuff_mask_head.blocks.0.attn.v.weight, seg_head.stuff_mask_head.blocks.0.attn.v.bias, seg_head.stuff_mask_head.blocks.0.attn.proj.weight, seg_head.stuff_mask_head.blocks.0.attn.proj.bias, seg_head.stuff_mask_head.blocks.0.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.0.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.0.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.0.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.0.head_norm2.weight, seg_head.stuff_mask_head.blocks.0.head_norm2.bias, seg_head.stuff_mask_head.blocks.0.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.0.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.0.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.0.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.0.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.0.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.0.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.0.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.0.norm3.weight, seg_head.stuff_mask_head.blocks.0.norm3.bias, seg_head.stuff_mask_head.blocks.1.head_norm1.weight, seg_head.stuff_mask_head.blocks.1.head_norm1.bias, seg_head.stuff_mask_head.blocks.1.attn.q.weight, seg_head.stuff_mask_head.blocks.1.attn.q.bias, seg_head.stuff_mask_head.blocks.1.attn.k.weight, seg_head.stuff_mask_head.blocks.1.attn.k.bias, seg_head.stuff_mask_head.blocks.1.attn.v.weight, seg_head.stuff_mask_head.blocks.1.attn.v.bias, seg_head.stuff_mask_head.blocks.1.attn.proj.weight, seg_head.stuff_mask_head.blocks.1.attn.proj.bias, seg_head.stuff_mask_head.blocks.1.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.1.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.1.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.1.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.1.head_norm2.weight, seg_head.stuff_mask_head.blocks.1.head_norm2.bias, seg_head.stuff_mask_head.blocks.1.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.1.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.1.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.1.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.1.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.1.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.1.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.1.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.1.norm3.weight, seg_head.stuff_mask_head.blocks.1.norm3.bias, seg_head.stuff_mask_head.blocks.2.head_norm1.weight, seg_head.stuff_mask_head.blocks.2.head_norm1.bias, seg_head.stuff_mask_head.blocks.2.attn.q.weight, seg_head.stuff_mask_head.blocks.2.attn.q.bias, seg_head.stuff_mask_head.blocks.2.attn.k.weight, seg_head.stuff_mask_head.blocks.2.attn.k.bias, seg_head.stuff_mask_head.blocks.2.attn.v.weight, seg_head.stuff_mask_head.blocks.2.attn.v.bias, seg_head.stuff_mask_head.blocks.2.attn.proj.weight, seg_head.stuff_mask_head.blocks.2.attn.proj.bias, seg_head.stuff_mask_head.blocks.2.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.2.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.2.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.2.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.2.head_norm2.weight, seg_head.stuff_mask_head.blocks.2.head_norm2.bias, seg_head.stuff_mask_head.blocks.2.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.2.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.2.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.2.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.2.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.2.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.2.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.2.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.2.norm3.weight, seg_head.stuff_mask_head.blocks.2.norm3.bias, seg_head.stuff_mask_head.blocks.3.head_norm1.weight, seg_head.stuff_mask_head.blocks.3.head_norm1.bias, seg_head.stuff_mask_head.blocks.3.attn.q.weight, seg_head.stuff_mask_head.blocks.3.attn.q.bias, seg_head.stuff_mask_head.blocks.3.attn.k.weight, seg_head.stuff_mask_head.blocks.3.attn.k.bias, seg_head.stuff_mask_head.blocks.3.attn.v.weight, seg_head.stuff_mask_head.blocks.3.attn.v.bias, seg_head.stuff_mask_head.blocks.3.attn.proj.weight, seg_head.stuff_mask_head.blocks.3.attn.proj.bias, seg_head.stuff_mask_head.blocks.3.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.3.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.3.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.3.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.3.head_norm2.weight, seg_head.stuff_mask_head.blocks.3.head_norm2.bias, seg_head.stuff_mask_head.blocks.3.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.3.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.3.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.3.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.3.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.3.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.3.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.3.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.3.norm3.weight, seg_head.stuff_mask_head.blocks.3.norm3.bias, seg_head.stuff_mask_head.blocks.4.head_norm1.weight, seg_head.stuff_mask_head.blocks.4.head_norm1.bias, seg_head.stuff_mask_head.blocks.4.attn.q.weight, seg_head.stuff_mask_head.blocks.4.attn.q.bias, seg_head.stuff_mask_head.blocks.4.attn.k.weight, seg_head.stuff_mask_head.blocks.4.attn.k.bias, seg_head.stuff_mask_head.blocks.4.attn.v.weight, seg_head.stuff_mask_head.blocks.4.attn.v.bias, seg_head.stuff_mask_head.blocks.4.attn.proj.weight, seg_head.stuff_mask_head.blocks.4.attn.proj.bias, seg_head.stuff_mask_head.blocks.4.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.4.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.4.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.4.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.4.head_norm2.weight, seg_head.stuff_mask_head.blocks.4.head_norm2.bias, seg_head.stuff_mask_head.blocks.4.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.4.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.4.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.4.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.4.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.4.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.4.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.4.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.4.norm3.weight, seg_head.stuff_mask_head.blocks.4.norm3.bias, seg_head.stuff_mask_head.blocks.5.head_norm1.weight, seg_head.stuff_mask_head.blocks.5.head_norm1.bias, seg_head.stuff_mask_head.blocks.5.attn.q.weight, seg_head.stuff_mask_head.blocks.5.attn.q.bias, seg_head.stuff_mask_head.blocks.5.attn.k.weight, seg_head.stuff_mask_head.blocks.5.attn.k.bias, seg_head.stuff_mask_head.blocks.5.attn.v.weight, seg_head.stuff_mask_head.blocks.5.attn.v.bias, seg_head.stuff_mask_head.blocks.5.attn.proj.weight, seg_head.stuff_mask_head.blocks.5.attn.proj.bias, seg_head.stuff_mask_head.blocks.5.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.5.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.5.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.5.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.5.head_norm2.weight, seg_head.stuff_mask_head.blocks.5.head_norm2.bias, seg_head.stuff_mask_head.blocks.5.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.5.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.5.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.5.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.5.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.5.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.5.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.5.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.5.norm3.weight, seg_head.stuff_mask_head.blocks.5.norm3.bias, seg_head.stuff_mask_head.attnen.q.weight, seg_head.stuff_mask_head.attnen.q.bias, seg_head.stuff_mask_head.attnen.k.weight, seg_head.stuff_mask_head.attnen.k.bias, seg_head.stuff_mask_head.attnen.linear_l1.0.weight, seg_head.stuff_mask_head.attnen.linear_l1.0.bias, seg_head.stuff_mask_head.attnen.linear.0.weight, seg_head.stuff_mask_head.attnen.linear.0.bias, pts_bbox_head.query_embedding.weight, pts_bbox_head.transformer.reference_points.weight, pts_bbox_head.transformer.reference_points.bias

> /Users/liangming.xu/code/UniAD/tools/test.py(229)main()
-> result = model(return_loss=False, rescale=True, **data)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(723)simple_test_track()
-> bs = img.size(0)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py(641)_forward_single_frame_inference()
-> active_inst = track_instances[track_instances.obj_idxes >= 0]
(Pdb) 636  	        img: B, num_cam, C, H, W = img.shape
637  	        """
638  	
639  	        """ velo update """
640  	        import pdb; pdb.set_trace()
641  ->	        active_inst = track_instances[track_instances.obj_idxes >= 0]
642  	        other_inst = track_instances[track_instances.obj_idxes < 0]
643  	
644  	        if l2g_r2 is not None and len(active_inst) > 0 and l2g_r1 is not None:
645  	            ref_pts = active_inst.ref_pts
646  	            velo = active_inst.pred_boxes[:, -2:]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(113)get_bev_features()
-> bs = mlvl_feats[0].size(0)
(Pdb) 108  	            img_metas=None):
109  	        """
110  	        obtain bev features.
111  	        """
112  	        import pdb; pdb.set_trace()
113  ->	        bs = mlvl_feats[0].size(0)
114  	        bev_queries = bev_queries.unsqueeze(1).repeat(1, bs, 1)
115  	        bev_pos = bev_pos.flatten(2).permute(2, 0, 1)
116  	        # obtain rotation angle and shift with ego motion
117  	        delta_x = np.array([each['can_bus'][0]
118  	                           for each in img_metas])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(114)get_bev_features()
-> bev_queries = bev_queries.unsqueeze(1).repeat(1, bs, 1)
(Pdb) 1
(Pdb) torch.Size([40000, 256])
(Pdb) torch.Size([1, 256, 200, 200])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(115)get_bev_features()
-> bev_pos = bev_pos.flatten(2).permute(2, 0, 1)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(117)get_bev_features()
-> delta_x = np.array([each['can_bus'][0]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(118)get_bev_features()
-> for each in img_metas])
(Pdb) *** NameError: name 'delta_x' is not defined
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(117)get_bev_features()
-> delta_x = np.array([each['can_bus'][0]
(Pdb) *** NameError: name 'delta_x' is not defined
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(119)get_bev_features()
-> delta_y = np.array([each['can_bus'][1]
(Pdb) array([732.06144445])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(120)get_bev_features()
-> for each in img_metas])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(119)get_bev_features()
-> delta_y = np.array([each['can_bus'][1]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(121)get_bev_features()
-> ego_angle = np.array(
(Pdb) 116  	        # obtain rotation angle and shift with ego motion
117  	        delta_x = np.array([each['can_bus'][0]
118  	                           for each in img_metas])
119  	        delta_y = np.array([each['can_bus'][1]
120  	                           for each in img_metas])
121  ->	        ego_angle = np.array(
122  	            [each['can_bus'][-2] / np.pi * 180 for each in img_metas])
123  	        grid_length_y = grid_length[0]
124  	        grid_length_x = grid_length[1]
125  	        translation_length = np.sqrt(delta_x ** 2 + delta_y ** 2)
126  	        translation_angle = np.arctan2(delta_y, delta_x) / np.pi * 180
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(122)get_bev_features()
-> [each['can_bus'][-2] / np.pi * 180 for each in img_metas])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(121)get_bev_features()
-> ego_angle = np.array(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(123)get_bev_features()
-> grid_length_y = grid_length[0]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(124)get_bev_features()
-> grid_length_x = grid_length[1]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(125)get_bev_features()
-> translation_length = np.sqrt(delta_x ** 2 + delta_y ** 2)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(126)get_bev_features()
-> translation_angle = np.arctan2(delta_y, delta_x) / np.pi * 180
(Pdb) array([1198.60060383])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(127)get_bev_features()
-> bev_angle = ego_angle - translation_angle
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(128)get_bev_features()
-> shift_y = translation_length * \
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(129)get_bev_features()
-> np.cos(bev_angle / 180 * np.pi) / grid_length_y / bev_h
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(128)get_bev_features()
-> shift_y = translation_length * \
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(129)get_bev_features()
-> np.cos(bev_angle / 180 * np.pi) / grid_length_y / bev_h
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(128)get_bev_features()
-> shift_y = translation_length * \
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(129)get_bev_features()
-> np.cos(bev_angle / 180 * np.pi) / grid_length_y / bev_h
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(128)get_bev_features()
-> shift_y = translation_length * \
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(130)get_bev_features()
-> shift_x = translation_length * \
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(131)get_bev_features()
-> np.sin(bev_angle / 180 * np.pi) / grid_length_x / bev_w
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(130)get_bev_features()
-> shift_x = translation_length * \
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(131)get_bev_features()
-> np.sin(bev_angle / 180 * np.pi) / grid_length_x / bev_w
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(130)get_bev_features()
-> shift_x = translation_length * \
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(131)get_bev_features()
-> np.sin(bev_angle / 180 * np.pi) / grid_length_x / bev_w
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(130)get_bev_features()
-> shift_x = translation_length * \
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(132)get_bev_features()
-> shift_y = shift_y * self.use_shift
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(133)get_bev_features()
-> shift_x = shift_x * self.use_shift
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(134)get_bev_features()
-> shift = bev_queries.new_tensor(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(135)get_bev_features()
-> [shift_x, shift_y]).permute(1, 0)  # xy, bs -> bs, xy
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(134)get_bev_features()
-> shift = bev_queries.new_tensor(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(135)get_bev_features()
-> [shift_x, shift_y]).permute(1, 0)  # xy, bs -> bs, xy
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(134)get_bev_features()
-> shift = bev_queries.new_tensor(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(137)get_bev_features()
-> if prev_bev is not None:
(Pdb) torch.Size([1, 2])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(152)get_bev_features()
-> can_bus = bev_queries.new_tensor(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(153)get_bev_features()
-> [each['can_bus'] for each in img_metas])  # [:, :]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(152)get_bev_features()
-> can_bus = bev_queries.new_tensor(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(154)get_bev_features()
-> can_bus = self.can_bus_mlp(can_bus)[None, :, :]
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(155)get_bev_features()
-> bev_queries = bev_queries + can_bus * self.use_can_bus
(Pdb) torch.Size([1, 1, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(157)get_bev_features()
-> feat_flatten = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(158)get_bev_features()
-> spatial_shapes = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(159)get_bev_features()
-> for lvl, feat in enumerate(mlvl_feats):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(160)get_bev_features()
-> bs, num_cam, c, h, w = feat.shape
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(161)get_bev_features()
-> spatial_shape = (h, w)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(162)get_bev_features()
-> feat = feat.flatten(3).permute(1, 0, 3, 2)
(Pdb) (116, 200)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(163)get_bev_features()
-> if self.use_cams_embeds:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(164)get_bev_features()
-> feat = feat + self.cams_embeds[:, None, None, :].to(feat.dtype)
(Pdb) torch.Size([6, 256])
(Pdb) torch.Size([4, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(166)get_bev_features()
-> None, lvl:lvl + 1, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(166)get_bev_features()
-> None, lvl:lvl + 1, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(167)get_bev_features()
-> spatial_shapes.append(spatial_shape)
(Pdb) torch.Size([6, 1, 23200, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(168)get_bev_features()
-> feat_flatten.append(feat)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(159)get_bev_features()
-> for lvl, feat in enumerate(mlvl_feats):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(160)get_bev_features()
-> bs, num_cam, c, h, w = feat.shape
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(161)get_bev_features()
-> spatial_shape = (h, w)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(162)get_bev_features()
-> feat = feat.flatten(3).permute(1, 0, 3, 2)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(163)get_bev_features()
-> if self.use_cams_embeds:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(164)get_bev_features()
-> feat = feat + self.cams_embeds[:, None, None, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(166)get_bev_features()
-> None, lvl:lvl + 1, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(166)get_bev_features()
-> None, lvl:lvl + 1, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(167)get_bev_features()
-> spatial_shapes.append(spatial_shape)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(168)get_bev_features()
-> feat_flatten.append(feat)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(159)get_bev_features()
-> for lvl, feat in enumerate(mlvl_feats):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(160)get_bev_features()
-> bs, num_cam, c, h, w = feat.shape
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(161)get_bev_features()
-> spatial_shape = (h, w)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(162)get_bev_features()
-> feat = feat.flatten(3).permute(1, 0, 3, 2)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(163)get_bev_features()
-> if self.use_cams_embeds:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(164)get_bev_features()
-> feat = feat + self.cams_embeds[:, None, None, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(166)get_bev_features()
-> None, lvl:lvl + 1, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(166)get_bev_features()
-> None, lvl:lvl + 1, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(167)get_bev_features()
-> spatial_shapes.append(spatial_shape)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(168)get_bev_features()
-> feat_flatten.append(feat)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(159)get_bev_features()
-> for lvl, feat in enumerate(mlvl_feats):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(160)get_bev_features()
-> bs, num_cam, c, h, w = feat.shape
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(161)get_bev_features()
-> spatial_shape = (h, w)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(162)get_bev_features()
-> feat = feat.flatten(3).permute(1, 0, 3, 2)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(163)get_bev_features()
-> if self.use_cams_embeds:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(164)get_bev_features()
-> feat = feat + self.cams_embeds[:, None, None, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(166)get_bev_features()
-> None, lvl:lvl + 1, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(166)get_bev_features()
-> None, lvl:lvl + 1, :].to(feat.dtype)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(165)get_bev_features()
-> feat = feat + self.level_embeds[None,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(167)get_bev_features()
-> spatial_shapes.append(spatial_shape)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(168)get_bev_features()
-> feat_flatten.append(feat)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(159)get_bev_features()
-> for lvl, feat in enumerate(mlvl_feats):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(170)get_bev_features()
-> feat_flatten = torch.cat(feat_flatten, 2)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(171)get_bev_features()
-> spatial_shapes = torch.as_tensor(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(172)get_bev_features()
-> spatial_shapes, dtype=torch.long, device=bev_pos.device)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(171)get_bev_features()
-> spatial_shapes = torch.as_tensor(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(173)get_bev_features()
-> level_start_index = torch.cat((spatial_shapes.new_zeros(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(174)get_bev_features()
-> (1,)), spatial_shapes.prod(1).cumsum(0)[:-1]))
(Pdb) torch.Size([6, 1, 30825, 256])
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(173)get_bev_features()
-> level_start_index = torch.cat((spatial_shapes.new_zeros(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(174)get_bev_features()
-> (1,)), spatial_shapes.prod(1).cumsum(0)[:-1]))
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(173)get_bev_features()
-> level_start_index = torch.cat((spatial_shapes.new_zeros(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(176)get_bev_features()
-> feat_flatten = feat_flatten.permute(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(177)get_bev_features()
-> 0, 2, 1, 3)  # (num_cam, H*W, bs, embed_dims)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(176)get_bev_features()
-> feat_flatten = feat_flatten.permute(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(179)get_bev_features()
-> bev_embed = self.encoder(
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(180)get_bev_features()
-> bev_queries,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(181)get_bev_features()
-> feat_flatten,
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/uniad/modules/transformer.py(182)get_bev_features()
-> feat_flatten,
(Pdb) torch.Size([40000, 1, 256])
(Pdb) 