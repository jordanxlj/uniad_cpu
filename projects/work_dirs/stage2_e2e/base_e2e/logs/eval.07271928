NOTE: Redirects are currently not supported in Windows or MacOs.
/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : ./tools/test.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 1
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:28596
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_ge0m5yao/none_6q0q_v99
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/opt/homebrew/anaconda3/envs/uniad/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=28596
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /var/folders/bl/c09z1sm91mxfb8z7mn7v4rhh0000gq/T/torchelastic_ge0m5yao/none_6q0q_v99/attempt_0/0/error.json
projects.mmdet3d_plugin
======
Loading NuScenes tables for version v1.0-trainval...
23 category,
8 attribute,
4 visibility,
64386 instance,
12 sensor,
10200 calibrated_sensor,
2631083 ego_pose,
68 log,
850 scene,
34149 sample,
2631083 sample_data,
1166187 sample_annotation,
4 map,
Done loading in 21.879 seconds.
======
Reverse indexing ...
Done reverse indexing in 6.2 seconds.
======
load checkpoint from local path: ./ckpts/uniad_base_e2e.pth
2023-07-27 19:29:19,550 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.0.conv2 is upgraded to version 2.
2023-07-27 19:29:19,553 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.1.conv2 is upgraded to version 2.
2023-07-27 19:29:19,556 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.2.conv2 is upgraded to version 2.
2023-07-27 19:29:19,558 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.3.conv2 is upgraded to version 2.
2023-07-27 19:29:19,560 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.4.conv2 is upgraded to version 2.
2023-07-27 19:29:19,563 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.5.conv2 is upgraded to version 2.
2023-07-27 19:29:19,565 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.6.conv2 is upgraded to version 2.
2023-07-27 19:29:19,568 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.7.conv2 is upgraded to version 2.
2023-07-27 19:29:19,570 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.8.conv2 is upgraded to version 2.
2023-07-27 19:29:19,572 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.9.conv2 is upgraded to version 2.
2023-07-27 19:29:19,575 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.10.conv2 is upgraded to version 2.
2023-07-27 19:29:19,577 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.11.conv2 is upgraded to version 2.
2023-07-27 19:29:19,580 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.12.conv2 is upgraded to version 2.
2023-07-27 19:29:19,582 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.13.conv2 is upgraded to version 2.
2023-07-27 19:29:19,585 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.14.conv2 is upgraded to version 2.
2023-07-27 19:29:19,587 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.15.conv2 is upgraded to version 2.
2023-07-27 19:29:19,589 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.16.conv2 is upgraded to version 2.
2023-07-27 19:29:19,592 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.17.conv2 is upgraded to version 2.
2023-07-27 19:29:19,594 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.18.conv2 is upgraded to version 2.
2023-07-27 19:29:19,597 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.19.conv2 is upgraded to version 2.
2023-07-27 19:29:19,599 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.20.conv2 is upgraded to version 2.
2023-07-27 19:29:19,602 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.21.conv2 is upgraded to version 2.
2023-07-27 19:29:19,604 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.22.conv2 is upgraded to version 2.
2023-07-27 19:29:19,607 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.0.conv2 is upgraded to version 2.
2023-07-27 19:29:19,611 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.1.conv2 is upgraded to version 2.
2023-07-27 19:29:19,614 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.2.conv2 is upgraded to version 2.
The model and loaded state dict do not match exactly

size mismatch for seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).
size mismatch for seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).
size mismatch for seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([32, 256]).
size mismatch for seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
unexpected key in source state_dict: bbox_size_fc.weight, bbox_size_fc.bias, pts_bbox_head.query_embedding.weight, pts_bbox_head.transformer.reference_points.weight, pts_bbox_head.transformer.reference_points.bias

> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(566)get_data_info()
-> prev_indices, future_indices = self.occ_get_temporal_indices(
(Pdb) 561  	        can_bus[-2] = patch_angle / 180 * np.pi
562  	        can_bus[-1] = patch_angle
563  	
564  	        import pdb; pdb.set_trace()
565  	        # TODO: Warp all those below occupancy-related codes into a function
566  ->	        prev_indices, future_indices = self.occ_get_temporal_indices(
567  	            index, self.occ_receptive_field, self.occ_n_future)
568  	
569  	        # ego motions of all frames are needed
570  	        all_frames = prev_indices + [index] + future_indices
571  	
(Pdb) 6
(Pdb) *** NameError: name 'prev_indices' is not defined
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(567)get_data_info()
-> index, self.occ_receptive_field, self.occ_n_future)
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(566)get_data_info()
-> prev_indices, future_indices = self.occ_get_temporal_indices(
(Pdb) --Call--
> /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(604)occ_get_temporal_indices()
-> def occ_get_temporal_indices(self, index, receptive_field, n_future):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(605)occ_get_temporal_indices()
-> current_scene_token = self.data_infos[index]['scene_token']
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(608)occ_get_temporal_indices()
-> previous_indices = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(610)occ_get_temporal_indices()
-> for t in range(- receptive_field + 1, 0):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(611)occ_get_temporal_indices()
-> index_t = index + t
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(612)occ_get_temporal_indices()
-> if index_t >= 0 and self.data_infos[index_t]['scene_token'] == current_scene_token:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(615)occ_get_temporal_indices()
-> previous_indices.append(-1)  # for invalid indices
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(610)occ_get_temporal_indices()
-> for t in range(- receptive_field + 1, 0):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(611)occ_get_temporal_indices()
-> index_t = index + t
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(612)occ_get_temporal_indices()
-> if index_t >= 0 and self.data_infos[index_t]['scene_token'] == current_scene_token:
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(615)occ_get_temporal_indices()
-> previous_indices.append(-1)  # for invalid indices
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(610)occ_get_temporal_indices()
-> for t in range(- receptive_field + 1, 0):
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(618)occ_get_temporal_indices()
-> future_indices = []
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(620)occ_get_temporal_indices()
-> for t in range(1, n_future + 1):
(Pdb) 6
(Pdb) > /Users/liangming.xu/code/UniAD/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py(621)occ_get_temporal_indices()
-> index_t = index + t
(Pdb) 0
(Pdb) 